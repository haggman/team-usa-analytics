{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1_cDpoY64e5"
      },
      "source": [
        "# AlloyDB Semantic Search: Team USA Athletes\n",
        "\n",
        "In this notebook, you'll set up **AlloyDB** as the operational search layer for the Team USA analytics platform.\n",
        "\n",
        "While BigQuery handles analytical queries (aggregations, clustering, trends), AlloyDB provides the **fast, real-time similarity search** that an AI agent needs ‚Äî answering questions like *\"which athletes had careers most similar to Simone Biles?\"* in milliseconds.\n",
        "\n",
        "**What you'll do:**\n",
        "1. Create the `team_usa` database on your AlloyDB cluster\n",
        "2. Load 12,000+ athletes with pre-computed vector embeddings\n",
        "3. Build a ScaNN index for Google-scale similarity search\n",
        "4. Run semantic queries that find athletes by meaning, not keywords\n",
        "5. Search by natural language description ‚Äî the same pattern the agent will use\n",
        "6. Load 25,000+ individual event results linked to athletes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BUVqCjm64e7"
      },
      "source": [
        "---\n",
        "## Step 1: Configure Your Environment\n",
        "\n",
        "Update the fields below with your lab-specific values. The cluster and instance IDs should match your Terraform deployment from Task 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLonkzhy64e7"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"YOUR_PROJECT_ID\"  # @param {type:\"string\"}\n",
        "REGION = \"YOUR_LAB_REGION\"  # @param {type:\"string\"}\n",
        "USER_EMAIL = \"YOUR_LAB_USER\"  # @param {type:\"string\"}\n",
        "\n",
        "# These should match your Terraform deployment\n",
        "CLUSTER_ID = \"team-usa-cluster\"  # @param {type:\"string\"}\n",
        "INSTANCE_ID = \"team-usa-primary\"  # @param {type:\"string\"}\n",
        "\n",
        "# Derived values\n",
        "DATABASE_NAME = \"team_usa\"\n",
        "INSTANCE_URI = f\"projects/{PROJECT_ID}/locations/{REGION}/clusters/{CLUSTER_ID}/instances/{INSTANCE_ID}\"\n",
        "\n",
        "print(\"üìã Configuration:\")\n",
        "print(f\"   Project:  {PROJECT_ID}\")\n",
        "print(f\"   Region:   {REGION}\")\n",
        "print(f\"   Cluster:  {CLUSTER_ID}\")\n",
        "print(f\"   Instance: {INSTANCE_ID}\")\n",
        "print(f\"   Database: {DATABASE_NAME}\")\n",
        "print(f\"   User:     {USER_EMAIL}\")\n",
        "print(f\"\\n   Instance URI: {INSTANCE_URI}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flmoo3Is64e7"
      },
      "source": [
        "---\n",
        "## Step 2: Install Dependencies & Connect to AlloyDB\n",
        "\n",
        "The **AlloyDB Python Connector** handles secure IAM authentication ‚Äî no passwords needed. Your Google Cloud identity *is* your database identity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yjlHg9564e8"
      },
      "outputs": [],
      "source": [
        "%pip install --quiet google-cloud-alloydb-connector[pg8000] sqlalchemy pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHKS_imt64e8"
      },
      "outputs": [],
      "source": [
        "from google.cloud.alloydb.connector import Connector, IPTypes\n",
        "import pg8000\n",
        "import sqlalchemy\n",
        "from sqlalchemy import text\n",
        "\n",
        "connector = Connector()\n",
        "\n",
        "def get_connection(database=\"postgres\"):\n",
        "    \"\"\"Create a connection to AlloyDB.\"\"\"\n",
        "    conn = connector.connect(\n",
        "        INSTANCE_URI,\n",
        "        \"pg8000\",\n",
        "        user=USER_EMAIL,\n",
        "        db=database,\n",
        "        enable_iam_auth=True,\n",
        "        ip_type=IPTypes.PUBLIC,\n",
        "    )\n",
        "    return conn\n",
        "\n",
        "# Test the connection against the default postgres database\n",
        "conn = get_connection(\"postgres\")\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\"SELECT version()\")\n",
        "version = cursor.fetchone()[0]\n",
        "conn.close()\n",
        "\n",
        "print(f\"‚úÖ Connected to AlloyDB!\")\n",
        "print(f\"üîê Authenticated as: {USER_EMAIL}\")\n",
        "print(f\"üìä {version[:70]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EainBX5n64e8"
      },
      "source": [
        "---\n",
        "## Step 3: Create the Database\n",
        "\n",
        "The AlloyDB cluster has been running since Task 1, but only with the default `postgres` database. Let's create a dedicated `team_usa` database for our athlete data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rZFZD4b64e8"
      },
      "outputs": [],
      "source": [
        "# CREATE DATABASE can't run inside a transaction, so we use autocommit\n",
        "conn = get_connection(\"postgres\")\n",
        "conn.autocommit = True\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute(\"SELECT 1 FROM pg_database WHERE datname = %s\", (DATABASE_NAME,))\n",
        "if cursor.fetchone() is None:\n",
        "    cursor.execute(f\"CREATE DATABASE {DATABASE_NAME}\")\n",
        "    print(f\"‚úÖ Database '{DATABASE_NAME}' created!\")\n",
        "else:\n",
        "    print(f\"‚ÑπÔ∏è  Database '{DATABASE_NAME}' already exists.\")\n",
        "\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnnqwlTb64e8"
      },
      "source": [
        "Now connect to the new `team_usa` database. This is the connection you'll use for everything that follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFc5zdYS64e8"
      },
      "outputs": [],
      "source": [
        "# Create a SQLAlchemy engine connected to team_usa\n",
        "engine = sqlalchemy.create_engine(\n",
        "    \"postgresql+pg8000://\",\n",
        "    creator=lambda: get_connection(DATABASE_NAME),\n",
        ")\n",
        "\n",
        "# Verify the connection\n",
        "with engine.connect() as conn:\n",
        "    result = conn.execute(text(\"SELECT current_database(), current_user\"))\n",
        "    db, user = result.fetchone()\n",
        "    print(f\"‚úÖ Connected to database: {db}\")\n",
        "    print(f\"   Authenticated as: {user}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34JrMmf064e8"
      },
      "source": [
        "---\n",
        "## Step 4: Enable Extensions\n",
        "\n",
        "Two extensions give AlloyDB its vector search capabilities:\n",
        "\n",
        "- **vector** ‚Äî Adds the `VECTOR` data type for storing embeddings\n",
        "- **alloydb_scann** ‚Äî Google's [ScaNN](https://github.com/google-research/google-research/tree/master/scann) (Scalable Nearest Neighbors) algorithm for high-performance vector similarity search\n",
        "- **pgaudit** ‚Äî Provides detailed logging of database operations for security and compliance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdEXjj3a64e8"
      },
      "outputs": [],
      "source": [
        "with engine.connect() as conn:\n",
        "    conn.execute(text(\"CREATE EXTENSION IF NOT EXISTS vector\"))\n",
        "    conn.execute(text(\"CREATE EXTENSION IF NOT EXISTS alloydb_scann\"))\n",
        "    conn.execute(text(\"CREATE EXTENSION IF NOT EXISTS pgaudit\"))\n",
        "\n",
        "    conn.commit()\n",
        "\n",
        "    # Verify\n",
        "    result = conn.execute(text(\n",
        "        \"SELECT extname, extversion FROM pg_extension \"\n",
        "        \"WHERE extname IN ('vector', 'alloydb_scann', 'pgaudit') ORDER BY extname\"\n",
        "    ))\n",
        "    for row in result:\n",
        "        print(f\"‚úÖ {row[0]} v{row[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsJtqMla64e9"
      },
      "source": [
        "---\n",
        "## Step 5: Create the Athletes Table\n",
        "\n",
        "The table includes standard columns for display and filtering, plus a `VECTOR(3072)` column for the pre-computed embeddings.\n",
        "\n",
        "We're loading 13 of the 29 columns from the full dataset ‚Äî the ones needed for search results display, filtering, and vector search. Columns like birth place, height/weight, and sparse Paralympic personal details are left in BigQuery where they're available if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-KMbKP364e9"
      },
      "outputs": [],
      "source": [
        "with engine.connect() as conn:\n",
        "    conn.execute(text(\"DROP TABLE IF EXISTS athletes\"))\n",
        "    conn.execute(text(\"\"\"\n",
        "        CREATE TABLE athletes (\n",
        "          athlete_id          VARCHAR(36)  PRIMARY KEY,\n",
        "          name                VARCHAR      NOT NULL,\n",
        "          gender              VARCHAR,\n",
        "          games_type          VARCHAR      NOT NULL,\n",
        "          games_season        VARCHAR      NOT NULL,\n",
        "          primary_sport       VARCHAR      NOT NULL,\n",
        "          classification_code VARCHAR,\n",
        "          total_medals        INTEGER      DEFAULT 0,\n",
        "          gold_count          INTEGER      DEFAULT 0,\n",
        "          silver_count        INTEGER      DEFAULT 0,\n",
        "          bronze_count        INTEGER      DEFAULT 0,\n",
        "          games_count         INTEGER      DEFAULT 0,\n",
        "          first_games_year    INTEGER,\n",
        "          last_games_year     INTEGER,\n",
        "          profile_summary     TEXT,\n",
        "          embedding           VECTOR(3072)\n",
        "      )\n",
        "    \"\"\"))\n",
        "    conn.commit()\n",
        "\n",
        "print(\"‚úÖ Athletes table created!\")\n",
        "print(\"   Columns: athlete_id, name, gender, games_type, primary_sport,\")\n",
        "print(\"            classification_code, total_medals, gold_count, games_count,\")\n",
        "print(\"            first_games_year, last_games_year, profile_summary, embedding\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzlQ3Bhh64e9"
      },
      "source": [
        "---\n",
        "## Step 6: Load Athlete Data\n",
        "\n",
        "We'll load data using AlloyDB's **GCS import** ‚Äî a server-side bulk load that's significantly faster than inserting rows through a client connection. The process:\n",
        "\n",
        "1. Download the source CSV and select the columns we need\n",
        "2. Stage the prepared data in a Cloud Storage bucket\n",
        "3. Import directly into AlloyDB via server-side load"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2RuFnJD64e9"
      },
      "source": [
        "### Step 6.1: Download and prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-Gnw3xi64e9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Download the full athletes CSV from the lab's GCS bucket\n",
        "print(\"‚è≥ Downloading athlete data from Cloud Storage...\")\n",
        "df = pd.read_csv(\"gs://class-demo/team-usa/final/team_usa_athletes.csv\")\n",
        "print(f\"   Downloaded {len(df):,} athletes with {len(df.columns)} columns\")\n",
        "\n",
        "# Select the 16 columns we need, in table column order\n",
        "columns = [\n",
        "    'athlete_id', 'name', 'gender', 'games_type', 'games_season',\n",
        "    'primary_sport', 'classification_code', 'total_medals', 'gold_count',\n",
        "    'silver_count', 'bronze_count', 'games_count', 'first_games_year',\n",
        "    'last_games_year', 'profile_summary', 'embedding'\n",
        "]\n",
        "df_alloydb = df[columns].copy()\n",
        "\n",
        "# Fix pandas float-promotion for integer columns\n",
        "int_columns = ['total_medals', 'gold_count', 'silver_count', 'bronze_count',\n",
        "               'games_count', 'first_games_year', 'last_games_year']\n",
        "for col in int_columns:\n",
        "    df_alloydb[col] = df_alloydb[col].fillna(0).astype(int)\n",
        "\n",
        "# Save without headers ‚Äî the GCS import maps columns positionally\n",
        "local_path = \"/tmp/athletes_for_alloydb.csv\"\n",
        "df_alloydb.to_csv(local_path, index=False, header=False)\n",
        "\n",
        "print(f\"‚úÖ Prepared {len(df_alloydb):,} athletes ({len(columns)} columns) for import\")\n",
        "print(f\"   Saved to {local_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFFITcR164e9"
      },
      "source": [
        "### Step 6.2: Stage data to Cloud Storage\n",
        "\n",
        "AlloyDB's GCS import reads directly from Cloud Storage, so we need to stage our prepared file in a bucket that the AlloyDB service agent can access."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAii3men64e9"
      },
      "outputs": [],
      "source": [
        "# Get the project number (needed to identify the AlloyDB service agent)\n",
        "project_number = !gcloud projects describe {PROJECT_ID} --format=\"value(projectNumber)\"\n",
        "project_number = project_number[0].strip()\n",
        "service_agent = f\"service-{project_number}@gcp-sa-alloydb.iam.gserviceaccount.com\"\n",
        "\n",
        "STAGING_BUCKET = f\"{PROJECT_ID}-team-usa-staging\"\n",
        "\n",
        "# Create the staging bucket\n",
        "!gcloud storage buckets create gs://{STAGING_BUCKET} --location={REGION} 2>/dev/null || true\n",
        "\n",
        "# Grant AlloyDB service agent read access\n",
        "!gcloud storage buckets add-iam-policy-binding gs://{STAGING_BUCKET} \\\n",
        "    --member=\"serviceAccount:{service_agent}\" \\\n",
        "    --role=\"roles/storage.objectViewer\" --quiet\n",
        "\n",
        "# Upload the prepared CSV\n",
        "!gcloud storage cp {local_path} gs://{STAGING_BUCKET}/athletes_for_alloydb.csv --quiet\n",
        "\n",
        "print(f\"\\n‚úÖ Data staged to gs://{STAGING_BUCKET}/athletes_for_alloydb.csv\")\n",
        "print(f\"   AlloyDB service agent ({service_agent[:40]}...) granted read access\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D_oAJlj64e9"
      },
      "source": [
        "### Step 6.3: Import into AlloyDB\n",
        "\n",
        "This triggers a **server-side import** ‚Äî AlloyDB reads the CSV directly from Cloud Storage. Much faster than sending rows through a client connection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zywtmYWy64e9"
      },
      "outputs": [],
      "source": [
        "print(\"‚è≥ Importing athletes into AlloyDB (this may take 1-3 minutes)...\")\n",
        "\n",
        "!gcloud alloydb clusters import {CLUSTER_ID} \\\n",
        "    --project={PROJECT_ID} \\\n",
        "    --region={REGION} \\\n",
        "    --database={DATABASE_NAME} \\\n",
        "    --user={USER_EMAIL} \\\n",
        "    --csv \\\n",
        "    --table=athletes \\\n",
        "    --gcs-uri=gs://{STAGING_BUCKET}/athletes_for_alloydb.csv \\\n",
        "    --columns=athlete_id,name,gender,games_type,games_season,primary_sport,classification_code,total_medals,gold_count,silver_count,bronze_count,games_count,first_games_year,last_games_year,profile_summary,embedding\n",
        "\n",
        "print(\"\\n‚úÖ Import complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNHseKpR64e9"
      },
      "source": [
        "---\n",
        "## Step 7: Verify the Data\n",
        "\n",
        "Let's confirm everything loaded correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWCV_t4e64e9"
      },
      "outputs": [],
      "source": [
        "with engine.connect() as conn:\n",
        "    # Total count\n",
        "    result = conn.execute(text(\"SELECT COUNT(*) FROM athletes\"))\n",
        "    total = result.scalar()\n",
        "\n",
        "    # Embedding count\n",
        "    result = conn.execute(text(\"SELECT COUNT(*) FROM athletes WHERE embedding IS NOT NULL\"))\n",
        "    with_embeddings = result.scalar()\n",
        "\n",
        "    # Games type breakdown\n",
        "    result = conn.execute(text(\n",
        "        \"SELECT games_type, COUNT(*) FROM athletes GROUP BY games_type ORDER BY games_type\"\n",
        "    ))\n",
        "    breakdown = result.fetchall()\n",
        "\n",
        "    print(f\"‚úÖ Athletes loaded: {total:,}\")\n",
        "    print(f\"   With embeddings: {with_embeddings:,}\")\n",
        "    for games_type, count in breakdown:\n",
        "        print(f\"   {games_type}: {count:,}\")\n",
        "\n",
        "    # Sample some athletes\n",
        "    print(\"\\nüìã Sample athletes:\")\n",
        "    result = conn.execute(text(\"\"\"\n",
        "        SELECT name, primary_sport, games_type,\n",
        "               gold_count, silver_count, bronze_count, total_medals,\n",
        "               first_games_year || '-' || last_games_year AS career\n",
        "        FROM athletes\n",
        "        WHERE total_medals > 5\n",
        "        ORDER BY total_medals DESC\n",
        "        LIMIT 8\n",
        "    \"\"\"))\n",
        "    print(f\"   {'Name':<30s} {'Sport':<25s} {'Type':<12s} {'ü•á':>3s} {'ü•à':>3s} {'ü•â':>3s} {'Tot':>4s} {'Career'}\")\n",
        "    print(f\"   {'-'*30} {'-'*25} {'-'*12} {'-'*3} {'-'*3} {'-'*3} {'-'*4} {'-'*9}\")\n",
        "    for row in result:\n",
        "        print(f\"   {row[0]:<30s} {row[1]:<25s} {row[2]:<12s} {row[3]:>3d} {row[4]:>3d} {row[5]:>3d} {row[6]:>4d} {row[7]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JP-1owT64e9"
      },
      "source": [
        "---\n",
        "## Step 8: Create the ScaNN Index\n",
        "\n",
        "Without an index, every similarity search compares your query against all 12,222 embeddings ‚Äî a brute-force scan. The **ScaNN** index pre-organizes vectors into partitions so queries search only the most promising candidates.\n",
        "\n",
        "- **cosine** distance: Measures the angle between vectors. Ideal for text embeddings.\n",
        "- **num_leaves = 50**: Partitions vectors into 50 clusters for search.\n",
        "- **quantizer = 'sq8'**: Compresses dimensions to 8-bit, reducing memory while preserving accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grFrER_u64e9"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    print(\"‚è≥ Creating ScaNN index...\")\n",
        "    start = time.time()\n",
        "    conn.execute(text(\"\"\"\n",
        "        CREATE INDEX athletes_embedding_idx\n",
        "        ON athletes USING scann (embedding cosine)\n",
        "        WITH (num_leaves = 50, quantizer = 'sq8')\n",
        "    \"\"\"))\n",
        "    conn.commit()\n",
        "    elapsed = time.time() - start\n",
        "    print(f\"‚úÖ ScaNN index created in {elapsed:.1f}s\")\n",
        "\n",
        "    # Verify the index exists\n",
        "    result = conn.execute(text(\"\"\"\n",
        "        SELECT indexname, indexdef\n",
        "        FROM pg_indexes\n",
        "        WHERE tablename = 'athletes' AND indexname = 'athletes_embedding_idx'\n",
        "    \"\"\"))\n",
        "    idx = result.fetchone()\n",
        "    if idx:\n",
        "        print(f\"   Index: {idx[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wUuo_Cs64e9"
      },
      "source": [
        "---\n",
        "## Step 9: Find Similar Athletes\n",
        "\n",
        "Now for the payoff. This query looks up a specific athlete's embedding and finds the nearest neighbors in vector space ‚Äî athletes whose career \"fingerprints\" are closest in 3,072-dimensional space.\n",
        "\n",
        "The `<=>` operator computes **cosine distance** between vectors (lower = more similar). We convert to a similarity score (higher = more similar) with `1 - distance`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNJ9FliD64e9"
      },
      "source": [
        "### Simone Biles ‚Äî Dominant multi-Games gymnast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7guDI0A64e9"
      },
      "outputs": [],
      "source": [
        "with engine.connect() as conn:\n",
        "    result = conn.execute(text(\"\"\"\n",
        "        SELECT\n",
        "            a2.name,\n",
        "            a2.primary_sport,\n",
        "            a2.games_type,\n",
        "            a2.classification_code,\n",
        "            a2.gold_count,\n",
        "            a2.silver_count,\n",
        "            a2.bronze_count,\n",
        "            a2.total_medals,\n",
        "            a2.first_games_year || '-' || a2.last_games_year AS career,\n",
        "            ROUND((1 - (a1.embedding <=> a2.embedding))::numeric, 3) AS similarity\n",
        "        FROM athletes a1\n",
        "        CROSS JOIN athletes a2\n",
        "        WHERE a1.name like '%Simone%Biles%'\n",
        "          AND a2.athlete_id != a1.athlete_id\n",
        "          AND a2.embedding IS NOT NULL\n",
        "        ORDER BY a1.embedding <=> a2.embedding\n",
        "        LIMIT 10\n",
        "    \"\"\"))\n",
        "\n",
        "    print(\"üîç Athletes most similar to Simone Biles:\\n\")\n",
        "    print(f\"   {'Name':<30s} {'Sport':<22s} {'Type':<10s} {'ü•á':>3s} {'ü•à':>3s} {'ü•â':>3s} {'Tot':>4s} {'Career':<10s} {'Sim':>5s}\")\n",
        "    print(f\"   {'-'*30} {'-'*22} {'-'*10} {'-'*3} {'-'*3} {'-'*3} {'-'*4} {'-'*10} {'-'*5}\")\n",
        "    for row in result:\n",
        "        print(f\"   {row[0]:<30s} {row[1]:<22s} {row[2]:<10s} {row[4]:>3d} {row[5]:>3d} {row[6]:>3d} {row[7]:>4d} {row[8]:<10s} {row[9]:>5.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wbz_CZ4G64e9"
      },
      "source": [
        "### Trischa Zorn ‚Äî Most decorated Paralympic athlete (blind swimmer, 55 medals)\n",
        "\n",
        "This result is especially interesting. Watch for visually impaired athletes from *different sports* appearing in the results ‚Äî the embeddings capture the disability classification signal, connecting athletes across sport boundaries by shared experience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apGKyxYM64e-"
      },
      "outputs": [],
      "source": [
        "with engine.connect() as conn:\n",
        "    result = conn.execute(text(\"\"\"\n",
        "        SELECT\n",
        "            a2.name,\n",
        "            a2.primary_sport,\n",
        "            a2.games_type,\n",
        "            a2.classification_code,\n",
        "            a2.gold_count,\n",
        "            a2.silver_count,\n",
        "            a2.bronze_count,\n",
        "            a2.total_medals,\n",
        "            a2.first_games_year || '-' || a2.last_games_year AS career,\n",
        "            ROUND((1 - (a1.embedding <=> a2.embedding))::numeric, 3) AS similarity\n",
        "        FROM athletes a1\n",
        "        CROSS JOIN athletes a2\n",
        "        WHERE a1.name = 'Trischa Zorn'\n",
        "          AND a2.athlete_id != a1.athlete_id\n",
        "          AND a2.embedding IS NOT NULL\n",
        "        ORDER BY a1.embedding <=> a2.embedding\n",
        "        LIMIT 10\n",
        "    \"\"\"))\n",
        "\n",
        "    print(\"üîç Athletes most similar to Trischa Zorn:\\n\")\n",
        "    print(f\"   {'Name':<30s} {'Sport':<22s} {'Type':<10s} {'Class':<8s} {'ü•á':>3s} {'ü•à':>3s} {'ü•â':>3s} {'Tot':>4s} {'Career':<10s} {'Sim':>5s}\")\n",
        "    print(f\"   {'-'*30} {'-'*22} {'-'*10} {'-'*8} {'-'*3} {'-'*3} {'-'*3} {'-'*4} {'-'*10} {'-'*5}\")\n",
        "    for row in result:\n",
        "        cls = row[3] if row[3] else \"\"\n",
        "        print(f\"   {row[0]:<30s} {row[1]:<22s} {row[2]:<10s} {cls:<8s} {row[4]:>3d} {row[5]:>3d} {row[6]:>3d} {row[7]:>4d} {row[8]:<10s} {row[9]:>5.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hcr_gYT64e-"
      },
      "source": [
        "---\n",
        "## Step 10: Filtered Similarity Search\n",
        "\n",
        "Pure vector search is powerful, but real-world applications almost always combine it with relational filters. This is where AlloyDB shines over standalone vector databases ‚Äî you can mix SQL `WHERE` clauses with vector similarity in a single query.\n",
        "\n",
        "The pattern: use `ORDER BY embedding <=>` for similarity ranking, and standard SQL filters to narrow the scope. One query, one database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1UnMGXH64e-"
      },
      "outputs": [],
      "source": [
        "# Find Winter athletes with careers most similar to Michael Phelps\n",
        "# Change the name or the WHERE filter and re-run!\n",
        "search_athlete = \"Michael Phelps\"\n",
        "filter_clause = \"a2.games_season = 'Winter'\"\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    result = conn.execute(text(f\"\"\"\n",
        "        SELECT\n",
        "            a2.name,\n",
        "            a2.primary_sport,\n",
        "            a2.games_type,\n",
        "            a2.games_season,\n",
        "            a2.gold_count,\n",
        "            a2.silver_count,\n",
        "            a2.bronze_count,\n",
        "            a2.total_medals,\n",
        "            a2.first_games_year || '-' || a2.last_games_year AS career,\n",
        "            ROUND((1 - (a1.embedding <=> a2.embedding))::numeric, 3) AS similarity\n",
        "        FROM athletes a1\n",
        "        CROSS JOIN athletes a2\n",
        "        WHERE a1.name like :athlete\n",
        "          AND a2.athlete_id != a1.athlete_id\n",
        "          AND a2.embedding IS NOT NULL\n",
        "          AND {filter_clause}\n",
        "        ORDER BY a1.embedding <=> a2.embedding\n",
        "        LIMIT 10\n",
        "    \"\"\"), {\"athlete\": search_athlete})\n",
        "\n",
        "    print(f\"üîç Athletes matching filter '{filter_clause}' most similar to {search_athlete}:\\n\")\n",
        "    print(f\"   {'Name':<30s} {'Sport':<22s} {'Season':<8s} {'ü•á':>3s} {'ü•à':>3s} {'ü•â':>3s} {'Tot':>4s} {'Career':<10s} {'Sim':>5s}\")\n",
        "    print(f\"   {'-'*30} {'-'*22} {'-'*8} {'-'*3} {'-'*3} {'-'*3} {'-'*4} {'-'*10} {'-'*5}\")\n",
        "    for row in result:\n",
        "        print(f\"   {row[0]:<30s} {row[1]:<22s} {row[3]:<8s} {row[4]:>3d} {row[5]:>3d} {row[6]:>3d} {row[7]:>4d} {row[8]:<10s} {row[9]:>5.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzgZsXZhGao0"
      },
      "source": [
        "---\n",
        "## Step 11: Search by Natural Language Description\n",
        "\n",
        "Here's what the agent will do in Task 5: instead of looking up a specific athlete's embedding, **generate an embedding from a text description on the fly** using AlloyDB's built-in `embedding()` function, then find the nearest athletes.\n",
        "\n",
        "This means you can search by *meaning* ‚Äî describe what you're looking for in plain English, and AlloyDB finds the closest matches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-URdN0FiGcO5"
      },
      "outputs": [],
      "source": [
        "# Try different descriptions by changing this variable!\n",
        "search_description = \"dominant swimmer with many gold medals across multiple Olympics\"\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    result = conn.execute(text(\"\"\"\n",
        "        SELECT\n",
        "            name,\n",
        "            primary_sport,\n",
        "            games_type,\n",
        "            gold_count,\n",
        "            silver_count,\n",
        "            bronze_count,\n",
        "            total_medals,\n",
        "            first_games_year || '-' || last_games_year AS career,\n",
        "            ROUND((1 - (embedding <=> embedding('gemini-embedding-001', :query)::vector))::numeric, 3) AS similarity\n",
        "        FROM athletes\n",
        "        WHERE embedding IS NOT NULL\n",
        "        ORDER BY embedding <=> embedding('gemini-embedding-001', :query)::vector\n",
        "        LIMIT 10\n",
        "    \"\"\"), {\"query\": search_description})\n",
        "\n",
        "    print(f\"üîç Athletes matching: \\\"{search_description}\\\"\\n\")\n",
        "    print(f\"   {'Name':<30s} {'Sport':<22s} {'Type':<10s} {'ü•á':>3s} {'ü•à':>3s} {'ü•â':>3s} {'Tot':>4s} {'Career':<10s} {'Sim':>5s}\")\n",
        "    print(f\"   {'-'*30} {'-'*22} {'-'*10} {'-'*3} {'-'*3} {'-'*3} {'-'*4} {'-'*10} {'-'*5}\")\n",
        "    for row in result:\n",
        "        print(f\"   {row[0]:<30s} {row[1]:<22s} {row[2]:<10s} {row[3]:>3d} {row[4]:>3d} {row[5]:>3d} {row[6]:>4d} {row[7]:<10s} {row[8]:>5.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0HmLfOB64e-"
      },
      "source": [
        "### Try other descriptions!\n",
        "\n",
        "Change the `search_description` variable above and re-run the cell. Some ideas:\n",
        "\n",
        "- `\"Paralympic track and field athlete competing in wheelchair events\"`\n",
        "- `\"Winter sport athlete with a long career spanning many Games\"`\n",
        "- `\"Young gymnast who became a cultural icon\"`\n",
        "- `\"Team sport athlete who won gold in basketball or volleyball\"`\n",
        "\n",
        "This is exactly the query pattern the agent will use in Task 5 ‚Äî converting a user's natural language question into a vector and searching AlloyDB for the most relevant athletes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAbhTgstjNLA"
      },
      "source": [
        "---\n",
        "## Step 12: Create the Results Table\n",
        "\n",
        "While the `athletes` table captures career summaries, the `results` table stores **individual event outcomes** ‚Äî every medal (and non-medal finish) for every athlete across every Games.\n",
        "\n",
        "This enables queries like \"what events did Simone Biles compete in?\" or \"show me all gold medals in gymnastics at the 2020 Games.\"\n",
        "\n",
        "Using the same approach we used above with `athletes`, the cells below create the `results` table and load the data from the CSV into it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zS3s2e-hQUbX"
      },
      "outputs": [],
      "source": [
        "with engine.connect() as conn:\n",
        "    conn.execute(text(\"DROP TABLE IF EXISTS results\"))\n",
        "    conn.execute(text(\"\"\"\n",
        "        CREATE TABLE results (\n",
        "            result_id           SERIAL PRIMARY KEY,\n",
        "            athlete_id          VARCHAR(36) REFERENCES athletes(athlete_id),\n",
        "            athlete_name        VARCHAR NOT NULL,\n",
        "            games_year          INTEGER,\n",
        "            games_season        VARCHAR,\n",
        "            games_type          VARCHAR,\n",
        "            sport               VARCHAR,\n",
        "            discipline          VARCHAR,\n",
        "            event               VARCHAR,\n",
        "            medal               VARCHAR,\n",
        "            classification_code VARCHAR\n",
        "        )\n",
        "    \"\"\"))\n",
        "    conn.commit()\n",
        "\n",
        "print(\"‚úÖ Results table created!\")\n",
        "print(\"   Columns: result_id (auto), athlete_id (FK), athlete_name, games_year,\")\n",
        "print(\"            games_season, games_type, sport, discipline, event, medal, classification_code\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpHk4HDLj818"
      },
      "outputs": [],
      "source": [
        "# Download the results CSV from the lab's GCS bucket\n",
        "print(\"‚è≥ Downloading results data from Cloud Storage...\")\n",
        "df_results = pd.read_csv(\"gs://class-demo/team-usa/final/team_usa_results.csv\")\n",
        "print(f\"   Downloaded {len(df_results):,} results with {len(df_results.columns)} columns\")\n",
        "\n",
        "# Select columns in table order (excluding result_id ‚Äî Postgres generates that)\n",
        "columns = [\n",
        "    'athlete_id', 'athlete_name', 'games_year', 'games_season', 'games_type',\n",
        "    'sport', 'discipline', 'event', 'medal', 'classification_code'\n",
        "]\n",
        "df_results_alloydb = df_results[columns].copy()\n",
        "\n",
        "# Convert games_year from float to nullable int (NaN ‚Üí empty string for CSV)\n",
        "df_results_alloydb['games_year'] = df_results_alloydb['games_year'].apply(\n",
        "    lambda x: '' if pd.isna(x) else str(int(x))\n",
        ")\n",
        "\n",
        "# Save without headers ‚Äî GCS import maps columns positionally\n",
        "local_results_path = \"/tmp/results_for_alloydb.csv\"\n",
        "df_results_alloydb.to_csv(local_results_path, index=False, header=False)\n",
        "\n",
        "print(f\"‚úÖ Prepared {len(df_results_alloydb):,} results ({len(columns)} columns) for import\")\n",
        "print(f\"   Saved to {local_results_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w60Gn1TkkBpD"
      },
      "outputs": [],
      "source": [
        "# Upload the prepared CSV to the staging bucket\n",
        "!gcloud storage cp {local_results_path} gs://{STAGING_BUCKET}/results_for_alloydb.csv --quiet\n",
        "\n",
        "print(f\"‚úÖ Data staged to gs://{STAGING_BUCKET}/results_for_alloydb.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kp_YIERCkHWs"
      },
      "outputs": [],
      "source": [
        "print(\"‚è≥ Importing results into AlloyDB (this may take 1-2 minutes)...\")\n",
        "\n",
        "!gcloud alloydb clusters import {CLUSTER_ID} \\\n",
        "    --project={PROJECT_ID} \\\n",
        "    --region={REGION} \\\n",
        "    --database={DATABASE_NAME} \\\n",
        "    --user={USER_EMAIL} \\\n",
        "    --csv \\\n",
        "    --table=results \\\n",
        "    --gcs-uri=gs://{STAGING_BUCKET}/results_for_alloydb.csv \\\n",
        "    --columns=athlete_id,athlete_name,games_year,games_season,games_type,sport,discipline,event,medal,classification_code\n",
        "\n",
        "print(\"\\n‚úÖ Import complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BBE88yEkIO5"
      },
      "outputs": [],
      "source": [
        "with engine.connect() as conn:\n",
        "    # Total count\n",
        "    result = conn.execute(text(\"SELECT COUNT(*) FROM results\"))\n",
        "    total = result.scalar()\n",
        "\n",
        "    # Medal breakdown\n",
        "    result = conn.execute(text(\"\"\"\n",
        "        SELECT medal, COUNT(*)\n",
        "        FROM results\n",
        "        WHERE medal IS NOT NULL\n",
        "        GROUP BY medal\n",
        "        ORDER BY COUNT(*) DESC\n",
        "    \"\"\"))\n",
        "    medals = result.fetchall()\n",
        "\n",
        "    # Results with athlete FK match\n",
        "    result = conn.execute(text(\"\"\"\n",
        "        SELECT COUNT(*) FROM results r\n",
        "        JOIN athletes a ON r.athlete_id = a.athlete_id\n",
        "    \"\"\"))\n",
        "    matched = result.scalar()\n",
        "\n",
        "    print(f\"‚úÖ Results loaded: {total:,}\")\n",
        "    print(f\"   Matched to athletes: {matched:,}\")\n",
        "    print(f\"\\n   Medal breakdown:\")\n",
        "    for medal, count in medals:\n",
        "        print(f\"   {medal}: {count:,}\")\n",
        "\n",
        "    # Sample some results\n",
        "    print(\"\\nüìã Sample results:\")\n",
        "    result = conn.execute(text(\"\"\"\n",
        "        SELECT athlete_name, games_year, sport, event, medal\n",
        "        FROM results\n",
        "        WHERE medal = 'Gold'\n",
        "        ORDER BY games_year DESC\n",
        "        LIMIT 8\n",
        "    \"\"\"))\n",
        "    print(f\"   {'Athlete':<25s} {'Year':>5s} {'Sport':<20s} {'Event':<30s} {'Medal'}\")\n",
        "    print(f\"   {'-'*25} {'-'*5} {'-'*20} {'-'*30} {'-'*6}\")\n",
        "    for row in result:\n",
        "        year = str(row[1]) if row[1] else 'N/A'\n",
        "        print(f\"   {row[0]:<25s} {year:>5s} {row[2]:<20s} {row[3]:<30s} {row[4]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V7z9o7Cp2qV"
      },
      "source": [
        "---\n",
        "## ‚úÖ Task 4 Complete!\n",
        "\n",
        "You've set up AlloyDB as the operational search layer for the Team USA platform:\n",
        "\n",
        "- **Created** the `team_usa` database with vector extensions\n",
        "- **Loaded** 12,000+ athletes with 3,072-dimension embeddings\n",
        "- **Built** a ScaNN index for fast similarity search\n",
        "- **Searched** by specific athlete (Simone Biles, Trischa Zorn)\n",
        "- **Searched** by natural language description using `embedding()`\n",
        "- **Loaded** 25,000+ event results with foreign key links to athletes\n",
        "\n",
        "Your AlloyDB instance now has two tables working together:\n",
        "- `athletes` ‚Äî career summaries with vector embeddings for semantic search\n",
        "- `results` ‚Äî individual event outcomes for detailed competition queries\n",
        "\n",
        "**What's next:** In Task 5, you'll build an AI agent that combines BigQuery (analytics, clustering) with AlloyDB (similarity search, event lookups) ‚Äî choosing the right tool for each question automatically."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "alloydb_semantic_search.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
