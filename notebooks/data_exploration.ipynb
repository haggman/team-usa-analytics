{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Team USA: Data Exploration & BigQuery Loading"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83c\udfc5 Team USA: Data Exploration & BigQuery Loading\n",
        "\n",
        "In this notebook, you'll load and explore 120 years of Team USA Olympic and Paralympic data, then load it into BigQuery for SQL analytics and machine learning.\n",
        "\n",
        "**What you'll do:**\n",
        "1. Load the athletes dataset into pandas for interactive exploration\n",
        "2. Use the **Data Science Agent** to profile and visualize the data with AI\n",
        "3. Load both datasets into BigQuery for analysis in the next task\n",
        "4. Verify the data loaded correctly\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load the Athletes Data\n",
        "\n",
        "Let's start by loading the athletes dataset from Google Cloud Storage into a pandas DataFrame. This gives you an in-memory copy that the Data Science Agent can analyze interactively.\n",
        "\n",
        "The dataset contains **12,222 Team USA athletes** spanning the 1896 Athens Olympics through the 2024 Paris Games \u2014 both Olympic and Paralympic competitors in a single unified table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load athletes data directly from Google Cloud Storage\n",
        "df = pd.read_csv('gs://class-demo/team-usa/final/team_usa_athletes.csv')\n",
        "\n",
        "print(f\"Dataset shape: {df.shape[0]:,} athletes \u00d7 {df.shape[1]} columns\")\n",
        "print(f\"\\nColumns: {', '.join(df.columns.tolist())}\")\n",
        "print(f\"\\nFirst 5 rows:\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Explore with the Data Science Agent\n",
        "\n",
        "Now let's use the AI-powered **Data Science Agent** to explore this data. Instead of writing analysis code yourself, you'll describe what you want to understand in plain English, and the agent will plan, code, execute, and visualize autonomously.\n",
        "\n",
        "### How to use the agent\n",
        "\n",
        "1. Look at the **chat panel at the bottom** of this notebook \u2014 it says *\"What can I help you build?\"*\n",
        "2. Type a prompt describing what you want to explore\n",
        "3. The agent will propose code cells (marked **\u2726 Gemini**) with a plan showing its steps\n",
        "4. Click **Accept & Run** to execute each proposed cell\n",
        "5. The agent may propose follow-up steps based on the results \u2014 keep clicking **Accept & Run**\n",
        "\n",
        "> **Note:** The first prompt may take a minute or two as the agent initializes. Subsequent prompts will be faster.\n",
        "\n",
        "---\n",
        "\n",
        "### Prompt 1 \u2014 Dataset Profiling\n",
        "\n",
        "Start by getting an overview of the data quality and structure. Copy this into the chat panel:\n",
        "\n",
        "```\n",
        "Profile this dataset. Show me the shape, data types, missing values, and basic statistics for the numeric columns.\n",
        "```\n",
        "\n",
        "**What to look for:**\n",
        "- `height_cm` and `weight_kg` \u2014 available for ~65-69% of athletes (mostly Olympic). Almost no biometric data exists for Paralympic athletes.\n",
        "- `reason`, `hero`, `philosophy`, etc. \u2014 populated only for Paris 2024 Paralympic athletes\n",
        "- `profile_summary` and `embedding` \u2014 100% coverage (AI-generated for every athlete)\n",
        "- Most athletes have zero medals \u2014 making the team is the achievement!\n",
        "\n",
        "---\n",
        "\n",
        "### Prompt 2 \u2014 Olympic vs. Paralympic Distribution\n",
        "\n",
        "```\n",
        "Show me the distribution of athletes by games_type and gender. Include a visualization.\n",
        "```\n",
        "\n",
        "**What to notice:** The Olympic/Paralympic split, gender balance, and how representation has evolved.\n",
        "\n",
        "---\n",
        "\n",
        "### Prompt 3 \u2014 Sports and Medal Distribution\n",
        "\n",
        "```\n",
        "Which sports have the most athletes and the most total medals? Show the top 10 of each with visualizations.\n",
        "```\n",
        "\n",
        "**What to notice:** Athletics and Swimming dominate. Paralympic sports like Wheelchair Basketball appear in the rankings \u2014 this dataset tells the *complete* Team USA story.\n",
        "\n",
        "---\n",
        "\n",
        "### Keep Exploring! (Optional)\n",
        "\n",
        "The agent is context-aware \u2014 it remembers everything in your notebook. Try your own questions:\n",
        "\n",
        "- *\"Who has the most career gold medals?\"*\n",
        "- *\"How has the number of female athletes changed over the decades?\"*\n",
        "- *\"What's the average career span of medalists vs. non-medalists?\"*\n",
        "- *\"Show the distribution of athletes across decades by games_type\"*\n",
        "\n",
        "When you're ready, move on to Step 3 to load the data into BigQuery."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load Data into BigQuery\n",
        "\n",
        "You've explored the data interactively \u2014 now let's load it into BigQuery where you can run SQL analytics and train ML models. We'll load directly from Google Cloud Storage using BigQuery's native import, which is much faster than uploading from this notebook.\n",
        "\n",
        "First, set your project ID:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Replace with your lab project ID\n",
        "PROJECT_ID = \"YOUR_PROJECT_ID\"  # e.g., \"qwiklabs-gcp-00-abc123def456\"\n",
        "\n",
        "print(f\"Project ID set to: {PROJECT_ID}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load the athletes table\n",
        "\n",
        "This loads all 12,222 athletes with schema autodetection. The embedding column (3072-dimension vectors stored as JSON strings) makes this file large, so the load takes about a minute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!bq load --project_id=$PROJECT_ID \\\n",
        "  --source_format=CSV \\\n",
        "  --autodetect \\\n",
        "  --replace \\\n",
        "  team_usa.athletes \\\n",
        "  gs://class-demo/team-usa/final/team_usa_athletes.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load the results table\n",
        "\n",
        "The results table (24,945 competition records) is smaller and loads in seconds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!bq load --project_id=$PROJECT_ID \\\n",
        "  --source_format=CSV \\\n",
        "  --autodetect \\\n",
        "  --replace \\\n",
        "  team_usa.results \\\n",
        "  gs://class-demo/team-usa/final/team_usa_results.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Note on data types:** BigQuery's autodetect may type integer columns like `total_medals` and `games_count` as FLOAT64 (because some rows have NULL values). This is perfectly fine \u2014 BQML handles FLOAT64 without issues, and you can CAST to INT64 in queries if you prefer cleaner display."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Verify the Load\n",
        "\n",
        "Let's confirm everything loaded correctly with a few quick queries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Row counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "# Check row counts\n",
        "for table in ['athletes', 'results']:\n",
        "    query = f\"SELECT COUNT(*) as row_count FROM `{PROJECT_ID}.team_usa.{table}`\"\n",
        "    result = client.query(query).result()\n",
        "    for row in result:\n",
        "        print(f\"team_usa.{table}: {row.row_count:,} rows\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should see:\n",
        "- `team_usa.athletes`: **12,222** rows\n",
        "- `team_usa.results`: **24,945** rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Top medalists \u2014 who leads Team USA's all-time medal count?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "query = \"\"\"\n",
        "SELECT \n",
        "    name,\n",
        "    primary_sport,\n",
        "    games_type,\n",
        "    CAST(games_count AS INT64) AS games_count,\n",
        "    CAST(gold_count AS INT64) AS gold,\n",
        "    CAST(silver_count AS INT64) AS silver,\n",
        "    CAST(bronze_count AS INT64) AS bronze,\n",
        "    CAST(total_medals AS INT64) AS total_medals\n",
        "FROM `team_usa.athletes`\n",
        "WHERE total_medals > 0\n",
        "ORDER BY total_medals DESC\n",
        "LIMIT 15\n",
        "\"\"\"\n",
        "\n",
        "top_medalists = client.query(query).to_dataframe()\n",
        "print(\"\ud83c\udfc5 Team USA All-Time Top Medalists:\")\n",
        "top_medalists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Olympic vs. Paralympic athlete counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "query = \"\"\"\n",
        "SELECT \n",
        "    games_type,\n",
        "    COUNT(*) as athlete_count,\n",
        "    CAST(SUM(total_medals) AS INT64) as total_medals\n",
        "FROM `team_usa.athletes`\n",
        "GROUP BY games_type\n",
        "ORDER BY athlete_count DESC\n",
        "\"\"\"\n",
        "\n",
        "breakdown = client.query(query).to_dataframe()\n",
        "print(\"Olympic vs. Paralympic:\")\n",
        "breakdown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## \u2705 Data Loaded \u2014 Ready for Analytics!\n",
        "\n",
        "You've loaded and explored 120 years of Team USA data. Here's what you accomplished:\n",
        "\n",
        "- **12,222 athletes** and **24,945 competition results** are now in BigQuery\n",
        "- You used the **Data Science Agent** to understand the data without writing analysis code\n",
        "- You've identified key patterns: the Olympic/Paralympic split, sport distributions, and data quality characteristics\n",
        "\n",
        "**In the next task**, you'll move to the BigQuery console to run analytical queries with **Gemini Cloud Assist** and train a **K-Means clustering model** that discovers hidden athlete career archetypes \u2014 using nothing but SQL.\n",
        "\n",
        "Close this notebook and head back to the lab instructions for **Task 3**."
      ]
    }
  ]
}