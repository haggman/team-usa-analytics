{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "data_exploration.ipynb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YksXvOW2XIPY"
      },
      "source": [
        "# üèÖ Team USA: Data Exploration & BigQuery Loading\n",
        "\n",
        "In this notebook, you'll load and explore 120 years of Team USA Olympic and Paralympic data, then load it into BigQuery for SQL analytics and machine learning.\n",
        "\n",
        "**What you'll do:**\n",
        "1. Load the athletes dataset into pandas for interactive exploration\n",
        "2. Use the **Data Science Agent** to profile and visualize the data with AI\n",
        "3. Load both datasets into BigQuery for analysis in the next task\n",
        "4. Verify the data loaded correctly\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA5D6ELJXIPZ"
      },
      "source": [
        "## Step 1: Load the Athletes Data\n",
        "\n",
        "Let's start by loading the athletes dataset from Google Cloud Storage into a pandas DataFrame. This gives you an in-memory copy that the Data Science Agent can analyze interactively.\n",
        "\n",
        "The dataset contains **11,843 Team USA athletes** spanning the 1896 Athens Olympics through the 2024 Paris Games ‚Äî both Olympic and Paralympic competitors in a single unified table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ONc0Bh7XIPa"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load athletes data directly from Google Cloud Storage\n",
        "df = pd.read_csv('gs://class-demo/team-usa/final/team_usa_athletes.csv')\n",
        "\n",
        "print(f\"Dataset shape: {df.shape[0]:,} athletes √ó {df.shape[1]} columns\")\n",
        "print(f\"\\nColumns: {', '.join(df.columns.tolist())}\")\n",
        "print(f\"\\nFirst 5 rows:\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fWzcd5zXIPa"
      },
      "source": [
        "## Step 2: Load Data into BigQuery\n",
        "\n",
        "You've explored the data interactively ‚Äî now let's load it into BigQuery where you can run SQL analytics and train ML models. We'll load directly from Google Cloud Storage using BigQuery's native import, which is much faster than uploading from this notebook.\n",
        "\n",
        "First, set your project ID:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2rO0kJ3XIPb"
      },
      "source": [
        "# TODO: Replace with your lab project ID\n",
        "PROJECT_ID = \"YOUR_PROJECT_ID\"  # @param {type:\"string\"}\n",
        "\n",
        "print(f\"Project ID set to: {PROJECT_ID}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBFisd4QXIPb"
      },
      "source": [
        "### Load the athletes table\n",
        "\n",
        "This loads all 11,843 athletes with schema autodetection. The embedding column (3072-dimension vectors stored as JSON strings) makes this file large, so the load takes about a minute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0swDx5TbXIPb"
      },
      "source": [
        "!bq load --project_id=$PROJECT_ID \\\n",
        "  --source_format=CSV \\\n",
        "  --autodetect \\\n",
        "  --replace \\\n",
        "  team_usa.athletes \\\n",
        "  gs://class-demo/team-usa/final/team_usa_athletes.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLeVt7oqXIPb"
      },
      "source": [
        "### Load the results table\n",
        "\n",
        "The results table (24,198 competition records) is smaller and loads in seconds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFI2mS2mXIPb"
      },
      "source": [
        "!bq load --project_id=$PROJECT_ID \\\n",
        "  --source_format=CSV \\\n",
        "  --autodetect \\\n",
        "  --replace \\\n",
        "  team_usa.results \\\n",
        "  gs://class-demo/team-usa/final/team_usa_results.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YRDsBwUXIPb"
      },
      "source": [
        "> **Note on data types:** BigQuery's autodetect may type integer columns like `total_medals` and `games_count` as FLOAT64 (because some rows have NULL values). This is perfectly fine ‚Äî BQML handles FLOAT64 without issues, and you can CAST to INT64 in queries if you prefer cleaner display."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q14VilANXIPb"
      },
      "source": [
        "## Step 3: Verify the Load\n",
        "\n",
        "Let's confirm everything loaded correctly with a few quick queries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6fepoO_XIPb"
      },
      "source": [
        "### Row counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byThTH_8XIPb"
      },
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "# Check row counts\n",
        "for table in ['athletes', 'results']:\n",
        "    query = f\"SELECT COUNT(*) as row_count FROM `{PROJECT_ID}.team_usa.{table}`\"\n",
        "    result = client.query(query).result()\n",
        "    for row in result:\n",
        "        print(f\"team_usa.{table}: {row.row_count:,} rows\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPE2AoWTXIPc"
      },
      "source": [
        "You should see:\n",
        "- `team_usa.athletes`: **11,843** rows\n",
        "- `team_usa.results`: **24,198** rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc0QWVRWXIPc"
      },
      "source": [
        "### Top medalists ‚Äî who leads Team USA's all-time medal count?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoxUmpZ_XIPc"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT\n",
        "    name,\n",
        "    primary_sport,\n",
        "    games_type,\n",
        "    CAST(games_count AS INT64) AS games_count,\n",
        "    CAST(gold_count AS INT64) AS gold,\n",
        "    CAST(silver_count AS INT64) AS silver,\n",
        "    CAST(bronze_count AS INT64) AS bronze,\n",
        "    CAST(total_medals AS INT64) AS total_medals\n",
        "FROM `team_usa.athletes`\n",
        "WHERE total_medals > 0\n",
        "ORDER BY total_medals DESC\n",
        "LIMIT 15\n",
        "\"\"\"\n",
        "\n",
        "top_medalists = client.query(query).to_dataframe()\n",
        "print(\"üèÖ Team USA All-Time Top Medalists:\")\n",
        "top_medalists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0zrYoGuXIPc"
      },
      "source": [
        "### Olympic vs. Paralympic athlete counts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sql_engine: bigquery\n",
        "# output_variable: breakdown\n",
        "# start _sql\n",
        "_sql = \"\"\"\n",
        "SELECT\n",
        "    games_type,\n",
        "    COUNT(*) as athlete_count,\n",
        "    CAST(SUM(total_medals) AS INT64) as total_medals\n",
        "FROM `team_usa.athletes`\n",
        "GROUP BY games_type\n",
        "\"\"\" # end _sql\n",
        "from google.colab.sql import bigquery as _bqsqlcell\n",
        "breakdown = _bqsqlcell.run(_sql)\n",
        "breakdown"
      ],
      "metadata": {
        "colab_type": "sql",
        "tags": [
          "table-ref:qwiklabs-gcp-01-bafc8841fc77.team_usa.athletes"
        ],
        "id": "5XFPbQfxg-na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfK1_49EXIPc"
      },
      "source": [
        "---\n",
        "\n",
        "## ‚úÖ Data Loaded ‚Äî Ready for Analytics!\n",
        "\n",
        "You've loaded and explored 120 years of Team USA data. Here's what you accomplished:\n",
        "\n",
        "- **11,843 athletes** and **24,198 competition results** are now in BigQuery\n",
        "- You used the **Data Science Agent** to understand the data without writing analysis code\n",
        "- You've identified key patterns: the Olympic/Paralympic split, sport distributions, and data quality characteristics\n"
      ]
    }
  ]
}