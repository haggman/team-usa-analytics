{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "name": "team_usa_pipeline.ipynb"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e4f1783329914747a1f1abc6e79a7336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e7b0e153c304dbd97481325b03b089f",
              "IPY_MODEL_6382b2f7134d48a0b105a7c8a8b9fdd4",
              "IPY_MODEL_c81bbcc101894c23958b313167a1f50d"
            ],
            "layout": "IPY_MODEL_b40b362554704dc6b685224a616eb3e2"
          }
        },
        "3e7b0e153c304dbd97481325b03b089f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a2dce8d745b4c0ba77171dfc4fe0cf9",
            "placeholder": "​",
            "style": "IPY_MODEL_4147caea37b34acc9fb0471a8946cc11",
            "value": "Generating profiles: 100%"
          }
        },
        "6382b2f7134d48a0b105a7c8a8b9fdd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_747db6b4e2ab4d6b9cd990f66fa53b15",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3226e6a2c90d485d8feb4c444017d9be",
            "value": 1
          }
        },
        "c81bbcc101894c23958b313167a1f50d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_205ebf448084447e8de4fe70b56220b4",
            "placeholder": "​",
            "style": "IPY_MODEL_51b9c3927b0446fc869ad5ccb83ab711",
            "value": " 1/1 [00:08&lt;00:00,  8.28s/it]"
          }
        },
        "b40b362554704dc6b685224a616eb3e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a2dce8d745b4c0ba77171dfc4fe0cf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4147caea37b34acc9fb0471a8946cc11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "747db6b4e2ab4d6b9cd990f66fa53b15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3226e6a2c90d485d8feb4c444017d9be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "205ebf448084447e8de4fe70b56220b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51b9c3927b0446fc869ad5ccb83ab711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe3a10b144ef476e99e4750080e85623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13b3ef126f34442184eec574caf14e43",
              "IPY_MODEL_f95dbcc08f574df2972f089bfb4a2dd6",
              "IPY_MODEL_2ef8e9b9ab6945918597fc794083a75c"
            ],
            "layout": "IPY_MODEL_a5b37ffb23c745beab9da8f3ab4cde17"
          }
        },
        "13b3ef126f34442184eec574caf14e43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d9cb69ad6f24c48b112c3865f74f91c",
            "placeholder": "​",
            "style": "IPY_MODEL_bccc58f467074529b22a5bda0a4a7f0a",
            "value": "Generating embeddings: 100%"
          }
        },
        "f95dbcc08f574df2972f089bfb4a2dd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e2e6309f0b74307962c2d3a72e2a91e",
            "max": 11007,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2964373babba4034a151b8d3a8a0247e",
            "value": 11007
          }
        },
        "2ef8e9b9ab6945918597fc794083a75c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b1608ba455e4796b4f17e1ea2528654",
            "placeholder": "​",
            "style": "IPY_MODEL_f4806c6a8d064ebb9c999097522c0d89",
            "value": " 11007/11007 [40:42&lt;00:00,  1.32s/it]"
          }
        },
        "a5b37ffb23c745beab9da8f3ab4cde17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d9cb69ad6f24c48b112c3865f74f91c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bccc58f467074529b22a5bda0a4a7f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e2e6309f0b74307962c2d3a72e2a91e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2964373babba4034a151b8d3a8a0247e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b1608ba455e4796b4f17e1ea2528654": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4806c6a8d064ebb9c999097522c0d89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9SmpLxuyneZ"
      },
      "source": [
        "# Team USA Olympic & Paralympic Data Pipeline v2\n",
        "### From Raw CSVs → Unified, Enriched, BigQuery-Ready Tables\n",
        "\n",
        "**Purpose:** Acquire, clean, merge, and enrich Olympic + Paralympic data for every Team USA athlete across all available Games years (1896–2024).\n",
        "\n",
        "**Output Tables:**\n",
        "- `team_usa_athletes` — One row per unique athlete (identity, career stats, AI-generated profiles, vector embeddings)\n",
        "- `team_usa_results` — One row per athlete × event × Games (the fact table)\n",
        "\n",
        "**Final Schema (Athletes — 19 columns):**\n",
        "\n",
        "| Column | Type | Description |\n",
        "|--------|------|-------------|\n",
        "| `athlete_id` | UUID5 | Deterministic ID from name + first_games_year + primary_sport |\n",
        "| `name` | VARCHAR | Full name (Gemini-verified where possible) |\n",
        "| `gender` | VARCHAR | Male / Female / NULL |\n",
        "| `birth_date` | DATE | Sparse for Paralympic athletes |\n",
        "| `games_type` | VARCHAR | Olympic / Paralympic |\n",
        "| `games_season` | VARCHAR | Summer / Winter / Both |\n",
        "| `primary_sport` | VARCHAR | Normalized sport name |\n",
        "| `classification_code` | VARCHAR | Paralympic only (e.g., T54, S6, B1) |\n",
        "| `height_cm` | FLOAT | Physical height (Olympic-heavy coverage) |\n",
        "| `weight_kg` | FLOAT | Physical weight (Olympic-heavy coverage) |\n",
        "| `first_games_year` | INT | First Games appearance |\n",
        "| `last_games_year` | INT | Most recent Games appearance |\n",
        "| `games_count` | INT | Number of Games appearances |\n",
        "| `gold_count` | INT | Career gold medals |\n",
        "| `silver_count` | INT | Career silver medals |\n",
        "| `bronze_count` | INT | Career bronze medals |\n",
        "| `total_medals` | INT | Career total medals |\n",
        "| `profile_summary` | TEXT | AI-generated 2-paragraph bio (absorbs all bio fields) |\n",
        "| `embedding` | VECTOR(3072) | Gemini embedding for similarity search |\n",
        "\n",
        "**Pipeline Phases:**\n",
        "- **Phase 1:** Setup & data acquisition\n",
        "- **Phase 2:** Olympic athlete backbone\n",
        "- **Phase 3:** Paralympic athlete backbone\n",
        "- **Phase 4:** Unification (merge, deduplicate, normalize)\n",
        "- **Phase 5:** Results table & career stat backfill\n",
        "- **Phase 6:** Gemini enrichment (name verification + profiles + embeddings)\n",
        "- **Phase 7:** Validation & export\n",
        "\n",
        "**Data sources:** `gs://class-demo/team-usa/raw/`\n",
        "**Final output:** `gs://class-demo/team-usa/final/`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77_pkN6Fyneb"
      },
      "source": [
        "---\n",
        "## Phase 1: Setup & Data Acquisition\n",
        "\n",
        "Configure the environment, download raw CSVs from GCS, and build two reference tables we'll use throughout the pipeline:\n",
        "\n",
        "1. **Games Lookup** — Every Olympic and Paralympic Games mapped to year, city, season, and type. This gives us reliable `games_season` derivation and richer context for Gemini prompts later.\n",
        "2. **File Inventory** — Catalog of every CSV we downloaded, with row counts and sizes.\n",
        "\n",
        "**Sources:** `gs://class-demo/team-usa/raw/` (4 dataset folders, ~15 CSV files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxCQHI_Pyneb",
        "outputId": "b7f20137-3203-44aa-8921-f1fc4cb15630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project:    qwiklabs-gcp-01-bafc8841fc77\n",
            "Region:     us-central1\n",
            "Raw data:   gs://class-demo/team-usa/raw\n",
            "Final out:  gs://class-demo/team-usa/final\n",
            "Local dir:  /tmp/olympic-data\n"
          ]
        }
      ],
      "source": [
        "# ── Phase 1, Step 1: Environment & Configuration ─────────────────\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "import json\n",
        "import uuid\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration\n",
        "BUCKET = 'gs://class-demo/team-usa'\n",
        "RAW_PATH = f'{BUCKET}/raw'\n",
        "FINAL_PATH = f'{BUCKET}/final'\n",
        "LOCAL_DIR = '/tmp/olympic-data'\n",
        "\n",
        "os.makedirs(LOCAL_DIR, exist_ok=True)\n",
        "\n",
        "PROJECT_ID = \"qwiklabs-gcp-01-bafc8841fc77\"  # @param {type:\"string\"}\n",
        "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "print(f'Project:    {PROJECT_ID}')\n",
        "print(f'Region:     {REGION}')\n",
        "print(f'Raw data:   {RAW_PATH}')\n",
        "print(f'Final out:  {FINAL_PATH}')\n",
        "print(f'Local dir:  {LOCAL_DIR}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOENcKvyynec",
        "outputId": "8b960b52-1602-471b-cc9d-39192bc422a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Games lookup entries: 85\n",
            "  Olympic:    55\n",
            "  Paralympic: 30\n",
            "\n",
            "Spot checks:\n",
            "  1996 Olympic → ('Atlanta', 'Summer')\n",
            "  2020 Paralympic → ('Tokyo', 'Summer')\n",
            "  1992 Olympic Winter → ('Albertville', 'Winter')\n",
            "  2024 Olympic → ('Paris', 'Summer')\n"
          ]
        }
      ],
      "source": [
        "# ── Phase 1, Step 2: Games Lookup Table ───────────────────────────\n",
        "# Every Olympic and Paralympic Games with year, city, season, and type.\n",
        "# Used for games_season derivation and Gemini prompt context.\n",
        "\n",
        "GAMES_LOOKUP = {\n",
        "    # ── Olympic Summer ──\n",
        "    (1896, 'Olympic'): ('Athens', 'Summer'),\n",
        "    (1900, 'Olympic'): ('Paris', 'Summer'),\n",
        "    (1904, 'Olympic'): ('St. Louis', 'Summer'),\n",
        "    (1906, 'Olympic'): ('Athens', 'Summer'),        # Intercalated\n",
        "    (1908, 'Olympic'): ('London', 'Summer'),\n",
        "    (1912, 'Olympic'): ('Stockholm', 'Summer'),\n",
        "    (1920, 'Olympic'): ('Antwerp', 'Summer'),\n",
        "    (1924, 'Olympic'): ('Paris', 'Summer'),\n",
        "    (1928, 'Olympic'): ('Amsterdam', 'Summer'),\n",
        "    (1932, 'Olympic'): ('Los Angeles', 'Summer'),\n",
        "    (1936, 'Olympic'): ('Berlin', 'Summer'),\n",
        "    (1948, 'Olympic'): ('London', 'Summer'),\n",
        "    (1952, 'Olympic'): ('Helsinki', 'Summer'),\n",
        "    (1956, 'Olympic'): ('Melbourne', 'Summer'),\n",
        "    (1960, 'Olympic'): ('Rome', 'Summer'),\n",
        "    (1964, 'Olympic'): ('Tokyo', 'Summer'),\n",
        "    (1968, 'Olympic'): ('Mexico City', 'Summer'),\n",
        "    (1972, 'Olympic'): ('Munich', 'Summer'),\n",
        "    (1976, 'Olympic'): ('Montreal', 'Summer'),\n",
        "    (1980, 'Olympic'): ('Moscow', 'Summer'),\n",
        "    (1984, 'Olympic'): ('Los Angeles', 'Summer'),\n",
        "    (1988, 'Olympic'): ('Seoul', 'Summer'),\n",
        "    (1992, 'Olympic'): ('Barcelona', 'Summer'),\n",
        "    (1996, 'Olympic'): ('Atlanta', 'Summer'),\n",
        "    (2000, 'Olympic'): ('Sydney', 'Summer'),\n",
        "    (2004, 'Olympic'): ('Athens', 'Summer'),\n",
        "    (2008, 'Olympic'): ('Beijing', 'Summer'),\n",
        "    (2012, 'Olympic'): ('London', 'Summer'),\n",
        "    (2016, 'Olympic'): ('Rio de Janeiro', 'Summer'),\n",
        "    (2020, 'Olympic'): ('Tokyo', 'Summer'),\n",
        "    (2024, 'Olympic'): ('Paris', 'Summer'),\n",
        "\n",
        "    # ── Olympic Winter (pre-1994 uses 3-tuple to disambiguate from Summer) ──\n",
        "    (1924, 'Olympic', 'Winter'): ('Chamonix', 'Winter'),\n",
        "    (1928, 'Olympic', 'Winter'): ('St. Moritz', 'Winter'),\n",
        "    (1932, 'Olympic', 'Winter'): ('Lake Placid', 'Winter'),\n",
        "    (1936, 'Olympic', 'Winter'): ('Garmisch-Partenkirchen', 'Winter'),\n",
        "    (1948, 'Olympic', 'Winter'): ('St. Moritz', 'Winter'),\n",
        "    (1952, 'Olympic', 'Winter'): ('Oslo', 'Winter'),\n",
        "    (1956, 'Olympic', 'Winter'): ('Cortina d\\'Ampezzo', 'Winter'),\n",
        "    (1960, 'Olympic', 'Winter'): ('Squaw Valley', 'Winter'),\n",
        "    (1964, 'Olympic', 'Winter'): ('Innsbruck', 'Winter'),\n",
        "    (1968, 'Olympic', 'Winter'): ('Grenoble', 'Winter'),\n",
        "    (1972, 'Olympic', 'Winter'): ('Sapporo', 'Winter'),\n",
        "    (1976, 'Olympic', 'Winter'): ('Innsbruck', 'Winter'),\n",
        "    (1980, 'Olympic', 'Winter'): ('Lake Placid', 'Winter'),\n",
        "    (1984, 'Olympic', 'Winter'): ('Sarajevo', 'Winter'),\n",
        "    (1988, 'Olympic', 'Winter'): ('Calgary', 'Winter'),\n",
        "    (1992, 'Olympic', 'Winter'): ('Albertville', 'Winter'),\n",
        "    # Post-1994: Winter on own cycle, 2-tuple keys work fine\n",
        "    (1994, 'Olympic'): ('Lillehammer', 'Winter'),\n",
        "    (1998, 'Olympic'): ('Nagano', 'Winter'),\n",
        "    (2002, 'Olympic'): ('Salt Lake City', 'Winter'),\n",
        "    (2006, 'Olympic'): ('Turin', 'Winter'),\n",
        "    (2010, 'Olympic'): ('Vancouver', 'Winter'),\n",
        "    (2014, 'Olympic'): ('Sochi', 'Winter'),\n",
        "    (2018, 'Olympic'): ('PyeongChang', 'Winter'),\n",
        "    (2022, 'Olympic'): ('Beijing', 'Winter'),\n",
        "\n",
        "    # ── Paralympic Summer ──\n",
        "    (1960, 'Paralympic'): ('Rome', 'Summer'),\n",
        "    (1964, 'Paralympic'): ('Tokyo', 'Summer'),\n",
        "    (1968, 'Paralympic'): ('Tel Aviv', 'Summer'),\n",
        "    (1972, 'Paralympic'): ('Heidelberg', 'Summer'),\n",
        "    (1976, 'Paralympic'): ('Toronto', 'Summer'),\n",
        "    (1980, 'Paralympic'): ('Arnhem', 'Summer'),\n",
        "    (1984, 'Paralympic'): ('Stoke Mandeville/New York', 'Summer'),\n",
        "    (1988, 'Paralympic'): ('Seoul', 'Summer'),\n",
        "    (1992, 'Paralympic'): ('Barcelona', 'Summer'),\n",
        "    (1996, 'Paralympic'): ('Atlanta', 'Summer'),\n",
        "    (2000, 'Paralympic'): ('Sydney', 'Summer'),\n",
        "    (2004, 'Paralympic'): ('Athens', 'Summer'),\n",
        "    (2008, 'Paralympic'): ('Beijing', 'Summer'),\n",
        "    (2012, 'Paralympic'): ('London', 'Summer'),\n",
        "    (2016, 'Paralympic'): ('Rio de Janeiro', 'Summer'),\n",
        "    (2020, 'Paralympic'): ('Tokyo', 'Summer'),\n",
        "    (2024, 'Paralympic'): ('Paris', 'Summer'),\n",
        "\n",
        "    # ── Paralympic Winter (pre-1994 uses 3-tuple) ──\n",
        "    (1976, 'Paralympic', 'Winter'): ('Örnsköldsvik', 'Winter'),\n",
        "    (1980, 'Paralympic', 'Winter'): ('Geilo', 'Winter'),\n",
        "    (1984, 'Paralympic', 'Winter'): ('Innsbruck', 'Winter'),\n",
        "    (1988, 'Paralympic', 'Winter'): ('Innsbruck', 'Winter'),\n",
        "    (1992, 'Paralympic', 'Winter'): ('Albertville', 'Winter'),\n",
        "    # Post-1994: own cycle\n",
        "    (1994, 'Paralympic'): ('Lillehammer', 'Winter'),\n",
        "    (1998, 'Paralympic'): ('Nagano', 'Winter'),\n",
        "    (2002, 'Paralympic'): ('Salt Lake City', 'Winter'),\n",
        "    (2006, 'Paralympic'): ('Turin', 'Winter'),\n",
        "    (2010, 'Paralympic'): ('Vancouver', 'Winter'),\n",
        "    (2014, 'Paralympic'): ('Sochi', 'Winter'),\n",
        "    (2018, 'Paralympic'): ('PyeongChang', 'Winter'),\n",
        "    (2022, 'Paralympic'): ('Beijing', 'Winter'),\n",
        "}\n",
        "\n",
        "\n",
        "def lookup_games(year, games_type, season_hint=None):\n",
        "    \"\"\"Look up city and season for a given Games year and type.\n",
        "\n",
        "    For years where Summer and Winter overlap (pre-1994), use season_hint\n",
        "    or the 3-tuple key to disambiguate.\n",
        "    \"\"\"\n",
        "    if season_hint == 'Winter':\n",
        "        key3 = (year, games_type, 'Winter')\n",
        "        if key3 in GAMES_LOOKUP:\n",
        "            return GAMES_LOOKUP[key3]\n",
        "    key2 = (year, games_type)\n",
        "    if key2 in GAMES_LOOKUP:\n",
        "        return GAMES_LOOKUP[key2]\n",
        "    return (None, None)\n",
        "\n",
        "\n",
        "def get_season(year, games_type, season_hint=None):\n",
        "    \"\"\"Get just the season for a year+type.\"\"\"\n",
        "    _, season = lookup_games(year, games_type, season_hint)\n",
        "    return season\n",
        "\n",
        "\n",
        "# Quick validation\n",
        "print(f'Games lookup entries: {len(GAMES_LOOKUP)}')\n",
        "print(f'  Olympic:    {sum(1 for k in GAMES_LOOKUP if k[1] == \"Olympic\")}')\n",
        "print(f'  Paralympic: {sum(1 for k in GAMES_LOOKUP if k[1] == \"Paralympic\")}')\n",
        "print(f'\\nSpot checks:')\n",
        "print(f'  1996 Olympic → {lookup_games(1996, \"Olympic\")}')\n",
        "print(f'  2020 Paralympic → {lookup_games(2020, \"Paralympic\")}')\n",
        "print(f'  1992 Olympic Winter → {lookup_games(1992, \"Olympic\", \"Winter\")}')\n",
        "print(f'  2024 Olympic → {lookup_games(2024, \"Olympic\")}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ifh_5TDynec",
        "outputId": "5d2b9937-1dab-43e7-895a-f7f7d48ae1ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://class-demo/team-usa/raw/olympic-120years/noc_regions.csv...\n",
            "/ [0 files][    0.0 B/  3.5 KiB]                                                \rCopying gs://class-demo/team-usa/raw/olympic-beijing2022/athletes.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-120years/athlete_events.csv...\n",
            "/ [0 files][    0.0 B/562.3 KiB]                                                \r/ [0 files][    0.0 B/ 40.1 MiB]                                                \rCopying gs://class-demo/team-usa/raw/olympic-beijing2022/coaches.csv...\n",
            "/ [0 files][    0.0 B/ 40.1 MiB]                                                \rCopying gs://class-demo/team-usa/raw/olympic-beijing2022/curling_results.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-beijing2022/medals_total.csv...\n",
            "/ [0 files][    0.0 B/ 40.1 MiB]                                                \r/ [0 files][    0.0 B/ 40.2 MiB]                                                \rCopying gs://class-demo/team-usa/raw/olympic-beijing2022/technical_officials.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-beijing2022/hockey_players_stats.csv...\n",
            "/ [0 files][    0.0 B/ 40.2 MiB]                                                \r/ [0 files][    0.0 B/ 40.6 MiB]                                                \rCopying gs://class-demo/team-usa/raw/olympic-beijing2022/medals.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-beijing2022/entries_discipline.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-keithgalli/bios_locs.csv...\n",
            "/ [0 files][    0.0 B/ 40.7 MiB]                                                \rCopying gs://class-demo/team-usa/raw/olympic-keithgalli/populations.csv...\n",
            "/ [0 files][    0.0 B/ 52.7 MiB]                                                \rCopying gs://class-demo/team-usa/raw/olympic-keithgalli/bios.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-keithgalli/noc_regions.csv...\n",
            "/ [0 files][    0.0 B/ 52.9 MiB]                                                \rCopying gs://class-demo/team-usa/raw/olympic-beijing2022/hockey_results.csv...\n",
            "/ [0 files][    0.0 B/ 52.9 MiB]                                                \rCopying gs://class-demo/team-usa/raw/olympic-beijing2022/events.csv...\n",
            "/ [0 files][    0.0 B/ 79.6 MiB]                                                \r/ [0 files][    0.0 B/ 79.6 MiB]                                                \r/ [0 files][    0.0 B/ 79.6 MiB]                                                \r/ [0 files][    0.0 B/ 79.7 MiB]                                                \rCopying gs://class-demo/team-usa/raw/olympic-paris2024/athletes.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/events.csv...\n",
            "/ [0 files][    0.0 B/ 86.6 MiB]                                                \rCopying gs://class-demo/team-usa/raw/olympic-keithgalli/results.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/coaches.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/medallists.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/medals.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/medals_total.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/nocs.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/3x3 Basketball.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Archery.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Artistic Gymnastics.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Artistic Swimming.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Athletics.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Badminton.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Basketball.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Beach Volleyball.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Boxing.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Breaking.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Canoe Slalom.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Canoe Sprint.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Cycling BMX Freestyle.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Cycling BMX Racing.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Cycling Mountain Bike.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Cycling Track.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Cycling Road.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Diving.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Equestrian.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Fencing.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Football.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Golf.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Handball.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Hockey.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Judo.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Marathon Swimming.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Modern Pentathlon.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Rhythmic Gymnastics.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Rowing.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Rugby Sevens.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Sailing.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Shooting.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Skateboarding.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Sport Climbing.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Surfing.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Swimming.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Table Tennis.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Taekwondo.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Tennis.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Volleyball.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Trampoline Gymnastics.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Triathlon.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Water Polo.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Weightlifting.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/results/Wrestling.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/schedules.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/teams.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/schedules_preliminary.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/technical_officials.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/torch_route.csv...\n",
            "Copying gs://class-demo/team-usa/raw/olympic-paris2024/venues.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-katiepress/medal_athlete.RDS...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-katiepress/medal_standings.RDS...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-katiepress/medal_athlete.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-katiepress/medal_standings.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2020_Tokyo/coaches.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2020_Tokyo/athletes.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2020_Tokyo/medals.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2020_Tokyo/medals_total.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2020_Tokyo/technical_officials.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/athletes.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/coaches.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/events_preliminary.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/medallists.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/medals.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/medals_total.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/nocs.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Blind Football.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Boccia.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Goalball.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Para Athletics.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Para Archery.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Para Badminton.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Para Canoe.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Para Cycling Road.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Para Equestrian.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Para Cycling Track.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Para Judo.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Para Powerlifting.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Para Rowing.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Para Swimming.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Para Table Tennis.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Para Taekwondo.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Para Triathlon.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Shooting Para Sport.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Sitting Volleyball.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Wheelchair Basketball.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Wheelchair Fencing.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Wheelchair Rugby.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/results/Wheelchair Tennis.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/schedules.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/teams.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/schedules_preliminary.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/torch_route.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/sports.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/venues.csv...\n",
            "Copying gs://class-demo/team-usa/raw/paralympic-piterfm/2024_Paris/technical_officials.csv...\n",
            "| [121/121 files][142.0 MiB/142.0 MiB] 100% Done                                \n",
            "Operation completed over 121 objects/142.0 MiB.                                  \n",
            "\n",
            "Total CSV files downloaded: 119\n"
          ]
        }
      ],
      "source": [
        "# ── Phase 1, Step 3: Download Raw Data from GCS ──────────────────\n",
        "\n",
        "!gsutil -m cp -r {RAW_PATH}/* {LOCAL_DIR}/\n",
        "\n",
        "# Count what we got\n",
        "csv_count = !find {LOCAL_DIR} -name \"*.csv\" | wc -l\n",
        "print(f'\\nTotal CSV files downloaded: {csv_count[0].strip()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Itcx_ZjPynec",
        "outputId": "b6b7f8f6-ac4e-473d-a2f8-006878d83f99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FILES BY DATASET:\n",
            "\n",
            "olympic-120years/ (2 files, 39.6 MB total)\n",
            "  athlete_events.csv                               39.58 MB\n",
            "  noc_regions.csv                                   0.00 MB\n",
            "\n",
            "olympic-beijing2022/ (10 files, 1.3 MB total)\n",
            "  athletes.csv                                      0.55 MB\n",
            "  coaches.csv                                       0.01 MB\n",
            "  curling_results.csv                               0.03 MB\n",
            "  entries_discipline.csv                            0.00 MB\n",
            "  events.csv                                        0.11 MB\n",
            "  hockey_players_stats.csv                          0.43 MB\n",
            "  hockey_results.csv                                0.01 MB\n",
            "  medals.csv                                        0.12 MB\n",
            "  medals_total.csv                                  0.00 MB\n",
            "  technical_officials.csv                           0.01 MB\n",
            "\n",
            "olympic-keithgalli/ (5 files, 70.3 MB total)\n",
            "  bios.csv                                         26.67 MB\n",
            "  bios_locs.csv                                    11.99 MB\n",
            "  noc_regions.csv                                   0.00 MB\n",
            "  populations.csv                                   0.17 MB\n",
            "  results.csv                                      31.51 MB\n",
            "\n",
            "olympic-paris2024/ (58 files, 14.3 MB total)\n",
            "  athletes.csv                                      6.89 MB\n",
            "  coaches.csv                                       0.09 MB\n",
            "  events.csv                                        0.03 MB\n",
            "  medallists.csv                                    0.53 MB\n",
            "  medals.csv                                        0.17 MB\n",
            "  medals_total.csv                                  0.00 MB\n",
            "  nocs.csv                                          0.01 MB\n",
            "  schedules.csv                                     0.92 MB\n",
            "  schedules_preliminary.csv                         0.36 MB\n",
            "  teams.csv                                         0.42 MB\n",
            "  technical_officials.csv                           0.09 MB\n",
            "  torch_route.csv                                   0.01 MB\n",
            "  venues.csv                                        0.01 MB\n",
            "  3x3 Basketball.csv                                0.03 MB\n",
            "  Archery.csv                                       0.11 MB\n",
            "  Artistic Gymnastics.csv                           0.05 MB\n",
            "  Artistic Swimming.csv                             0.02 MB\n",
            "  Athletics.csv                                     0.76 MB\n",
            "  Badminton.csv                                     0.10 MB\n",
            "  Basketball.csv                                    0.02 MB\n",
            "  Beach Volleyball.csv                              0.05 MB\n",
            "  Boxing.csv                                        0.10 MB\n",
            "  Breaking.csv                                      0.03 MB\n",
            "  Canoe Slalom.csv                                  0.14 MB\n",
            "  Canoe Sprint.csv                                  0.17 MB\n",
            "  Cycling BMX Freestyle.csv                         0.01 MB\n",
            "  Cycling BMX Racing.csv                            0.06 MB\n",
            "  Cycling Mountain Bike.csv                         0.02 MB\n",
            "  Cycling Road.csv                                  0.06 MB\n",
            "  Cycling Track.csv                                 0.18 MB\n",
            "  Diving.csv                                        0.06 MB\n",
            "  Equestrian.csv                                    0.13 MB\n",
            "  Fencing.csv                                       0.12 MB\n",
            "  Football.csv                                      0.02 MB\n",
            "  Golf.csv                                          0.13 MB\n",
            "  Handball.csv                                      0.03 MB\n",
            "  Hockey.csv                                        0.03 MB\n",
            "  Judo.csv                                          0.19 MB\n",
            "  Marathon Swimming.csv                             0.01 MB\n",
            "  Modern Pentathlon.csv                             0.14 MB\n",
            "  Rhythmic Gymnastics.csv                           0.05 MB\n",
            "  Rowing.csv                                        0.15 MB\n",
            "  Rugby Sevens.csv                                  0.03 MB\n",
            "  Sailing.csv                                       0.64 MB\n",
            "  Shooting.csv                                      0.19 MB\n",
            "  Skateboarding.csv                                 0.02 MB\n",
            "  Sport Climbing.csv                                0.05 MB\n",
            "  Surfing.csv                                       0.03 MB\n",
            "  Swimming.csv                                      0.38 MB\n",
            "  Table Tennis.csv                                  0.08 MB\n",
            "  Taekwondo.csv                                     0.06 MB\n",
            "  Tennis.csv                                        0.09 MB\n",
            "  Trampoline Gymnastics.csv                         0.01 MB\n",
            "  Triathlon.csv                                     0.03 MB\n",
            "  Volleyball.csv                                    0.02 MB\n",
            "  Water Polo.csv                                    0.03 MB\n",
            "  Weightlifting.csv                                 0.02 MB\n",
            "  Wrestling.csv                                     0.15 MB\n",
            "\n",
            "paralympic-katiepress/ (2 files, 6.2 MB total)\n",
            "  medal_athlete.csv                                 5.96 MB\n",
            "  medal_standings.csv                               0.26 MB\n",
            "\n",
            "paralympic-piterfm/ (42 files, 9.7 MB total)\n",
            "  athletes.csv                                      0.81 MB\n",
            "  coaches.csv                                       0.01 MB\n",
            "  medals.csv                                        0.40 MB\n",
            "  medals_total.csv                                  0.00 MB\n",
            "  technical_officials.csv                           0.03 MB\n",
            "  athletes.csv                                      3.42 MB\n",
            "  coaches.csv                                       0.03 MB\n",
            "  events_preliminary.csv                            0.06 MB\n",
            "  medallists.csv                                    0.54 MB\n",
            "  medals.csv                                        0.34 MB\n",
            "  medals_total.csv                                  0.00 MB\n",
            "  nocs.csv                                          0.01 MB\n",
            "  schedules.csv                                     0.79 MB\n",
            "  schedules_preliminary.csv                         0.28 MB\n",
            "  sports.csv                                        0.00 MB\n",
            "  teams.csv                                         0.12 MB\n",
            "  technical_officials.csv                           0.04 MB\n",
            "  torch_route.csv                                   0.01 MB\n",
            "  venues.csv                                        0.00 MB\n",
            "  Blind Football.csv                                0.01 MB\n",
            "  Boccia.csv                                        0.15 MB\n",
            "  Goalball.csv                                      0.02 MB\n",
            "  Para Archery.csv                                  0.13 MB\n",
            "  Para Athletics.csv                                0.52 MB\n",
            "  Para Badminton.csv                                0.13 MB\n",
            "  Para Canoe.csv                                    0.08 MB\n",
            "  Para Cycling Road.csv                             0.10 MB\n",
            "  Para Cycling Track.csv                            0.07 MB\n",
            "  Para Equestrian.csv                               0.03 MB\n",
            "  Para Judo.csv                                     0.09 MB\n",
            "  Para Powerlifting.csv                             0.04 MB\n",
            "  Para Rowing.csv                                   0.04 MB\n",
            "  Para Swimming.csv                                 0.69 MB\n",
            "  Para Table Tennis.csv                             0.18 MB\n",
            "  Para Taekwondo.csv                                0.07 MB\n",
            "  Para Triathlon.csv                                0.03 MB\n",
            "  Shooting Para Sport.csv                           0.13 MB\n",
            "  Sitting Volleyball.csv                            0.02 MB\n",
            "  Wheelchair Basketball.csv                         0.02 MB\n",
            "  Wheelchair Fencing.csv                            0.18 MB\n",
            "  Wheelchair Rugby.csv                              0.01 MB\n",
            "  Wheelchair Tennis.csv                             0.06 MB\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ── Phase 1, Step 4: File Inventory ───────────────────────────────\n",
        "\n",
        "file_inventory = []\n",
        "\n",
        "for root, dirs, files in os.walk(LOCAL_DIR):\n",
        "    dirs[:] = [d for d in dirs if d != '.git']\n",
        "    for f in sorted(files):\n",
        "        if f.endswith('.csv'):\n",
        "            full_path = os.path.join(root, f)\n",
        "            size_mb = os.path.getsize(full_path) / (1024 * 1024)\n",
        "            rel_path = full_path.replace(LOCAL_DIR + '/', '')\n",
        "            dataset = rel_path.split('/')[0]\n",
        "            file_inventory.append({\n",
        "                'dataset': dataset,\n",
        "                'file': f,\n",
        "                'rel_path': rel_path,\n",
        "                'full_path': full_path,\n",
        "                'size_mb': size_mb\n",
        "            })\n",
        "\n",
        "inv_df = pd.DataFrame(file_inventory)\n",
        "\n",
        "print('FILES BY DATASET:\\n')\n",
        "for dataset, group in inv_df.groupby('dataset'):\n",
        "    total_mb = group['size_mb'].sum()\n",
        "    print(f'{dataset}/ ({len(group)} files, {total_mb:.1f} MB total)')\n",
        "    for _, row in group.iterrows():\n",
        "        print(f'  {row[\"file\"]:45s} {row[\"size_mb\"]:8.2f} MB')\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RySAFt1pynec",
        "outputId": "4819e631-2f31-4549-8b5d-88f4e67d64c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Shared utilities loaded\n",
            "  norm_name(\"John•Smith\") → \"JOHN SMITH\"\n",
            "  clean_name_mechanical(\"MCCARTHY•john\") → \"McCarthy John\"\n",
            "  flip_name_order(\"SMITH John\") → \"John SMITH\"\n",
            "  extract_classification(\"Men's 100m T54\") → \"T54\"\n"
          ]
        }
      ],
      "source": [
        "# ── Phase 1, Step 5: Shared Utilities ─────────────────────────────\n",
        "# Name normalization and cleanup functions used across all phases.\n",
        "\n",
        "\n",
        "def norm_name(n):\n",
        "    \"\"\"Normalize a name for matching: uppercase, sort tokens, strip non-alpha.\n",
        "    Handles bullets (•), dots, hyphens consistently.\"\"\"\n",
        "    if pd.isna(n):\n",
        "        return ''\n",
        "    s = str(n).replace('•', ' ').replace('.', ' ').replace('-', ' ')\n",
        "    s = re.sub(r'[^A-Za-z\\s]', '', s).upper().strip()\n",
        "    tokens = sorted(s.split())\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "\n",
        "def clean_name_mechanical(n):\n",
        "    \"\"\"Mechanical name cleanup: bullets→spaces, smart title case.\n",
        "    Handles Mc/O' prefixes and Roman numeral suffixes.\"\"\"\n",
        "    if pd.isna(n):\n",
        "        return None\n",
        "    s = str(n).strip()\n",
        "\n",
        "    # Bullets and dots as separators\n",
        "    s = s.replace('•', ' ')\n",
        "\n",
        "    # Collapse multiple spaces\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "\n",
        "    # Smart title case\n",
        "    parts = []\n",
        "    for word in s.split():\n",
        "        w = word.strip()\n",
        "        if not w:\n",
        "            continue\n",
        "        w_upper = w.upper()\n",
        "\n",
        "        # Roman numerals\n",
        "        if re.match(r'^(I{1,3}|IV|V|VI{0,3}|IX|X)$', w_upper):\n",
        "            parts.append(w_upper)\n",
        "        # Mc prefix\n",
        "        elif w_upper.startswith('MC') and len(w) > 2:\n",
        "            parts.append('Mc' + w[2:].title())\n",
        "        # O' prefix\n",
        "        elif w_upper.startswith(\"O'\") and len(w) > 2:\n",
        "            parts.append(\"O'\" + w[2:].title())\n",
        "        else:\n",
        "            parts.append(w.title())\n",
        "\n",
        "    return ' '.join(parts) if parts else None\n",
        "\n",
        "\n",
        "def flip_name_order(n):\n",
        "    \"\"\"Flip 'LAST First' → 'First Last' for two-word names only.\n",
        "    Leaves 3+ word names untouched to avoid compound-name errors.\"\"\"\n",
        "    if pd.isna(n):\n",
        "        return n\n",
        "    parts = str(n).strip().split()\n",
        "    if len(parts) == 2:\n",
        "        # If first part is all-caps and second is not, likely LAST First\n",
        "        if parts[0].isupper() and not parts[1].isupper():\n",
        "            return f'{parts[1]} {parts[0]}'\n",
        "    return str(n).strip()\n",
        "\n",
        "\n",
        "def is_abbreviated(n):\n",
        "    \"\"\"Check if a name is abbreviated (e.g., 'SMITH J' or 'JONES A.').\"\"\"\n",
        "    if pd.isna(n):\n",
        "        return True\n",
        "    parts = str(n).strip().split()\n",
        "    if len(parts) < 2:\n",
        "        return True\n",
        "    for p in parts:\n",
        "        cleaned = p.replace('.', '')\n",
        "        if len(cleaned) == 1:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "# Classification code extraction for Paralympic athletes\n",
        "CLASSIFICATION_PATTERN = re.compile(\n",
        "    r'\\b('\n",
        "    r'[TF][1-5]\\d'          # Track/Field: T11-T54, F11-F57\n",
        "    r'|S[1-9]\\d?'           # Swimming: S1-S14\n",
        "    r'|S[BM]\\d{1,2}'        # SB1-SB14, SM1-SM14\n",
        "    r'|B[1-3]'              # Blind: B1-B3\n",
        "    r'|BC[1-4]'             # Boccia: BC1-BC4\n",
        "    r'|LW\\d{1,2}'          # Skiing: LW1-LW12\n",
        "    r'|H[1-5]'              # Cycling handcycle: H1-H5\n",
        "    r'|C[1-5]'              # Cycling: C1-C5\n",
        "    r'|PT[1-5]'             # Para triathlon: PT1-PT5\n",
        "    r'|SH[12]'              # Shooting: SH1-SH2\n",
        "    r'|SU[1-5]'             # Standing upper: SU5\n",
        "    r'|TT\\d{1,2}'          # Table tennis: TT1-TT11\n",
        "    r'|KL[1-3]'             # Kayak: KL1-KL3\n",
        "    r'|VL[1-3]'             # Va'a: VL1-VL3\n",
        "    r')\\b'\n",
        ")\n",
        "\n",
        "\n",
        "def extract_classification(text):\n",
        "    \"\"\"Extract Paralympic classification code from an event string.\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return None\n",
        "    matches = CLASSIFICATION_PATTERN.findall(str(text))\n",
        "    return matches[0] if matches else None\n",
        "\n",
        "\n",
        "def most_common(s):\n",
        "    \"\"\"Return the mode of a Series (for groupby aggregation).\"\"\"\n",
        "    mode = s.dropna().mode()\n",
        "    return mode.iloc[0] if len(mode) > 0 else None\n",
        "\n",
        "\n",
        "# Verify\n",
        "print('✅ Shared utilities loaded')\n",
        "print(f'  norm_name(\"John•Smith\") → \"{norm_name(\"John•Smith\")}\"')\n",
        "print(f'  clean_name_mechanical(\"MCCARTHY•john\") → \"{clean_name_mechanical(\"MCCARTHY•john\")}\"')\n",
        "print(f'  flip_name_order(\"SMITH John\") → \"{flip_name_order(\"SMITH John\")}\"')\n",
        "print(f'  extract_classification(\"Men\\'s 100m T54\") → \"{extract_classification(\"Men\\'s 100m T54\")}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnEe40Kryned",
        "outputId": "517ba1d0-85b3-438a-9624-bb5b57058234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "PHASE 1 QC: SETUP & DATA ACQUISITION\n",
            "======================================================================\n",
            "\n",
            "📂 DATA INVENTORY\n",
            "  Datasets:    6\n",
            "  CSV files:   119\n",
            "  Total size:  141.5 MB\n",
            "\n",
            "📋 DATASETS\n",
            "  olympic-120years                     2 files,    39.6 MB\n",
            "  olympic-beijing2022                 10 files,     1.3 MB\n",
            "  olympic-keithgalli                   5 files,    70.3 MB\n",
            "  olympic-paris2024                   58 files,    14.3 MB\n",
            "  paralympic-katiepress                2 files,     6.2 MB\n",
            "  paralympic-piterfm                  42 files,     9.7 MB\n",
            "\n",
            "🗺️ GAMES LOOKUP\n",
            "  Total entries: 85\n",
            "  Olympic range:    1896–2024 (39 editions)\n",
            "  Paralympic range: 1960–2024 (25 editions)\n",
            "\n",
            "🔧 UTILITIES\n",
            "  ✅ norm_name, clean_name_mechanical, flip_name_order\n",
            "  ✅ extract_classification (Paralympic codes)\n",
            "  ✅ lookup_games / get_season\n",
            "\n",
            "======================================================================\n",
            "Ready to proceed to Phase 2: Olympic Athletes\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ── PHASE 1 QC REPORT ─────────────────────────────────────────────\n",
        "\n",
        "print('=' * 70)\n",
        "print('PHASE 1 QC: SETUP & DATA ACQUISITION')\n",
        "print('=' * 70)\n",
        "\n",
        "print(f'\\n📂 DATA INVENTORY')\n",
        "print(f'  Datasets:    {inv_df[\"dataset\"].nunique()}')\n",
        "print(f'  CSV files:   {len(inv_df)}')\n",
        "print(f'  Total size:  {inv_df[\"size_mb\"].sum():.1f} MB')\n",
        "\n",
        "print(f'\\n📋 DATASETS')\n",
        "for dataset in sorted(inv_df['dataset'].unique()):\n",
        "    sub = inv_df[inv_df['dataset'] == dataset]\n",
        "    print(f'  {dataset:35s} {len(sub):2d} files, {sub[\"size_mb\"].sum():7.1f} MB')\n",
        "\n",
        "print(f'\\n🗺️ GAMES LOOKUP')\n",
        "print(f'  Total entries: {len(GAMES_LOOKUP)}')\n",
        "olympic_years = sorted(set(k[0] for k in GAMES_LOOKUP if k[1] == 'Olympic'))\n",
        "para_years = sorted(set(k[0] for k in GAMES_LOOKUP if k[1] == 'Paralympic'))\n",
        "print(f'  Olympic range:    {min(olympic_years)}–{max(olympic_years)} ({len(olympic_years)} editions)')\n",
        "print(f'  Paralympic range: {min(para_years)}–{max(para_years)} ({len(para_years)} editions)')\n",
        "\n",
        "print(f'\\n🔧 UTILITIES')\n",
        "print(f'  ✅ norm_name, clean_name_mechanical, flip_name_order')\n",
        "print(f'  ✅ extract_classification (Paralympic codes)')\n",
        "print(f'  ✅ lookup_games / get_season')\n",
        "\n",
        "print(f'\\n{\"=\" * 70}')\n",
        "print('Ready to proceed to Phase 2: Olympic Athletes')\n",
        "print('=' * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWu7cmmWyned"
      },
      "source": [
        "---\n",
        "## Phase 2: Olympic Athletes\n",
        "\n",
        "Build the Olympic athlete backbone from keithgalli (bios + results through 2022), then identify and add Paris 2024 debut athletes.\n",
        "\n",
        "**Sources:**\n",
        "- `olympic-keithgalli/bios.csv` → USA athlete identification via NOC\n",
        "- `olympic-keithgalli/bios_locs.csv` → Structured birth, height, weight\n",
        "- `olympic-keithgalli/results.csv` → Career stats (Games appearances, medals, primary sport)\n",
        "- `olympic-paris2024/athletes.csv` → Gap check for 2024 debut athletes\n",
        "\n",
        "**Key operations:**\n",
        "1. Join bios with structured data (birth info, physical attributes)\n",
        "2. Compute career stats from results (games_count, medals, primary_sport)\n",
        "3. Mechanical name cleanup (bullet separators → spaces, smart title case)\n",
        "4. Identify Paris 2024 athletes not in keithgalli → add as new rows\n",
        "5. Derive `games_season` from Games lookup table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rHq-UOtyned",
        "outputId": "93a99a0d-6d56-4676-885d-ce8e99092cd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keithgalli USA athletes: 10,332\n",
            "  With birth_date:  10,277\n",
            "  With height (>0): 8,050\n",
            "  With weight (>0): 7,648\n",
            "\n",
            "Sex distribution:\n",
            "Sex\n",
            "Male      7379\n",
            "Female    2953\n"
          ]
        }
      ],
      "source": [
        "# ── Phase 2, Step 1: Load keithgalli backbone ────────────────────\n",
        "# bios.csv has NOC for USA filtering; bios_locs.csv has structured physical data\n",
        "\n",
        "bios = pd.read_csv(\n",
        "    os.path.join(LOCAL_DIR, 'olympic-keithgalli', 'bios.csv'),\n",
        "    low_memory=False\n",
        ")\n",
        "usa_bios = bios[\n",
        "    bios['NOC'].astype(str).str.contains('United States', case=False, na=False)\n",
        "].copy()\n",
        "\n",
        "bios_locs = pd.read_csv(\n",
        "    os.path.join(LOCAL_DIR, 'olympic-keithgalli', 'bios_locs.csv'),\n",
        "    low_memory=False\n",
        ")\n",
        "\n",
        "# Join USA athletes with their structured data\n",
        "olympic_backbone = usa_bios[['athlete_id', 'Sex', 'Used name', 'Roles']].merge(\n",
        "    bios_locs[['athlete_id', 'name', 'born_date', 'born_city', 'born_region',\n",
        "                'born_country', 'height_cm', 'weight_kg']],\n",
        "    on='athlete_id',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Prefer 'Used name' from bios, fall back to bios_locs 'name'\n",
        "olympic_backbone['display_name'] = olympic_backbone['Used name'].fillna(\n",
        "    olympic_backbone['name']\n",
        ")\n",
        "\n",
        "has_h = olympic_backbone['height_cm'].notna() & (olympic_backbone['height_cm'] > 0)\n",
        "has_w = olympic_backbone['weight_kg'].notna() & (olympic_backbone['weight_kg'] > 0)\n",
        "\n",
        "print(f\"Keithgalli USA athletes: {len(olympic_backbone):,}\")\n",
        "print(f\"  With birth_date:  {olympic_backbone['born_date'].notna().sum():,}\")\n",
        "print(f\"  With height (>0): {has_h.sum():,}\")\n",
        "print(f\"  With weight (>0): {has_w.sum():,}\")\n",
        "print(f\"\\nSex distribution:\\n{olympic_backbone['Sex'].value_counts().to_string()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hILl_8tyned",
        "outputId": "ca88db3a-cd93-4cf0-e846-4c572a5290f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results: 308,408 total → 21,353 USA\n",
            "Unique USA athletes in results: 10,058\n",
            "Year range: 1896 — 2022\n",
            "\n",
            "Career stats computed for 10,058 athletes\n",
            "  With medals: 4,060\n",
            "  Multi-Games: 2,630\n"
          ]
        }
      ],
      "source": [
        "# ── Phase 2, Step 2: Career stats from keithgalli results ────────\n",
        "\n",
        "results_raw = pd.read_csv(\n",
        "    os.path.join(LOCAL_DIR, 'olympic-keithgalli', 'results.csv'),\n",
        "    low_memory=False\n",
        ")\n",
        "usa_results = results_raw[\n",
        "    results_raw['noc'].str.upper().str.strip() == 'USA'\n",
        "].copy()\n",
        "\n",
        "print(f\"Results: {len(results_raw):,} total → {len(usa_results):,} USA\")\n",
        "print(f\"Unique USA athletes in results: {usa_results['athlete_id'].nunique():,}\")\n",
        "print(f\"Year range: {int(usa_results['year'].min())} — {int(usa_results['year'].max())}\")\n",
        "\n",
        "career = usa_results.groupby('athlete_id').agg(\n",
        "    first_games_year=('year', 'min'),\n",
        "    last_games_year=('year', 'max'),\n",
        "    games_count=('year', 'nunique'),\n",
        "    primary_sport=('discipline', most_common),\n",
        "    gold_count=('medal', lambda x: (x == 'Gold').sum()),\n",
        "    silver_count=('medal', lambda x: (x == 'Silver').sum()),\n",
        "    bronze_count=('medal', lambda x: (x == 'Bronze').sum()),\n",
        "    _season_types=('type', lambda x: ','.join(sorted(x.dropna().unique())))\n",
        ").reset_index()\n",
        "\n",
        "career['total_medals'] = (\n",
        "    career['gold_count'] + career['silver_count'] + career['bronze_count']\n",
        ")\n",
        "\n",
        "print(f\"\\nCareer stats computed for {len(career):,} athletes\")\n",
        "print(f\"  With medals: {(career['total_medals'] > 0).sum():,}\")\n",
        "print(f\"  Multi-Games: {(career['games_count'] > 1).sum():,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ082mB6yned",
        "outputId": "c77ad79c-4741-4317-ee4f-50563a2cd45e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Olympic athletes table: 10,332 rows\n",
            "  With career results:   10,058\n",
            "  Bios only (no results): 274\n",
            "\n",
            "Season distribution:\n",
            "games_season\n",
            "Summer    8119\n",
            "Winter    1907\n",
            "None       290\n",
            "Both        16\n"
          ]
        }
      ],
      "source": [
        "# ── Phase 2, Step 3: Merge backbone + career stats ───────────────\n",
        "\n",
        "olympic_athletes = olympic_backbone.merge(career, on='athlete_id', how='left')\n",
        "olympic_athletes = olympic_athletes.drop(\n",
        "    columns=['name', 'Used name', 'Roles'], errors='ignore'\n",
        ")\n",
        "\n",
        "# Standardize columns\n",
        "olympic_athletes = olympic_athletes.rename(columns={\n",
        "    'Sex': 'gender',\n",
        "    'display_name': 'name',\n",
        "    'born_date': 'birth_date',\n",
        "    'born_city': 'birth_place',\n",
        "    'born_country': 'birth_country'\n",
        "})\n",
        "\n",
        "# Drop born_region (not in final schema)\n",
        "olympic_athletes = olympic_athletes.drop(columns=['born_region'], errors='ignore')\n",
        "olympic_athletes['games_type'] = 'Olympic'\n",
        "\n",
        "\n",
        "# Derive games_season from the _season_types field\n",
        "def derive_season(row):\n",
        "    st = row.get('_season_types', '')\n",
        "    if pd.isna(st) or st == '':\n",
        "        # Fall back to games lookup\n",
        "        yr = row.get('first_games_year')\n",
        "        if pd.notna(yr):\n",
        "            return get_season(int(yr), 'Olympic')\n",
        "        return None\n",
        "\n",
        "    types = str(st).split(',')\n",
        "    seasons = set()\n",
        "    for t in types:\n",
        "        t = t.strip()\n",
        "        if 'Winter' in t:\n",
        "            seasons.add('Winter')\n",
        "        elif 'Summer' in t:\n",
        "            seasons.add('Summer')\n",
        "\n",
        "    if seasons == {'Summer', 'Winter'}:\n",
        "        return 'Both'\n",
        "    elif 'Winter' in seasons:\n",
        "        return 'Winter'\n",
        "    elif 'Summer' in seasons:\n",
        "        return 'Summer'\n",
        "    return None\n",
        "\n",
        "\n",
        "olympic_athletes['games_season'] = olympic_athletes.apply(derive_season, axis=1)\n",
        "olympic_athletes = olympic_athletes.drop(columns=['_season_types'], errors='ignore')\n",
        "\n",
        "# Mechanical name cleanup\n",
        "olympic_athletes['name'] = olympic_athletes['name'].apply(clean_name_mechanical)\n",
        "\n",
        "print(f\"Olympic athletes table: {len(olympic_athletes):,} rows\")\n",
        "print(f\"  With career results:   {olympic_athletes['games_count'].notna().sum():,}\")\n",
        "print(f\"  Bios only (no results): {olympic_athletes['games_count'].isna().sum():,}\")\n",
        "print(f\"\\nSeason distribution:\")\n",
        "print(olympic_athletes['games_season'].value_counts(dropna=False).to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R4hwgXuyned",
        "outputId": "a7ea9129-a1b5-4040-ee6d-2ebba31d3c63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paris 2024 USA athletes: 619\n",
            "  Already in keithgalli (name match): 214\n",
            "  Not matched: 405\n",
            "  Pass 2 (last name + birth year): 38 additional matches\n",
            "  Truly new 2024 athletes: 367\n"
          ]
        }
      ],
      "source": [
        "# ── Phase 2, Step 4: Paris 2024 gap analysis ─────────────────────\n",
        "\n",
        "paris = pd.read_csv(\n",
        "    os.path.join(LOCAL_DIR, 'olympic-paris2024', 'athletes.csv'),\n",
        "    low_memory=False\n",
        ")\n",
        "paris_usa = paris[paris['country_code'] == 'USA'].copy()\n",
        "\n",
        "# Match using normalized names\n",
        "paris_usa['_norm'] = paris_usa['name'].apply(norm_name)\n",
        "olympic_athletes['_norm'] = olympic_athletes['name'].apply(norm_name)\n",
        "\n",
        "matched = paris_usa['_norm'].isin(olympic_athletes['_norm'])\n",
        "\n",
        "print(f\"Paris 2024 USA athletes: {len(paris_usa):,}\")\n",
        "print(f\"  Already in keithgalli (name match): {matched.sum():,}\")\n",
        "print(f\"  Not matched: {(~matched).sum():,}\")\n",
        "\n",
        "# Pass 2: last name + birth year for unmatched\n",
        "unmatched = paris_usa[~matched].copy()\n",
        "unmatched['_last'] = unmatched['name'].apply(\n",
        "    lambda n: str(n).split()[0].upper() if pd.notna(n) else ''\n",
        ")\n",
        "unmatched['_by'] = pd.to_datetime(\n",
        "    unmatched['birth_date'], errors='coerce'\n",
        ").dt.year\n",
        "\n",
        "olympic_athletes['_last'] = olympic_athletes['name'].apply(\n",
        "    lambda n: str(n).replace('•', ' ').split()[-1].upper() if pd.notna(n) else ''\n",
        ")\n",
        "olympic_athletes['_by'] = pd.to_datetime(\n",
        "    olympic_athletes['birth_date'], errors='coerce'\n",
        ").dt.year\n",
        "\n",
        "pass2 = unmatched.merge(\n",
        "    olympic_athletes[['_last', '_by']].drop_duplicates(),\n",
        "    on=['_last', '_by'],\n",
        "    how='inner'\n",
        ")\n",
        "print(f\"  Pass 2 (last name + birth year): {len(pass2)} additional matches\")\n",
        "\n",
        "# Identify truly new athletes\n",
        "pass2_norms = set(pass2['_norm']) if len(pass2) > 0 else set()\n",
        "paris_new = paris_usa[\n",
        "    (~paris_usa['_norm'].isin(set(olympic_athletes['_norm']))) &\n",
        "    (~paris_usa['_norm'].isin(pass2_norms))\n",
        "].copy()\n",
        "\n",
        "print(f\"  Truly new 2024 athletes: {len(paris_new):,}\")\n",
        "\n",
        "# Clean up temp columns\n",
        "for df in [olympic_athletes, paris_usa, unmatched]:\n",
        "    for col in ['_norm', '_last', '_by']:\n",
        "        if col in df.columns:\n",
        "            df.drop(columns=[col], inplace=True, errors='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p31plQ_Iynee",
        "outputId": "5cbf75ce-57d3-42d4-bb2b-0b19cc95dfda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 367 new Paris 2024 athletes\n",
            "Olympic athletes total: 10,699\n",
            "\n",
            "⚠️  Note: Medal counts for new Paris 2024 athletes are set to 0.\n",
            "   They will be backfilled from the results table in Phase 5.\n"
          ]
        }
      ],
      "source": [
        "# ── Phase 2, Step 5: Add new Paris 2024 athletes ────────────────\n",
        "\n",
        "paris_new_rows = []\n",
        "for _, row in paris_new.iterrows():\n",
        "    # Flip name order (Paris uses LAST First) and clean\n",
        "    raw_name = flip_name_order(str(row.get('name', '')))\n",
        "    cleaned_name = clean_name_mechanical(raw_name)\n",
        "\n",
        "    paris_new_rows.append({\n",
        "        'name': cleaned_name,\n",
        "        'gender': row.get('gender'),\n",
        "        'birth_date': row.get('birth_date'),\n",
        "        'birth_place': row.get('birth_place'),\n",
        "        'birth_country': row.get('birth_country'),\n",
        "        'height_cm': (\n",
        "            row.get('height')\n",
        "            if pd.notna(row.get('height')) and row.get('height', 0) > 0\n",
        "            else None\n",
        "        ),\n",
        "        'weight_kg': (\n",
        "            row.get('weight')\n",
        "            if pd.notna(row.get('weight')) and row.get('weight', 0) > 0\n",
        "            else None\n",
        "        ),\n",
        "        'games_type': 'Olympic',\n",
        "        'games_season': 'Summer',  # Paris 2024 is Summer\n",
        "        'primary_sport': row.get('disciplines'),\n",
        "        'first_games_year': 2024,\n",
        "        'last_games_year': 2024,\n",
        "        'games_count': 1,\n",
        "        'gold_count': 0,    # Will be backfilled from results in Phase 5\n",
        "        'silver_count': 0,\n",
        "        'bronze_count': 0,\n",
        "        'total_medals': 0,\n",
        "    })\n",
        "\n",
        "paris_new_df = pd.DataFrame(paris_new_rows)\n",
        "\n",
        "# Stack onto Olympic backbone\n",
        "olympic_athletes = pd.concat([olympic_athletes, paris_new_df], ignore_index=True)\n",
        "\n",
        "print(f\"Added {len(paris_new_df):,} new Paris 2024 athletes\")\n",
        "print(f\"Olympic athletes total: {len(olympic_athletes):,}\")\n",
        "print(f\"\\n⚠️  Note: Medal counts for new Paris 2024 athletes are set to 0.\")\n",
        "print(f\"   They will be backfilled from the results table in Phase 5.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHk6_PV9ynee",
        "outputId": "5e37376d-1165-4f98-ea97-e32ca1bfffc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "PHASE 2 QC: OLYMPIC ATHLETES\n",
            "======================================================================\n",
            "\n",
            "📊 COUNTS\n",
            "  Total athletes:          10,699\n",
            "  With career results:     10,425\n",
            "  Bios only (no results):  274\n",
            "  From Paris 2024 gap:     367\n",
            "\n",
            "📅 TEMPORAL RANGE\n",
            "  Earliest: 1896.0\n",
            "  Latest:   2024.0\n",
            "\n",
            "📏 PHYSICAL ATTRIBUTES\n",
            "  Height: 8,237 / 10,699 (77.0%)\n",
            "  Weight: 7,660 / 10,699 (71.6%)\n",
            "\n",
            "🏅 MEDAL TOTALS\n",
            "  gold_count           2,717\n",
            "  silver_count         1,806\n",
            "  bronze_count         1,472\n",
            "  total_medals         5,995\n",
            "  Athletes with 1+ medal: 4,060\n",
            "\n",
            "⚧ GENDER\n",
            "gender\n",
            "Male      7547\n",
            "Female    3152\n",
            "\n",
            "🏟️ SEASON\n",
            "games_season\n",
            "Summer    8486\n",
            "Winter    1907\n",
            "None       290\n",
            "Both        16\n",
            "\n",
            "📋 SAMPLE (5 random with results):\n",
            "                      name  gender games_season         primary_sport  games_count  total_medals  first_games_year  last_games_year\n",
            "10618       McCane Morelle  Female       Summer            ['Boxing']          1.0           0.0            2024.0           2024.0\n",
            "6696           Brad Hauser    Male       Summer             Athletics          1.0           0.0            2000.0           2000.0\n",
            "2144          Adler Volmar    Male       Summer                  Judo          1.0           0.0            2008.0           2008.0\n",
            "6461         Peder Falstad    Male       Winter  Ski Jumping (Skiing)          1.0           0.0            1932.0           1932.0\n",
            "4285   Walter Glasgow, Jr.    Male       Summer               Sailing          1.0           1.0            1976.0           1976.0\n",
            "\n",
            "⚠️  KNOWN ISSUES\n",
            "  Paris 2024 medal counts: Not yet backfilled (set to 0)\n",
            "  Missing primary_sport:   274\n",
            "  Missing gender:          0\n",
            "\n",
            "======================================================================\n",
            "Ready to proceed to Phase 3: Paralympic Athletes\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ── PHASE 2 QC REPORT ─────────────────────────────────────────────\n",
        "\n",
        "print('=' * 70)\n",
        "print('PHASE 2 QC: OLYMPIC ATHLETES')\n",
        "print('=' * 70)\n",
        "\n",
        "print(f'\\n📊 COUNTS')\n",
        "print(f'  Total athletes:          {len(olympic_athletes):,}')\n",
        "has_results = olympic_athletes['games_count'].notna().sum()\n",
        "print(f'  With career results:     {has_results:,}')\n",
        "print(f'  Bios only (no results):  {len(olympic_athletes) - has_results:,}')\n",
        "print(f'  From Paris 2024 gap:     {len(paris_new_df):,}')\n",
        "\n",
        "print(f'\\n📅 TEMPORAL RANGE')\n",
        "print(f'  Earliest: {olympic_athletes[\"first_games_year\"].min()}')\n",
        "print(f'  Latest:   {olympic_athletes[\"last_games_year\"].max()}')\n",
        "\n",
        "print(f'\\n📏 PHYSICAL ATTRIBUTES')\n",
        "h = (olympic_athletes['height_cm'].notna() & (olympic_athletes['height_cm'] > 0)).sum()\n",
        "w = (olympic_athletes['weight_kg'].notna() & (olympic_athletes['weight_kg'] > 0)).sum()\n",
        "print(f'  Height: {h:,} / {len(olympic_athletes):,} ({h/len(olympic_athletes)*100:.1f}%)')\n",
        "print(f'  Weight: {w:,} / {len(olympic_athletes):,} ({w/len(olympic_athletes)*100:.1f}%)')\n",
        "\n",
        "print(f'\\n🏅 MEDAL TOTALS')\n",
        "for medal in ['gold_count', 'silver_count', 'bronze_count', 'total_medals']:\n",
        "    val = olympic_athletes[medal].sum()\n",
        "    print(f'  {medal:20s} {val:,.0f}')\n",
        "print(f'  Athletes with 1+ medal: {(olympic_athletes[\"total_medals\"] > 0).sum():,}')\n",
        "\n",
        "print(f'\\n⚧ GENDER')\n",
        "print(olympic_athletes['gender'].value_counts(dropna=False).to_string())\n",
        "\n",
        "print(f'\\n🏟️ SEASON')\n",
        "print(olympic_athletes['games_season'].value_counts(dropna=False).to_string())\n",
        "\n",
        "print(f'\\n📋 SAMPLE (5 random with results):')\n",
        "sample_cols = ['name', 'gender', 'games_season', 'primary_sport',\n",
        "               'games_count', 'total_medals', 'first_games_year', 'last_games_year']\n",
        "sample_cols = [c for c in sample_cols if c in olympic_athletes.columns]\n",
        "print(olympic_athletes.dropna(subset=['games_count'])[sample_cols].sample(\n",
        "    5, random_state=42\n",
        ").to_string())\n",
        "\n",
        "print(f'\\n⚠️  KNOWN ISSUES')\n",
        "print(f'  Paris 2024 medal counts: Not yet backfilled (set to 0)')\n",
        "no_sport = olympic_athletes['primary_sport'].isna().sum()\n",
        "print(f'  Missing primary_sport:   {no_sport:,}')\n",
        "no_gender = olympic_athletes['gender'].isna().sum()\n",
        "print(f'  Missing gender:          {no_gender:,}')\n",
        "\n",
        "print(f'\\n{\"=\" * 70}')\n",
        "print('Ready to proceed to Phase 3: Paralympic Athletes')\n",
        "print('=' * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SF6CM6lynee"
      },
      "source": [
        "---\n",
        "## Phase 3: Paralympic Athletes\n",
        "\n",
        "Build the Paralympic athlete backbone from three sources, extracting classification codes and standardizing names.\n",
        "\n",
        "**Sources:**\n",
        "- `paralympic-piterfm/2020_Tokyo/athletes.csv` → 199 USA athletes, has dedicated `sport_class` column\n",
        "- `paralympic-piterfm/2024_Paris/athletes.csv` → 220 USA athletes, rich bio fields (hobbies, occupation, etc.), classification in event strings\n",
        "- `paralympic-katiepress/medal_athlete.csv` → Historical medalists 1960–2018, abbreviated names (\"LAST I\" format), classification in event strings\n",
        "\n",
        "**Key operations:**\n",
        "1. Extract and normalize classification codes from all sources\n",
        "2. Mechanical name cleanup (LAST First → First Last, dots, case)\n",
        "3. Capture bio fields from Paris 2024 Paralympic data (these feed Gemini prompts in Phase 6, but don't become schema columns)\n",
        "4. Infer gender from event strings for katiepress (no gender column)\n",
        "5. Merge Tokyo + Paris overlapping athletes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwo-efd9ynee",
        "outputId": "4daa01e0-23d9-432b-da01-b6be95f481b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokyo 2020 Paralympic: 4,527 total → 252 USA\n",
            "  sport_class non-null: 252 / 252\n",
            "  Disciplines: ['Archery', 'Athletics', 'Canoe Sprint', 'Cycling Road', 'Cycling Track', 'Equestrian', 'Goalball', 'Judo', 'Powerlifting', 'Rowing', 'Shooting', 'Sitting Volleyball', 'Swimming', 'Table Tennis', 'Taekwondo', 'Triathlon', 'Wheelchair Basketball', 'Wheelchair Fencing', 'Wheelchair Rugby', 'Wheelchair Tennis']\n",
            "\n",
            "Tokyo standardized: 252 athletes\n",
            "  With classification: 252\n",
            "  Sample:\n",
            "                     name     primary_sport classification_code\n",
            "30   Abrahams David Henry          Swimming       S13,SB13,SM13\n",
            "140         Jazmin Almlie          Shooting                 SH2\n",
            "199          Charles Aoki  Wheelchair Rugby                 3.0\n",
            "209      Danielle Aravich         Athletics                 T47\n",
            "219        Ryohei Ariyasu            Rowing              PR3-B2\n"
          ]
        }
      ],
      "source": [
        "# ── Phase 3, Step 1: Tokyo 2020 Paralympic athletes ──────────────\n",
        "\n",
        "tokyo_para = pd.read_csv(\n",
        "    os.path.join(LOCAL_DIR, 'paralympic-piterfm', '2020_Tokyo', 'athletes.csv'),\n",
        "    low_memory=False\n",
        ")\n",
        "tokyo_usa = tokyo_para[\n",
        "    tokyo_para['birth_country'].astype(str).str.contains('United States', case=False, na=False) |\n",
        "    tokyo_para['country_code'].astype(str).str.upper().eq('USA') |\n",
        "    tokyo_para['country'].astype(str).str.contains('United States', case=False, na=False)\n",
        "].copy()\n",
        "\n",
        "print(f\"Tokyo 2020 Paralympic: {len(tokyo_para):,} total → {len(tokyo_usa):,} USA\")\n",
        "print(f\"  sport_class non-null: {tokyo_usa['sport_class'].notna().sum()} / {len(tokyo_usa)}\")\n",
        "print(f\"  Disciplines: {sorted(tokyo_usa['discipline'].dropna().unique())}\")\n",
        "\n",
        "# Standardize\n",
        "tokyo_std = tokyo_usa.rename(columns={\n",
        "    'name': 'name',\n",
        "    'gender': 'gender',\n",
        "    'birth_date': 'birth_date',\n",
        "    'discipline': 'primary_sport',\n",
        "    'sport_class': 'classification_code',\n",
        "}).copy()\n",
        "\n",
        "# Flip name order and clean (piterfm uses LAST First)\n",
        "tokyo_std['name'] = (\n",
        "    tokyo_std['name']\n",
        "    .apply(flip_name_order)\n",
        "    .apply(clean_name_mechanical)\n",
        ")\n",
        "\n",
        "tokyo_std['games_type'] = 'Paralympic'\n",
        "tokyo_std['games_season'] = 'Summer'\n",
        "tokyo_std['first_games_year'] = 2020\n",
        "tokyo_std['last_games_year'] = 2020\n",
        "tokyo_std['games_count'] = 1\n",
        "\n",
        "for col in ['gold_count', 'silver_count', 'bronze_count', 'total_medals']:\n",
        "    tokyo_std[col] = 0\n",
        "\n",
        "# Keep only unified schema columns\n",
        "tokyo_keep = [\n",
        "    'name', 'gender', 'birth_date', 'games_type', 'games_season',\n",
        "    'primary_sport', 'classification_code', 'height_cm', 'weight_kg',\n",
        "    'first_games_year', 'last_games_year', 'games_count',\n",
        "    'gold_count', 'silver_count', 'bronze_count', 'total_medals'\n",
        "]\n",
        "tokyo_keep = [c for c in tokyo_keep if c in tokyo_std.columns]\n",
        "tokyo_std = tokyo_std[tokyo_keep].copy()\n",
        "\n",
        "print(f\"\\nTokyo standardized: {len(tokyo_std)} athletes\")\n",
        "print(f\"  With classification: {tokyo_std['classification_code'].notna().sum()}\")\n",
        "print(f\"  Sample:\")\n",
        "print(tokyo_std[['name', 'primary_sport', 'classification_code']].head(5).to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4adnncCynee",
        "outputId": "876fb116-0a79-499e-b63b-9f966d867d27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paris 2024 Paralympic: 4,459 total → 220 USA\n",
            "  Bio fields available: ['reason', 'hero', 'philosophy', 'other_sports', 'coach', 'hobbies', 'occupation', 'education']\n",
            "  Athletes with bio data: 218\n",
            "\n",
            "Paris Paralympic standardized: 220 athletes\n",
            "  With classification: 88\n"
          ]
        }
      ],
      "source": [
        "# ── Phase 3, Step 2: Paris 2024 Paralympic athletes ──────────────\n",
        "\n",
        "paris_para = pd.read_csv(\n",
        "    os.path.join(LOCAL_DIR, 'paralympic-piterfm', '2024_Paris', 'athletes.csv'),\n",
        "    low_memory=False\n",
        ")\n",
        "paris_para_usa = paris_para[\n",
        "    paris_para['country_code'].astype(str).str.upper().eq('USA')\n",
        "].copy()\n",
        "\n",
        "print(f\"Paris 2024 Paralympic: {len(paris_para):,} total → {len(paris_para_usa):,} USA\")\n",
        "\n",
        "# Extract classification from events column\n",
        "if 'events' in paris_para_usa.columns:\n",
        "    paris_para_usa['classification_code'] = paris_para_usa['events'].apply(extract_classification)\n",
        "elif 'sport_class' in paris_para_usa.columns:\n",
        "    paris_para_usa['classification_code'] = paris_para_usa['sport_class']\n",
        "else:\n",
        "    paris_para_usa['classification_code'] = None\n",
        "\n",
        "# Capture bio fields — stored for Phase 6 Gemini prompts, NOT schema columns\n",
        "bio_fields = [\n",
        "    'reason', 'hero', 'philosophy', 'other_sports',\n",
        "    'coach', 'hobbies', 'occupation', 'education'\n",
        "]\n",
        "bio_available = [f for f in bio_fields if f in paris_para_usa.columns]\n",
        "print(f\"  Bio fields available: {bio_available}\")\n",
        "\n",
        "# Store bio data separately for Phase 6 Gemini prompts\n",
        "paris_para_bios = {}\n",
        "for _, row in paris_para_usa.iterrows():\n",
        "    name = row.get('name', '')\n",
        "    bio = {f: row[f] for f in bio_available if pd.notna(row.get(f))}\n",
        "    if bio:\n",
        "        paris_para_bios[norm_name(name)] = bio\n",
        "\n",
        "print(f\"  Athletes with bio data: {len(paris_para_bios)}\")\n",
        "\n",
        "# Standardize\n",
        "paris_para_std = paris_para_usa.rename(columns={\n",
        "    'name': 'name',\n",
        "    'gender': 'gender',\n",
        "    'birth_date': 'birth_date',\n",
        "    'discipline': 'primary_sport',\n",
        "}).copy()\n",
        "\n",
        "paris_para_std['name'] = (\n",
        "    paris_para_std['name']\n",
        "    .apply(flip_name_order)\n",
        "    .apply(clean_name_mechanical)\n",
        ")\n",
        "\n",
        "paris_para_std['games_type'] = 'Paralympic'\n",
        "paris_para_std['games_season'] = 'Summer'\n",
        "paris_para_std['first_games_year'] = 2024\n",
        "paris_para_std['last_games_year'] = 2024\n",
        "paris_para_std['games_count'] = 1\n",
        "\n",
        "for col in ['gold_count', 'silver_count', 'bronze_count', 'total_medals']:\n",
        "    paris_para_std[col] = 0\n",
        "\n",
        "para_keep = [\n",
        "    'name', 'gender', 'birth_date', 'games_type', 'games_season',\n",
        "    'primary_sport', 'classification_code',\n",
        "    'first_games_year', 'last_games_year', 'games_count',\n",
        "    'gold_count', 'silver_count', 'bronze_count', 'total_medals'\n",
        "]\n",
        "para_keep = [c for c in para_keep if c in paris_para_std.columns]\n",
        "paris_para_std = paris_para_std[para_keep].copy()\n",
        "\n",
        "# Height/weight typically not available for Paralympic athletes\n",
        "paris_para_std['height_cm'] = None\n",
        "paris_para_std['weight_kg'] = None\n",
        "\n",
        "print(f\"\\nParis Paralympic standardized: {len(paris_para_std)} athletes\")\n",
        "print(f\"  With classification: {paris_para_std['classification_code'].notna().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA-D1S6pynee",
        "outputId": "e58d32be-f551-4437-820e-f82f9eded1a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokyo-Paris overlap: 108 athletes competed in both\n",
            "\n",
            "Recent Paralympic athletes: 364\n",
            "  From Tokyo only:    144\n",
            "  Both Tokyo+Paris:   108\n",
            "  Paris only:         112\n"
          ]
        }
      ],
      "source": [
        "# ── Phase 3, Step 3: Merge Tokyo + Paris Paralympic ──────────────\n",
        "# Some athletes competed in both — merge on normalized name\n",
        "\n",
        "tokyo_std['_norm'] = tokyo_std['name'].apply(norm_name)\n",
        "paris_para_std['_norm'] = paris_para_std['name'].apply(norm_name)\n",
        "\n",
        "overlap = paris_para_std['_norm'].isin(tokyo_std['_norm'])\n",
        "print(f\"Tokyo-Paris overlap: {overlap.sum()} athletes competed in both\")\n",
        "\n",
        "# For overlapping athletes, update Tokyo records with Paris 2024 data\n",
        "for _, paris_row in paris_para_std[overlap].iterrows():\n",
        "    mask = tokyo_std['_norm'] == paris_row['_norm']\n",
        "    if mask.any():\n",
        "        idx = tokyo_std[mask].index[0]\n",
        "        tokyo_std.loc[idx, 'last_games_year'] = 2024\n",
        "        tokyo_std.loc[idx, 'games_count'] = 2\n",
        "        # Prefer Paris classification if Tokyo is missing\n",
        "        if pd.isna(tokyo_std.loc[idx, 'classification_code']):\n",
        "            tokyo_std.loc[idx, 'classification_code'] = paris_row['classification_code']\n",
        "\n",
        "# Add Paris-only athletes\n",
        "paris_only = paris_para_std[~overlap].copy()\n",
        "para_recent = pd.concat([tokyo_std, paris_only], ignore_index=True)\n",
        "para_recent = para_recent.drop(columns=['_norm'], errors='ignore')\n",
        "\n",
        "print(f\"\\nRecent Paralympic athletes: {len(para_recent)}\")\n",
        "print(f\"  From Tokyo only:    {(para_recent['last_games_year'] == 2020).sum()}\")\n",
        "print(f\"  Both Tokyo+Paris:   {(para_recent['games_count'] == 2).sum()}\")\n",
        "print(f\"  Paris only:         {len(paris_only)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUGEF04vynee",
        "outputId": "7939e862-da06-4139-a0b1-1e31daa7b107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Katiepress raw: 3,105 medal records\n",
            "  Name col: 'athlete_name', Year: 'games_year', Sport: 'sport', Medal: 'medal'\n",
            "  Year range: 1960 — 2018\n"
          ]
        }
      ],
      "source": [
        "# ── Phase 3, Step 4: Katiepress historical Paralympic athletes ───\n",
        "\n",
        "katie_raw = pd.read_csv(\n",
        "    os.path.join(LOCAL_DIR, 'paralympic-katiepress', 'medal_athlete.csv'),\n",
        "    low_memory=False\n",
        ")\n",
        "katie_raw = katie_raw[katie_raw['npc'].astype(str).str.upper().eq('USA')].copy()\n",
        "print(f\"Katiepress raw: {len(katie_raw):,} medal records\")\n",
        "\n",
        "# Extract classification from event column\n",
        "if 'event' in katie_raw.columns:\n",
        "    katie_raw['_class'] = katie_raw['event'].apply(extract_classification)\n",
        "\n",
        "# Infer gender from event names\n",
        "def infer_gender(event_str):\n",
        "    if pd.isna(event_str):\n",
        "        return None\n",
        "    e = str(event_str).lower()\n",
        "    if \"women\" in e or \"female\" in e:\n",
        "        return \"Female\"\n",
        "    if \"men's\" in e or \"men \" in e or \"male\" in e:\n",
        "        return \"Male\"\n",
        "    if \"mixed\" in e:\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "if 'event' in katie_raw.columns:\n",
        "    katie_raw['_gender'] = katie_raw['event'].apply(infer_gender)\n",
        "\n",
        "# Determine column names dynamically\n",
        "name_col = next(\n",
        "    (c for c in ['athlete', 'athlete_name', 'name'] if c in katie_raw.columns),\n",
        "    katie_raw.columns[0]\n",
        ")\n",
        "year_col = next(\n",
        "    (c for c in ['year', 'games_year', 'Year'] if c in katie_raw.columns),\n",
        "    'year'\n",
        ")\n",
        "sport_col = next(\n",
        "    (c for c in ['sport', 'discipline', 'Sport'] if c in katie_raw.columns),\n",
        "    'sport'\n",
        ")\n",
        "medal_col = next(\n",
        "    (c for c in ['medal', 'Medal'] if c in katie_raw.columns),\n",
        "    'medal'\n",
        ")\n",
        "\n",
        "print(f\"  Name col: '{name_col}', Year: '{year_col}', Sport: '{sport_col}', Medal: '{medal_col}'\")\n",
        "print(f\"  Year range: {katie_raw[year_col].min()} — {katie_raw[year_col].max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4Q6nu_Nynee",
        "outputId": "47f54aa5-04b8-4364-8df4-ca237b80d10a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Katiepress aggregated: 1,165 unique athletes\n",
            "  With classification: 411\n",
            "  With gender:         1,033\n",
            "  Abbreviated names:   1,161 (will be resolved by Gemini in Phase 6)\n",
            "  Year range: 1960 — 2018\n",
            "  Season distribution:\n",
            "games_season\n",
            "Summer    869\n",
            "Both      243\n",
            "Winter     53\n"
          ]
        }
      ],
      "source": [
        "# ── Phase 3, Step 5: Aggregate katiepress to per-athlete rows ────\n",
        "\n",
        "katie_athletes = katie_raw.groupby(name_col).agg(\n",
        "    first_games_year=(year_col, 'min'),\n",
        "    last_games_year=(year_col, 'max'),\n",
        "    games_count=(year_col, 'nunique'),\n",
        "    primary_sport=(sport_col, most_common),\n",
        "    classification_code=(\n",
        "        '_class',\n",
        "        lambda x: x.dropna().mode().iloc[0] if len(x.dropna().mode()) > 0 else None\n",
        "    ),\n",
        "    gold_count=(\n",
        "        medal_col,\n",
        "        lambda x: (x.astype(str).str.lower() == 'gold').sum()\n",
        "    ),\n",
        "    silver_count=(\n",
        "        medal_col,\n",
        "        lambda x: (x.astype(str).str.lower() == 'silver').sum()\n",
        "    ),\n",
        "    bronze_count=(\n",
        "        medal_col,\n",
        "        lambda x: (x.astype(str).str.lower() == 'bronze').sum()\n",
        "    ),\n",
        "    gender=(\n",
        "        '_gender',\n",
        "        lambda x: x.dropna().mode().iloc[0] if len(x.dropna().mode()) > 0 else None\n",
        "    ),\n",
        ").reset_index()\n",
        "\n",
        "katie_athletes = katie_athletes.rename(columns={name_col: 'name'})\n",
        "katie_athletes['total_medals'] = (\n",
        "    katie_athletes['gold_count'] +\n",
        "    katie_athletes['silver_count'] +\n",
        "    katie_athletes['bronze_count']\n",
        ")\n",
        "katie_athletes['games_type'] = 'Paralympic'\n",
        "katie_athletes['birth_date'] = None\n",
        "katie_athletes['height_cm'] = None\n",
        "katie_athletes['weight_kg'] = None\n",
        "\n",
        "\n",
        "# Derive games_season from the lookup table\n",
        "def katie_season(row):\n",
        "    seasons = set()\n",
        "    for yr in range(int(row['first_games_year']), int(row['last_games_year']) + 1):\n",
        "        s = get_season(yr, 'Paralympic')\n",
        "        if s:\n",
        "            seasons.add(s)\n",
        "    if seasons == {'Summer', 'Winter'}:\n",
        "        return 'Both'\n",
        "    elif 'Winter' in seasons:\n",
        "        return 'Winter'\n",
        "    elif 'Summer' in seasons:\n",
        "        return 'Summer'\n",
        "    return 'Summer'  # Default for historical Paralympic\n",
        "\n",
        "\n",
        "katie_athletes['games_season'] = katie_athletes.apply(katie_season, axis=1)\n",
        "\n",
        "# Name cleanup\n",
        "def clean_katie_name(n):\n",
        "    if pd.isna(n):\n",
        "        return None\n",
        "    s = str(n).strip()\n",
        "    s = re.sub(r'^[^A-Za-z]+', '', s)  # Strip leading punctuation\n",
        "    s = s.strip()\n",
        "    if len(s) < 3:\n",
        "        return None\n",
        "    return s\n",
        "\n",
        "katie_athletes['name'] = katie_athletes['name'].apply(clean_katie_name)\n",
        "katie_athletes = katie_athletes[katie_athletes['name'].notna()].copy()\n",
        "\n",
        "# Flag abbreviated names\n",
        "abbrev_count = katie_athletes['name'].apply(is_abbreviated).sum()\n",
        "\n",
        "# Apply mechanical cleanup\n",
        "katie_athletes['name'] = katie_athletes['name'].apply(clean_name_mechanical)\n",
        "\n",
        "print(f\"Katiepress aggregated: {len(katie_athletes):,} unique athletes\")\n",
        "print(f\"  With classification: {katie_athletes['classification_code'].notna().sum():,}\")\n",
        "print(f\"  With gender:         {katie_athletes['gender'].notna().sum():,}\")\n",
        "print(f\"  Abbreviated names:   {abbrev_count:,} (will be resolved by Gemini in Phase 6)\")\n",
        "print(f\"  Year range: {katie_athletes['first_games_year'].min()} — {katie_athletes['last_games_year'].max()}\")\n",
        "print(f\"  Season distribution:\\n{katie_athletes['games_season'].value_counts().to_string()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkiMS5UJynee",
        "outputId": "1073a950-c31c-4ddd-c1c2-0bda46caabe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Katiepress athletes already in piterfm: 0\n",
            "\n",
            "Paralympic athletes total: 1,529\n",
            "  From piterfm (recent): 364\n",
            "  From katiepress only:  1,165\n"
          ]
        }
      ],
      "source": [
        "# ── Phase 3, Step 6: Remove katiepress athletes already in piterfm\n",
        "\n",
        "# Avoid duplicates — katiepress covers 1960-2018, piterfm covers 2020-2024\n",
        "# Some athletes span both periods\n",
        "\n",
        "para_recent['_norm'] = para_recent['name'].apply(norm_name)\n",
        "katie_athletes['_norm'] = katie_athletes['name'].apply(norm_name)\n",
        "\n",
        "katie_overlap = katie_athletes['_norm'].isin(para_recent['_norm'])\n",
        "print(f\"Katiepress athletes already in piterfm: {katie_overlap.sum()}\")\n",
        "\n",
        "# For overlapping, merge career stats (extend year range, sum medals)\n",
        "for _, katie_row in katie_athletes[katie_overlap].iterrows():\n",
        "    mask = para_recent['_norm'] == katie_row['_norm']\n",
        "    if mask.any():\n",
        "        idx = para_recent[mask].index[0]\n",
        "\n",
        "        # Extend year range\n",
        "        para_recent.loc[idx, 'first_games_year'] = min(\n",
        "            para_recent.loc[idx, 'first_games_year'],\n",
        "            katie_row['first_games_year']\n",
        "        )\n",
        "\n",
        "        # Add games count\n",
        "        para_recent.loc[idx, 'games_count'] = (\n",
        "            para_recent.loc[idx, 'games_count'] + katie_row['games_count']\n",
        "        )\n",
        "\n",
        "        # Add medals\n",
        "        for medal in ['gold_count', 'silver_count', 'bronze_count', 'total_medals']:\n",
        "            para_recent.loc[idx, medal] = (\n",
        "                para_recent.loc[idx, medal] + katie_row[medal]\n",
        "            )\n",
        "\n",
        "        # Prefer classification from piterfm if available\n",
        "        if pd.isna(para_recent.loc[idx, 'classification_code']):\n",
        "            para_recent.loc[idx, 'classification_code'] = katie_row['classification_code']\n",
        "\n",
        "        # Update gender if missing\n",
        "        if pd.isna(para_recent.loc[idx, 'gender']):\n",
        "            para_recent.loc[idx, 'gender'] = katie_row['gender']\n",
        "\n",
        "# Keep katiepress-only athletes\n",
        "katie_only = katie_athletes[~katie_overlap].drop(columns=['_norm']).copy()\n",
        "para_recent = para_recent.drop(columns=['_norm'], errors='ignore')\n",
        "\n",
        "# Stack all Paralympic athletes\n",
        "paralympic_athletes = pd.concat([para_recent, katie_only], ignore_index=True)\n",
        "\n",
        "print(f\"\\nParalympic athletes total: {len(paralympic_athletes):,}\")\n",
        "print(f\"  From piterfm (recent): {len(para_recent):,}\")\n",
        "print(f\"  From katiepress only:  {len(katie_only):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f22l-Viaynee",
        "outputId": "ef37275a-9b1a-4834-fe1d-5569d2cc7228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "PHASE 3 QC: PARALYMPIC ATHLETES\n",
            "======================================================================\n",
            "\n",
            "📊 COUNTS\n",
            "  Total athletes:       1,529\n",
            "  From piterfm:         364 (Tokyo 2020 + Paris 2024)\n",
            "  From katiepress:      1,165 (historical 1960-2018)\n",
            "\n",
            "📅 TEMPORAL RANGE\n",
            "  Earliest: 1960\n",
            "  Latest:   2024\n",
            "\n",
            "🏷️ CLASSIFICATION CODES\n",
            "  Coverage: 697 / 1,529 (45.6%)\n",
            "  Unique codes: 154\n",
            "\n",
            "🏅 MEDAL TOTALS\n",
            "  gold_count           1,154\n",
            "  silver_count         959\n",
            "  bronze_count         976\n",
            "  total_medals         3,089\n",
            "  Athletes with 1+ medal: 1,165\n",
            "\n",
            "⚧ GENDER\n",
            "gender\n",
            "Male      768\n",
            "Female    629\n",
            "None      132\n",
            "\n",
            "🏟️ SEASON\n",
            "games_season\n",
            "Summer    1233\n",
            "Both       243\n",
            "Winter      53\n",
            "\n",
            "📝 NAME QUALITY\n",
            "  Abbreviated names: 1,162 (to be resolved by Gemini in Phase 6)\n",
            "\n",
            "🗃️ BIO DATA (for Gemini prompts)\n",
            "  Paris 2024 athletes with bio fields: 218\n",
            "  Bio fields captured: ['reason', 'hero', 'philosophy', 'other_sports', 'coach', 'hobbies', 'occupation', 'education']\n",
            "\n",
            "📋 SAMPLE (5 random):\n",
            "                 name  gender games_season          primary_sport classification_code  games_count  total_medals  first_games_year  last_games_year\n",
            "439          Blabac M    None       Winter        Para Ice Hockey                None            1             1              2010             2010\n",
            "76    Kendall Gretsch  Female       Summer              Triathlon               PTWC2            2             0              2020             2024\n",
            "1270         Saxton T    None       Summer             Equestrian                  C1            1             3              1984             1984\n",
            "661         Elliott N    Male       Winter              Snowboard                None            1             2              2018             2018\n",
            "1036     McCullough A    Male       Summer  Wheelchair Basketball                None            1             1              1960             1960\n",
            "\n",
            "⚠️  KNOWN ISSUES\n",
            "  Abbreviated names: 1,162 (katiepress \"LAST I\" format)\n",
            "  Missing gender:    132\n",
            "  Missing class:     832\n",
            "  Medal counts for piterfm athletes not yet backfilled from results\n",
            "\n",
            "======================================================================\n",
            "Ready to proceed to Phase 4: Unification\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ── PHASE 3 QC REPORT ─────────────────────────────────────────────\n",
        "\n",
        "print('=' * 70)\n",
        "print('PHASE 3 QC: PARALYMPIC ATHLETES')\n",
        "print('=' * 70)\n",
        "\n",
        "print(f'\\n📊 COUNTS')\n",
        "print(f'  Total athletes:       {len(paralympic_athletes):,}')\n",
        "print(f'  From piterfm:         {len(para_recent):,} (Tokyo 2020 + Paris 2024)')\n",
        "print(f'  From katiepress:      {len(katie_only):,} (historical 1960-2018)')\n",
        "\n",
        "print(f'\\n📅 TEMPORAL RANGE')\n",
        "print(f'  Earliest: {paralympic_athletes[\"first_games_year\"].min()}')\n",
        "print(f'  Latest:   {paralympic_athletes[\"last_games_year\"].max()}')\n",
        "\n",
        "print(f'\\n🏷️ CLASSIFICATION CODES')\n",
        "has_class = paralympic_athletes['classification_code'].notna().sum()\n",
        "print(f'  Coverage: {has_class:,} / {len(paralympic_athletes):,} ({has_class/len(paralympic_athletes)*100:.1f}%)')\n",
        "print(f'  Unique codes: {paralympic_athletes[\"classification_code\"].nunique()}')\n",
        "\n",
        "print(f'\\n🏅 MEDAL TOTALS')\n",
        "for medal in ['gold_count', 'silver_count', 'bronze_count', 'total_medals']:\n",
        "    val = paralympic_athletes[medal].sum()\n",
        "    print(f'  {medal:20s} {val:,.0f}')\n",
        "print(f'  Athletes with 1+ medal: {(paralympic_athletes[\"total_medals\"] > 0).sum():,}')\n",
        "\n",
        "print(f'\\n⚧ GENDER')\n",
        "print(paralympic_athletes['gender'].value_counts(dropna=False).to_string())\n",
        "\n",
        "print(f'\\n🏟️ SEASON')\n",
        "print(paralympic_athletes['games_season'].value_counts(dropna=False).to_string())\n",
        "\n",
        "print(f'\\n📝 NAME QUALITY')\n",
        "abbrev = paralympic_athletes['name'].apply(is_abbreviated).sum()\n",
        "print(f'  Abbreviated names: {abbrev:,} (to be resolved by Gemini in Phase 6)')\n",
        "\n",
        "print(f'\\n🗃️ BIO DATA (for Gemini prompts)')\n",
        "print(f'  Paris 2024 athletes with bio fields: {len(paris_para_bios)}')\n",
        "print(f'  Bio fields captured: {bio_available}')\n",
        "\n",
        "print(f'\\n📋 SAMPLE (5 random):')\n",
        "sample_cols = [\n",
        "    'name', 'gender', 'games_season', 'primary_sport', 'classification_code',\n",
        "    'games_count', 'total_medals', 'first_games_year', 'last_games_year'\n",
        "]\n",
        "sample_cols = [c for c in sample_cols if c in paralympic_athletes.columns]\n",
        "print(paralympic_athletes[sample_cols].sample(\n",
        "    min(5, len(paralympic_athletes)), random_state=42\n",
        ").to_string())\n",
        "\n",
        "print(f'\\n⚠️  KNOWN ISSUES')\n",
        "print(f'  Abbreviated names: {abbrev:,} (katiepress \"LAST I\" format)')\n",
        "print(f'  Missing gender:    {paralympic_athletes[\"gender\"].isna().sum():,}')\n",
        "print(f'  Missing class:     {paralympic_athletes[\"classification_code\"].isna().sum():,}')\n",
        "print(f'  Medal counts for piterfm athletes not yet backfilled from results')\n",
        "\n",
        "print(f'\\n{\"=\" * 70}')\n",
        "print('Ready to proceed to Phase 4: Unification')\n",
        "print('=' * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr16C3pSynee"
      },
      "source": [
        "---\n",
        "## Phase 4: Unification\n",
        "\n",
        "Merge Olympic and Paralympic athlete DataFrames into a single `all_athletes` table.\n",
        "\n",
        "**Steps:**\n",
        "1. Concatenate Olympic + Paralympic, inspect combined shape\n",
        "2. Spot-check the katiepress \"Both\" seasons derivation\n",
        "3. Normalize sport names (strip list brackets, parentheticals)\n",
        "4. Fill missing `games_season` via sport→season mapping\n",
        "5. Detect and handle cross-type athletes (keep as separate rows)\n",
        "6. Deduplicate within each games_type\n",
        "7. Generate deterministic UUID5 `athlete_id`\n",
        "8. Final column selection and ordering"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 4, Step 1: Concatenate & Initial Inspection ────────────────\n",
        "\n",
        "# Tag source before merging (helpful for debugging, will drop later)\n",
        "olympic_athletes['_source'] = 'olympic'\n",
        "paralympic_athletes['_source'] = 'paralympic'\n",
        "\n",
        "all_athletes = pd.concat([olympic_athletes, paralympic_athletes], ignore_index=True)\n",
        "\n",
        "print(f'Combined shape: {all_athletes.shape}')\n",
        "print(f'\\nBy source:')\n",
        "print(all_athletes['_source'].value_counts())\n",
        "print(f'\\nBy games_type:')\n",
        "print(all_athletes['games_type'].value_counts())\n",
        "print(f'\\nBy games_season:')\n",
        "print(all_athletes['games_season'].value_counts(dropna=False))\n",
        "print(f'\\nColumns: {list(all_athletes.columns)}')\n",
        "\n",
        "# ── Spot-check: katiepress \"Both\" seasons ────────────────────────────\n",
        "# These athletes should have games spanning both Summer and Winter years\n",
        "both_para = all_athletes[\n",
        "    (all_athletes['games_season'] == 'Both') &\n",
        "    (all_athletes['_source'] == 'paralympic')\n",
        "]\n",
        "print(f'\\n{\"=\" * 60}')\n",
        "print(f'SPOT CHECK: Paralympic \"Both\" season athletes: {len(both_para)}')\n",
        "\n",
        "if len(both_para) > 0:\n",
        "    sample = both_para.sample(min(10, len(both_para)), random_state=42)\n",
        "    print(sample[['name', 'primary_sport', 'first_games_year', 'last_games_year',\n",
        "                   'games_count', 'games_season', 'total_medals']].to_string(index=False))\n",
        "\n",
        "   # Check plausibility: Summer-only sports flagged \"Both\" = misclassified\n",
        "    WINTER_SPORTS = {\n",
        "        'Alpine Skiing', 'Biathlon', 'Cross-Country Skiing', 'Ice Sledge Hockey',\n",
        "        'Para Ice Hockey', 'Wheelchair Curling', 'Nordic Skiing', 'Snowboard',\n",
        "        'Ice Sledge Speed Racing'\n",
        "    }\n",
        "    winter_both = both_para[both_para['primary_sport'].isin(WINTER_SPORTS)]\n",
        "    summer_both = both_para[~both_para['primary_sport'].isin(WINTER_SPORTS)]\n",
        "    print(f'\\n  Winter-sport athletes marked \"Both\": {len(winter_both)}')\n",
        "    print(f'  Summer-sport athletes marked \"Both\": {len(summer_both)}')\n",
        "    print(f'  ⚠️  Most \"Both\" are likely misclassified — will fix in next step')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP9EG1u02dmJ",
        "outputId": "dfd9bb8a-636b-4104-8407-6004372a6a09"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined shape: (12228, 20)\n",
            "\n",
            "By source:\n",
            "_source\n",
            "olympic       10699\n",
            "paralympic     1529\n",
            "Name: count, dtype: int64\n",
            "\n",
            "By games_type:\n",
            "games_type\n",
            "Olympic       10699\n",
            "Paralympic     1529\n",
            "Name: count, dtype: int64\n",
            "\n",
            "By games_season:\n",
            "games_season\n",
            "Summer    9719\n",
            "Winter    1960\n",
            "None       290\n",
            "Both       259\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Columns: ['athlete_id', 'gender', 'birth_date', 'birth_place', 'birth_country', 'height_cm', 'weight_kg', 'name', 'first_games_year', 'last_games_year', 'games_count', 'primary_sport', 'gold_count', 'silver_count', 'bronze_count', 'total_medals', 'games_type', 'games_season', '_source', 'classification_code']\n",
            "\n",
            "============================================================\n",
            "SPOT CHECK: Paralympic \"Both\" season athletes: 243\n",
            "       name     primary_sport  first_games_year  last_games_year  games_count games_season  total_medals\n",
            "    Brown D         Athletics            1976.0           2016.0          4.0         Both           5.0\n",
            "   Asbury A         Athletics            1988.0           1996.0          3.0         Both           4.0\n",
            "  Nichols A     Alpine Skiing            2008.0           2014.0          3.0         Both           6.0\n",
            "    Welch S Wheelchair Tennis            1996.0           2000.0          2.0         Both           4.0\n",
            "    Young C     Alpine Skiing            1994.0           2016.0          2.0         Both           2.0\n",
            "    Roman R   Para Ice Hockey            2014.0           2018.0          2.0         Both           2.0\n",
            "Theryoung R          Goalball            2004.0           2008.0          2.0         Both           2.0\n",
            "   Moucha S          Swimming            1984.0           1996.0          3.0         Both           6.0\n",
            "    Banta L          Goalball            2000.0           2008.0          3.0         Both           3.0\n",
            "   Larson D         Athletics            1988.0           1996.0          3.0         Both           8.0\n",
            "\n",
            "  Winter-sport athletes marked \"Both\": 56\n",
            "  Summer-sport athletes marked \"Both\": 187\n",
            "  ⚠️  Most \"Both\" are likely misclassified — will fix in next step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 4, Step 2: Fix \"Both\" season misclassification ────────────\n",
        "\n",
        "# Reclassify using sport → season mapping\n",
        "# These are unambiguously Winter Paralympic sports\n",
        "WINTER_SPORTS = {\n",
        "    'Alpine Skiing', 'Biathlon', 'Cross-Country Skiing', 'Ice Sledge Hockey',\n",
        "    'Para Ice Hockey', 'Wheelchair Curling', 'Nordic Skiing', 'Snowboard',\n",
        "    'Ice Sledge Speed Racing'\n",
        "}\n",
        "\n",
        "both_mask = all_athletes['games_season'] == 'Both'\n",
        "both_athletes = all_athletes[both_mask].copy()\n",
        "\n",
        "reclassified = 0\n",
        "for idx, row in both_athletes.iterrows():\n",
        "    sport = str(row['primary_sport']).strip()\n",
        "    if sport in WINTER_SPORTS:\n",
        "        all_athletes.at[idx, 'games_season'] = 'Winter'\n",
        "        reclassified += 1\n",
        "    elif sport != 'nan' and sport != 'None':\n",
        "        # Known sport and NOT winter → Summer\n",
        "        all_athletes.at[idx, 'games_season'] = 'Summer'\n",
        "        reclassified += 1\n",
        "\n",
        "still_both = (all_athletes['games_season'] == 'Both').sum()\n",
        "print(f'Reclassified {reclassified} / {len(both_athletes)} \"Both\" athletes')\n",
        "print(f'Remaining \"Both\": {still_both}')\n",
        "print(f'\\nUpdated season distribution:')\n",
        "print(all_athletes['games_season'].value_counts(dropna=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFJErjQ83Nx7",
        "outputId": "3c139fd3-6053-4090-a7a5-7f02e8f9b78c"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reclassified 259 / 259 \"Both\" athletes\n",
            "Remaining \"Both\": 0\n",
            "\n",
            "Updated season distribution:\n",
            "games_season\n",
            "Summer    9922\n",
            "Winter    2016\n",
            "None       290\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 4, Step 3: Normalize sports & fill missing seasons ─────────\n",
        "\n",
        "# Fix list-bracket sports from Paris 2024 gap athletes: \"['Boxing']\" → \"Boxing\"\n",
        "def clean_sport(s):\n",
        "    if pd.isna(s):\n",
        "        return s\n",
        "    s = str(s).strip()\n",
        "    # Strip list brackets and quotes\n",
        "    if s.startswith('[') and s.endswith(']'):\n",
        "        s = s.strip('[]').strip(\"'\\\"\")\n",
        "    # Strip parenthetical suffixes: \"Ski Jumping (Skiing)\" → \"Ski Jumping\"\n",
        "    s = re.sub(r'\\s*\\(.*?\\)\\s*$', '', s)\n",
        "    return s.strip()\n",
        "\n",
        "all_athletes['primary_sport'] = all_athletes['primary_sport'].apply(clean_sport)\n",
        "\n",
        "# Verify bracket fix\n",
        "bracket_remaining = all_athletes['primary_sport'].str.contains(r'[\\[\\]]', na=False).sum()\n",
        "print(f'Sports with remaining brackets: {bracket_remaining}')\n",
        "\n",
        "# Map obvious sports → season for the 290 None records\n",
        "SPORT_SEASON = {\n",
        "    # Winter\n",
        "    'Alpine Skiing': 'Winter', 'Biathlon': 'Winter', 'Bobsled': 'Winter',\n",
        "    'Bobsleigh': 'Winter', 'Cross-Country Skiing': 'Winter', 'Curling': 'Winter',\n",
        "    'Figure Skating': 'Winter', 'Freestyle Skiing': 'Winter',\n",
        "    'Ice Hockey': 'Winter', 'Luge': 'Winter', 'Nordic Combined': 'Winter',\n",
        "    'Short Track Speed Skating': 'Winter', 'Skeleton': 'Winter',\n",
        "    'Ski Jumping': 'Winter', 'Snowboard': 'Winter', 'Speed Skating': 'Winter',\n",
        "}\n",
        "\n",
        "none_mask = all_athletes['games_season'].isna() | (all_athletes['games_season'] == 'None')\n",
        "none_before = none_mask.sum()\n",
        "\n",
        "def assign_season(row):\n",
        "    if row['primary_sport'] in SPORT_SEASON:\n",
        "        return SPORT_SEASON[row['primary_sport']]\n",
        "    elif pd.notna(row['primary_sport']):\n",
        "        return 'Summer'  # Default — vast majority of sports are Summer\n",
        "    return None\n",
        "\n",
        "fixed_seasons = all_athletes[none_mask].apply(assign_season, axis=1)\n",
        "all_athletes.loc[none_mask, 'games_season'] = fixed_seasons\n",
        "\n",
        "none_after = (all_athletes['games_season'].isna() | (all_athletes['games_season'] == 'None')).sum()\n",
        "print(f'None seasons: {none_before} → {none_after}')\n",
        "print(f'\\nFinal season distribution:')\n",
        "print(all_athletes['games_season'].value_counts(dropna=False))\n",
        "\n",
        "# Quick look at sport cleanup\n",
        "print(f'\\nUnique sports: {all_athletes[\"primary_sport\"].nunique()}')\n",
        "print(f'\\nTop 15 sports:')\n",
        "print(all_athletes['primary_sport'].value_counts().head(15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuZtOPub3iLL",
        "outputId": "89395d2c-c393-4d5b-c9dc-8b07b636bcd7"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports with remaining brackets: 0\n",
            "None seasons: 290 → 274\n",
            "\n",
            "Final season distribution:\n",
            "games_season\n",
            "Summer    9938\n",
            "Winter    2016\n",
            "None       274\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Unique sports: 93\n",
            "\n",
            "Top 15 sports:\n",
            "primary_sport\n",
            "Athletics              2542\n",
            "Swimming                986\n",
            "Rowing                  737\n",
            "Ice Hockey              434\n",
            "Wrestling               348\n",
            "Artistic Gymnastics     333\n",
            "Shooting                319\n",
            "Basketball              295\n",
            "Fencing                 287\n",
            "Football                285\n",
            "Alpine Skiing           280\n",
            "Sailing                 266\n",
            "Boxing                  260\n",
            "Figure Skating          223\n",
            "Volleyball              219\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 4, Step 4: Deduplicate & Generate UUID5 athlete_id ─────────\n",
        "import uuid\n",
        "\n",
        "all_athletes['_norm'] = all_athletes['name'].apply(norm_name)\n",
        "\n",
        "# Find potential duplicates\n",
        "dupes = all_athletes.groupby(['_norm', 'games_type']).size()\n",
        "dupe_groups = dupes[dupes > 1]\n",
        "print(f'Potential duplicate groups: {len(dupe_groups)}')\n",
        "\n",
        "# Only merge when SAME sport or overlapping year ranges (likely same person)\n",
        "# Different sport + different era = different person\n",
        "before_dedup = len(all_athletes)\n",
        "drop_indices = []\n",
        "\n",
        "for (norm, gtype), count in dupe_groups.items():\n",
        "    rows = all_athletes[(all_athletes['_norm'] == norm) & (all_athletes['games_type'] == gtype)]\n",
        "    idxs = rows.index.tolist()\n",
        "\n",
        "    # Group by sport — same sport = likely same person\n",
        "    sport_groups = rows.groupby('primary_sport')\n",
        "    if len(sport_groups) == 1:\n",
        "        # Same sport: keep row with most data\n",
        "        keeper = rows.sort_values(['games_count', 'total_medals'], ascending=False).index[0]\n",
        "        drop_indices.extend([i for i in idxs if i != keeper])\n",
        "    else:\n",
        "        # Different sports — check year overlap\n",
        "        sorted_rows = rows.sort_values('first_games_year')\n",
        "        for i in range(len(sorted_rows) - 1):\n",
        "            r1 = sorted_rows.iloc[i]\n",
        "            r2 = sorted_rows.iloc[i + 1]\n",
        "            # If year ranges overlap, likely same person switching sports\n",
        "            if pd.notna(r1['last_games_year']) and pd.notna(r2['first_games_year']):\n",
        "                if r1['last_games_year'] >= r2['first_games_year']:\n",
        "                    # Overlapping — keep the one with more games\n",
        "                    pair = sorted_rows.iloc[i:i+2]\n",
        "                    loser = pair.sort_values(['games_count', 'total_medals']).index[0]\n",
        "                    if loser not in drop_indices:\n",
        "                        drop_indices.append(loser)\n",
        "            # Non-overlapping + different sport = different people, keep both\n",
        "\n",
        "all_athletes = all_athletes.drop(index=drop_indices).reset_index(drop=True)\n",
        "after_dedup = len(all_athletes)\n",
        "print(f'Dedup: {before_dedup} → {after_dedup} (removed {before_dedup - after_dedup})')\n",
        "\n",
        "# Remaining same-name groups (different people we're keeping)\n",
        "remaining_dupes = all_athletes.groupby(['_norm', 'games_type']).size()\n",
        "remaining_multi = remaining_dupes[remaining_dupes > 1]\n",
        "print(f'Retained distinct athletes sharing a name: {len(remaining_multi)} groups')\n",
        "\n",
        "# UUID5: norm_name + games_type + first_games_year + primary_sport\n",
        "NAMESPACE = uuid.UUID('a1b2c3d4-e5f6-7890-abcd-ef1234567890')\n",
        "\n",
        "def make_athlete_id(row):\n",
        "    parts = [row['_norm'], str(row['games_type'])]\n",
        "    if pd.notna(row['first_games_year']):\n",
        "        parts.append(str(int(row['first_games_year'])))\n",
        "    if pd.notna(row['primary_sport']):\n",
        "        parts.append(str(row['primary_sport']))\n",
        "    seed = '|'.join(parts)\n",
        "    return str(uuid.uuid5(NAMESPACE, seed))\n",
        "\n",
        "all_athletes['athlete_id'] = all_athletes.apply(make_athlete_id, axis=1)\n",
        "\n",
        "id_dupes = all_athletes['athlete_id'].duplicated().sum()\n",
        "print(f'UUID5 collisions: {id_dupes}')\n",
        "print(f'Final athlete count: {len(all_athletes)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yznfg1Vo3-zG",
        "outputId": "9a96ea00-a3d3-4ccd-c822-5f443c855154"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Potential duplicate groups: 77\n",
            "Dedup: 12228 → 12207 (removed 21)\n",
            "Retained distinct athletes sharing a name: 57 groups\n",
            "UUID5 collisions: 0\n",
            "Final athlete count: 12207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 4, Step 5: Final column selection & QC ─────────────────────\n",
        "\n",
        "# Drop working columns\n",
        "all_athletes = all_athletes.drop(columns=['_norm', '_source', 'birth_place',\n",
        "                                          'birth_country'], errors='ignore')\n",
        "\n",
        "# Ensure classification_code is clean\n",
        "all_athletes['classification_code'] = all_athletes['classification_code'].replace(\n",
        "    {'None': None, 'nan': None, '': None}\n",
        ")\n",
        "\n",
        "# Column order matching final schema\n",
        "SCHEMA_COLS = [\n",
        "    'athlete_id', 'name', 'gender', 'birth_date', 'games_type', 'games_season',\n",
        "    'primary_sport', 'classification_code', 'height_cm', 'weight_kg',\n",
        "    'first_games_year', 'last_games_year', 'games_count',\n",
        "    'gold_count', 'silver_count', 'bronze_count', 'total_medals'\n",
        "]\n",
        "# profile_summary and embedding added in Phase 6\n",
        "\n",
        "# Check for missing columns\n",
        "missing = [c for c in SCHEMA_COLS if c not in all_athletes.columns]\n",
        "extra = [c for c in all_athletes.columns if c not in SCHEMA_COLS]\n",
        "print(f'Missing schema cols: {missing}')\n",
        "print(f'Extra cols (will drop): {extra}')\n",
        "\n",
        "all_athletes = all_athletes[[c for c in SCHEMA_COLS if c in all_athletes.columns]]\n",
        "\n",
        "print(f'\\n{\"=\" * 60}')\n",
        "print(f'PHASE 4 QC: UNIFICATION')\n",
        "print(f'{\"=\" * 60}')\n",
        "print(f'\\n📊 FINAL COUNTS')\n",
        "print(f'  Total athletes: {len(all_athletes):,}')\n",
        "print(f'  Olympic:        {(all_athletes[\"games_type\"]==\"Olympic\").sum():,}')\n",
        "print(f'  Paralympic:     {(all_athletes[\"games_type\"]==\"Paralympic\").sum():,}')\n",
        "print(f'\\n⚧ GENDER')\n",
        "print(all_athletes['gender'].value_counts(dropna=False))\n",
        "print(f'\\n🏟️ SEASON')\n",
        "print(all_athletes['games_season'].value_counts(dropna=False))\n",
        "print(f'\\n🏅 MEDALS')\n",
        "for col in ['gold_count', 'silver_count', 'bronze_count', 'total_medals']:\n",
        "    print(f'  {col}: {all_athletes[col].sum():,.0f}')\n",
        "print(f'  Athletes with 1+ medal: {(all_athletes[\"total_medals\"]>0).sum():,}')\n",
        "print(f'\\n🏷️ CLASSIFICATION (Paralympic only)')\n",
        "para = all_athletes[all_athletes['games_type'] == 'Paralympic']\n",
        "print(f'  Coverage: {para[\"classification_code\"].notna().sum()} / {len(para)}')\n",
        "print(f'\\n📋 SAMPLE (5 random):')\n",
        "print(all_athletes.sample(5, random_state=42)[SCHEMA_COLS].to_string(index=False))\n",
        "print(f'\\n⚠️  KNOWN ISSUES')\n",
        "print(f'  Missing gender: {all_athletes[\"gender\"].isna().sum() + (all_athletes[\"gender\"]==\"None\").sum()}')\n",
        "print(f'  Missing season: {all_athletes[\"games_season\"].isna().sum() + (all_athletes[\"games_season\"]==\"None\").sum()}')\n",
        "print(f'  Missing sport:  {all_athletes[\"primary_sport\"].isna().sum()}')\n",
        "print(f'  ~100 aggressive dedup losses from earlier pass (mixed true dupes + distinct athletes)')\n",
        "print(f'\\n{\"=\" * 60}')\n",
        "print(f'Ready to proceed to Phase 5: Results Table & Career Stat Backfill')\n",
        "print(f'{\"=\" * 60}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyHW5YAZ4rCs",
        "outputId": "c6fda746-ad7b-458e-87a1-43594f579428"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing schema cols: []\n",
            "Extra cols (will drop): []\n",
            "\n",
            "============================================================\n",
            "PHASE 4 QC: UNIFICATION\n",
            "============================================================\n",
            "\n",
            "📊 FINAL COUNTS\n",
            "  Total athletes: 12,207\n",
            "  Olympic:        10,685\n",
            "  Paralympic:     1,522\n",
            "\n",
            "⚧ GENDER\n",
            "gender\n",
            "Male      8298\n",
            "Female    3777\n",
            "None       132\n",
            "Name: count, dtype: int64\n",
            "\n",
            "🏟️ SEASON\n",
            "games_season\n",
            "Summer    9920\n",
            "Winter    2015\n",
            "None       272\n",
            "Name: count, dtype: int64\n",
            "\n",
            "🏅 MEDALS\n",
            "  gold_count: 3,869\n",
            "  silver_count: 2,764\n",
            "  bronze_count: 2,447\n",
            "  total_medals: 9,080\n",
            "  Athletes with 1+ medal: 5,221\n",
            "\n",
            "🏷️ CLASSIFICATION (Paralympic only)\n",
            "  Coverage: 691 / 1522\n",
            "\n",
            "📋 SAMPLE (5 random):\n",
            "                          athlete_id           name gender birth_date games_type games_season primary_sport classification_code  height_cm  weight_kg  first_games_year  last_games_year  games_count  gold_count  silver_count  bronze_count  total_medals\n",
            "d25208cf-6a56-50e7-b528-28b351382566 Anne Abernathy Female 1953-04-12    Olympic         None           NaN                 NaN      165.0       75.0               NaN              NaN          NaN         NaN           NaN           NaN           NaN\n",
            "aa147068-0d4a-5f0d-b4d6-015901493ae2   Dinah Browne Female 1969-11-27    Olympic         None           NaN                 NaN      165.0       65.0               NaN              NaN          NaN         NaN           NaN           NaN           NaN\n",
            "c648a020-4a62-5988-ae5d-246bb4f02c9c  William Peets   Male 1952-08-23    Olympic         None           NaN                 NaN      180.0       70.0               NaN              NaN          NaN         NaN           NaN           NaN           NaN\n",
            "bceebdd4-b740-5911-ac47-c564f1bb84fa         Shea M   Male       None Paralympic       Winter Alpine Skiing                None        NaN        NaN            2014.0           2014.0          1.0         0.0           1.0           0.0           1.0\n",
            "64c98e20-4877-5634-b8b0-7440a79031bb    Dick Hyland   Male 1900-07-06    Olympic       Summer         Rugby                 NaN        NaN        NaN            1924.0           1924.0          1.0         1.0           0.0           0.0           1.0\n",
            "\n",
            "⚠️  KNOWN ISSUES\n",
            "  Missing gender: 132\n",
            "  Missing season: 272\n",
            "  Missing sport:  383\n",
            "  ~100 aggressive dedup losses from earlier pass (mixed true dupes + distinct athletes)\n",
            "\n",
            "============================================================\n",
            "Ready to proceed to Phase 5: Results Table & Career Stat Backfill\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlW_wzBYynee"
      },
      "source": [
        "---\n",
        "## Phase 5: Results Table & Career Stat Backfill\n",
        "\n",
        "Build the unified `team_usa_results` fact table (one row per athlete × event × Games) and backfill any missing career stats in `all_athletes`.\n",
        "\n",
        "**Steps:**\n",
        "1. Build results from keithgalli results.csv (Olympic backbone)\n",
        "2. Build results from katiepress medal_athlete.csv (Paralympic historical medalists)\n",
        "3. Concatenate, normalize, attach athlete_id via name matching\n",
        "4. Backfill medal counts and career stats for athletes whose counts were set to 0 (Paris 2024 Olympic, piterfm Paralympic)\n",
        "5. QC report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 5, Step 1: Olympic results from keithgalli ─────────────────\n",
        "\n",
        "results_raw = pd.read_csv(f'{LOCAL_DIR}/olympic-keithgalli/results.csv')\n",
        "oly_results = results_raw[results_raw['noc'] == 'USA'].copy()\n",
        "\n",
        "print(f'Raw USA Olympic results: {len(oly_results):,}')\n",
        "print(f'Columns: {list(oly_results.columns)}')\n",
        "print(f'\\nSample:')\n",
        "print(oly_results.head(3).to_string(index=False))\n",
        "\n",
        "# Standardize column names to match results schema\n",
        "oly_results = oly_results.rename(columns={\n",
        "    'year': 'games_year',\n",
        "    'type': 'games_season',  # 'Summer' / 'Winter' in keithgalli\n",
        "})\n",
        "\n",
        "# Clean up\n",
        "oly_results['games_type'] = 'Olympic'\n",
        "oly_results['classification_code'] = None\n",
        "\n",
        "# Extract athlete name — prefer 'Used name' if in bios, else use 'name'\n",
        "# But results.csv uses 'name' column directly\n",
        "oly_results['athlete_name'] = oly_results['as'].apply(clean_name_mechanical)\n",
        "\n",
        "# Normalize medal values\n",
        "oly_results['medal'] = oly_results['medal'].replace({\n",
        "    'Gold': 'Gold', 'Silver': 'Silver', 'Bronze': 'Bronze'\n",
        "})\n",
        "oly_results.loc[~oly_results['medal'].isin(['Gold', 'Silver', 'Bronze']), 'medal'] = None\n",
        "\n",
        "# Select results schema columns\n",
        "RESULTS_COLS = ['athlete_name', 'games_year', 'games_season', 'games_type',\n",
        "                'sport', 'discipline', 'event', 'medal', 'classification_code']\n",
        "# Keep only columns that exist\n",
        "available = [c for c in RESULTS_COLS if c in oly_results.columns]\n",
        "missing_cols = [c for c in RESULTS_COLS if c not in oly_results.columns]\n",
        "print(f'\\nAvailable results cols: {available}')\n",
        "print(f'Missing (will add empty): {missing_cols}')\n",
        "for c in missing_cols:\n",
        "    oly_results[c] = None\n",
        "\n",
        "oly_results['sport'] = oly_results['discipline']\n",
        "oly_results = oly_results[RESULTS_COLS]\n",
        "\n",
        "print(f'\\nOlympic results: {len(oly_results):,}')\n",
        "print(f'With medals: {oly_results[\"medal\"].notna().sum():,}')\n",
        "print(f'Year range: {oly_results[\"games_year\"].min():.0f}–{oly_results[\"games_year\"].max():.0f}')\n",
        "print(f'Unique athletes: {oly_results[\"athlete_name\"].nunique():,}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2CCtHpw438t",
        "outputId": "96aac6bb-28d3-46b0-aee1-85c936b61186"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw USA Olympic results: 21,353\n",
            "Columns: ['year', 'type', 'discipline', 'event', 'as', 'athlete_id', 'noc', 'team', 'place', 'tied', 'medal']\n",
            "\n",
            "Sample:\n",
            "  year   type discipline                       event            as  athlete_id noc          team  place  tied medal\n",
            "2008.0 Summer    Archery Individual, Women (Olympic) Khatuna Lorig         504 USA           NaN    5.0 False   NaN\n",
            "2012.0 Summer    Archery Individual, Women (Olympic) Khatuna Lorig         504 USA           NaN    4.0 False   NaN\n",
            "2012.0 Summer    Archery       Team, Women (Olympic) Khatuna Lorig         504 USA United States    6.0 False   NaN\n",
            "\n",
            "Available results cols: ['athlete_name', 'games_year', 'games_season', 'games_type', 'discipline', 'event', 'medal', 'classification_code']\n",
            "Missing (will add empty): ['sport']\n",
            "\n",
            "Olympic results: 21,353\n",
            "With medals: 5,995\n",
            "Year range: 1896–2022\n",
            "Unique athletes: 10,118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 5, Step 2: Paralympic results from katiepress ──────────────\n",
        "\n",
        "katie_raw = pd.read_csv(f'{LOCAL_DIR}/paralympic-katiepress/medal_athlete.csv')\n",
        "print(f'Raw katiepress rows: {len(katie_raw):,}')\n",
        "print(f'Columns: {list(katie_raw.columns)}')\n",
        "print(f'\\nSample:')\n",
        "print(katie_raw.head(3).to_string(index=False))\n",
        "\n",
        "# Filter to USA\n",
        "usa_col = [c for c in katie_raw.columns if 'country' in c.lower() or 'npc' in c.lower() or 'noc' in c.lower()]\n",
        "print(f'\\nCountry columns: {usa_col}')\n",
        "\n",
        "# Identify the right filter column and value\n",
        "for col in usa_col:\n",
        "    usa_vals = katie_raw[col].value_counts()\n",
        "    us_matches = [v for v in usa_vals.index if 'US' in str(v).upper() or 'UNITED' in str(v).upper() or 'AMERICA' in str(v).upper()]\n",
        "    if us_matches:\n",
        "        print(f'  {col}: {us_matches[:5]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-VZ64Bk5nX5",
        "outputId": "59595353-f8d6-464b-cf9e-77e8f5e98b66"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw katiepress rows: 29,170\n",
            "Columns: ['games_code', 'games_year', 'games_city', 'games_country', 'games_continent', 'games_start', 'games_end', 'games_season', 'sport', 'sport_code', 'event_dates', 'event_venue', 'events', 'npcs', 'athletes', 'event', 'medal', 'npc', 'npc_new', 'npc_name', 'athlete_name', 'athlete_info_og']\n",
            "\n",
            "Sample:\n",
            "games_code  games_year games_city games_country games_continent  games_start    games_end games_season   sport sport_code event_dates event_venue  events  npcs  athletes                         event  medal npc npc_new       npc_name athlete_name  athlete_info_og\n",
            "    PG1960        1960       Rome         Italy          Europe 18 September 25 September       Summer Archery         AR 18 - 25 Sep         NaN       8     8        19         Men's FITA Round Open Bronze GBR     GBR United Kingdom       POTTER     POTTER (GBR)\n",
            "    PG1960        1960       Rome         Italy          Europe 18 September 25 September       Summer Archery         AR 18 - 25 Sep         NaN       8     8        19     Men's Columbia Round Open Bronze GBR     GBR United Kingdom       HEPPLE     HEPPLE (GBR)\n",
            "    PG1960        1960       Rome         Italy          Europe 18 September 25 September       Summer Archery         AR 18 - 25 Sep         NaN       8     8        19 Men's St. Nicholas Round Open Bronze USA     USA  United States      SONES P SONES Paul (USA)\n",
            "\n",
            "Country columns: ['games_country', 'npcs', 'npc', 'npc_new', 'npc_name']\n",
            "  games_country: ['United StatesUnited Kingdom', 'United States', 'Australia', 'United Kingdom', 'Austria']\n",
            "  npc: ['USA', 'AUS', 'RUS']\n",
            "  npc_new: ['USA', 'AUS', 'RUS']\n",
            "  npc_name: ['United States', 'United Kingdom', 'Australia', 'Russia', 'Austria']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 5, Step 3: Filter & standardize katiepress Paralympic results ──\n",
        "\n",
        "para_results = katie_raw[katie_raw['npc'] == 'USA'].copy()\n",
        "print(f'USA Paralympic results: {len(para_results):,}')\n",
        "\n",
        "# Clean names\n",
        "para_results['athlete_name'] = para_results['athlete_name'].apply(\n",
        "    lambda x: clean_name_mechanical(str(x).strip())\n",
        ")\n",
        "\n",
        "# Extract classification from event\n",
        "para_results['classification_code'] = para_results['event'].apply(extract_classification)\n",
        "\n",
        "# Standardize medal values\n",
        "para_results['medal'] = para_results['medal'].replace({\n",
        "    'Gold': 'Gold', 'Silver': 'Silver', 'Bronze': 'Bronze'\n",
        "})\n",
        "para_results.loc[~para_results['medal'].isin(['Gold', 'Silver', 'Bronze']), 'medal'] = None\n",
        "\n",
        "# Add missing columns\n",
        "para_results['games_type'] = 'Paralympic'\n",
        "para_results['discipline'] = para_results['sport']\n",
        "\n",
        "# Select results schema columns\n",
        "para_results = para_results[RESULTS_COLS]\n",
        "\n",
        "print(f'With medals: {para_results[\"medal\"].notna().sum():,}')\n",
        "print(f'Year range: {para_results[\"games_year\"].min():.0f}–{para_results[\"games_year\"].max():.0f}')\n",
        "print(f'Unique athletes: {para_results[\"athlete_name\"].nunique():,}')\n",
        "print(f'Unique sports: {para_results[\"sport\"].nunique()}')\n",
        "print(f'\\nSample:')\n",
        "print(para_results.head(5).to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nklpKudU5vQj",
        "outputId": "30f4bdd2-b09e-48a1-c9f5-6b69c574086e"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USA Paralympic results: 3,105\n",
            "With medals: 3,105\n",
            "Year range: 1960–2018\n",
            "Unique athletes: 1,169\n",
            "Unique sports: 29\n",
            "\n",
            "Sample:\n",
            "athlete_name  games_year games_season games_type     sport discipline                         event  medal classification_code\n",
            "     Sones P        1960       Summer Paralympic   Archery    Archery Men's St. Nicholas Round Open Bronze                None\n",
            "   Whitman J        1960       Summer Paralympic   Archery    Archery         Men's FITA Round Open   Gold                None\n",
            "   Whitman J        1960       Summer Paralympic   Archery    Archery      Men's Windsor Round Open   Gold                None\n",
            "    Welger S        1960       Summer Paralympic Athletics  Athletics              Men's Shot Put C Bronze                None\n",
            "     Stein R        1960       Summer Paralympic Athletics  Athletics              Men's Shot Put C   Gold                None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 5, Step 4: Concatenate results & attach athlete_id ─────────\n",
        "\n",
        "all_results = pd.concat([oly_results, para_results], ignore_index=True)\n",
        "print(f'Combined results: {len(all_results):,}')\n",
        "print(f'  Olympic:    {(all_results[\"games_type\"]==\"Olympic\").sum():,}')\n",
        "print(f'  Paralympic: {(all_results[\"games_type\"]==\"Paralympic\").sum():,}')\n",
        "\n",
        "# Match results to all_athletes via norm_name + games_type\n",
        "all_results['_norm'] = all_results['athlete_name'].apply(norm_name)\n",
        "all_athletes['_norm'] = all_athletes['name'].apply(norm_name)\n",
        "\n",
        "# Build lookup: (norm_name, games_type) → athlete_id\n",
        "# For athletes sharing a name, include sport to disambiguate\n",
        "id_lookup = {}\n",
        "for _, row in all_athletes.iterrows():\n",
        "    key = (row['_norm'], row['games_type'])\n",
        "    if key not in id_lookup:\n",
        "        id_lookup[key] = row['athlete_id']\n",
        "    # else: first match wins (most games/medals from dedup sort)\n",
        "\n",
        "all_results['athlete_id'] = all_results.apply(\n",
        "    lambda r: id_lookup.get((r['_norm'], r['games_type'])), axis=1\n",
        ")\n",
        "\n",
        "matched = all_results['athlete_id'].notna().sum()\n",
        "unmatched = all_results['athlete_id'].isna().sum()\n",
        "print(f'\\nMatched to athlete_id: {matched:,} ({matched/len(all_results)*100:.1f}%)')\n",
        "print(f'Unmatched: {unmatched:,}')\n",
        "\n",
        "if unmatched > 0:\n",
        "    unmatched_sample = all_results[all_results['athlete_id'].isna()].sample(\n",
        "        min(10, unmatched), random_state=42\n",
        "    )\n",
        "    print('\\nUnmatched sample:')\n",
        "    print(unmatched_sample[['athlete_name', '_norm', 'games_type', 'games_year',\n",
        "                             'sport']].to_string(index=False))\n",
        "\n",
        "# Drop working column\n",
        "all_results = all_results.drop(columns=['_norm'])\n",
        "all_athletes = all_athletes.drop(columns=['_norm'], errors='ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4c_xeqd52No",
        "outputId": "a04600f5-a522-4f7a-d947-ef5854ba333c"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined results: 24,458\n",
            "  Olympic:    21,353\n",
            "  Paralympic: 3,105\n",
            "\n",
            "Matched to athlete_id: 24,054 (98.3%)\n",
            "Unmatched: 404\n",
            "\n",
            "Unmatched sample:\n",
            "    athlete_name            _norm games_type  games_year                            sport\n",
            "     Connie Lenz      CONNIE LENZ    Olympic      1948.0 Artistic Gymnastics (Gymnastics)\n",
            "     Alison Owen      ALISON OWEN    Olympic      1972.0    Cross Country Skiing (Skiing)\n",
            "  Mia Manganello   MANGANELLO MIA    Olympic      2018.0          Speed Skating (Skating)\n",
            "  Karen O'Connor    KAREN OCONNOR    Olympic      2008.0 Equestrian Eventing (Equestrian)\n",
            "Jessica Newberry JESSICA NEWBERRY    Olympic      1964.0 Equestrian Dressage (Equestrian)\n",
            "    Muriel Davis     DAVIS MURIEL    Olympic      1956.0 Artistic Gymnastics (Gymnastics)\n",
            "  Danielle Scott   DANIELLE SCOTT    Olympic      2000.0          Volleyball (Volleyball)\n",
            "     Kara Winger      KARA WINGER    Olympic      2016.0                        Athletics\n",
            "      Des Davila       DAVILA DES    Olympic      2012.0                        Athletics\n",
            "     Kerri Walsh      KERRI WALSH    Olympic      2000.0          Volleyball (Volleyball)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 5, Step 5: Backfill career stats from results ──────────────\n",
        "\n",
        "# Compute fresh career stats from all_results for matched athletes\n",
        "matched_results = all_results[all_results['athlete_id'].notna()].copy()\n",
        "\n",
        "fresh_stats = matched_results.groupby('athlete_id').agg(\n",
        "    results_count=('games_year', 'size'),\n",
        "    first_year=('games_year', 'min'),\n",
        "    last_year=('games_year', 'max'),\n",
        "    games_years=('games_year', 'nunique'),\n",
        "    gold=('medal', lambda x: (x == 'Gold').sum()),\n",
        "    silver=('medal', lambda x: (x == 'Silver').sum()),\n",
        "    bronze=('medal', lambda x: (x == 'Bronze').sum()),\n",
        ").reset_index()\n",
        "\n",
        "fresh_stats['total'] = fresh_stats['gold'] + fresh_stats['silver'] + fresh_stats['bronze']\n",
        "\n",
        "print(f'Fresh stats computed for {len(fresh_stats):,} athletes')\n",
        "\n",
        "# Identify athletes needing backfill (medal counts were set to 0)\n",
        "zero_medals = all_athletes[\n",
        "    (all_athletes['total_medals'] == 0) &\n",
        "    (all_athletes['athlete_id'].isin(fresh_stats['athlete_id']))\n",
        "]\n",
        "print(f'Athletes with 0 medals eligible for backfill: {len(zero_medals):,}')\n",
        "\n",
        "# Backfill: update medals and year ranges where current values are 0 or missing\n",
        "backfilled = 0\n",
        "for _, stats in fresh_stats.iterrows():\n",
        "    mask = all_athletes['athlete_id'] == stats['athlete_id']\n",
        "    idx = all_athletes[mask].index\n",
        "    if len(idx) == 0:\n",
        "        continue\n",
        "    i = idx[0]\n",
        "    row = all_athletes.loc[i]\n",
        "\n",
        "    updated = False\n",
        "    # Backfill medals if current is 0 and results show medals\n",
        "    if row['total_medals'] == 0 and stats['total'] > 0:\n",
        "        all_athletes.at[i, 'gold_count'] = stats['gold']\n",
        "        all_athletes.at[i, 'silver_count'] = stats['silver']\n",
        "        all_athletes.at[i, 'bronze_count'] = stats['bronze']\n",
        "        all_athletes.at[i, 'total_medals'] = stats['total']\n",
        "        updated = True\n",
        "\n",
        "    # Extend year range if results show wider range\n",
        "    if pd.notna(stats['first_year']):\n",
        "        if pd.isna(row['first_games_year']) or stats['first_year'] < row['first_games_year']:\n",
        "            all_athletes.at[i, 'first_games_year'] = stats['first_year']\n",
        "            updated = True\n",
        "    if pd.notna(stats['last_year']):\n",
        "        if pd.isna(row['last_games_year']) or stats['last_year'] > row['last_games_year']:\n",
        "            all_athletes.at[i, 'last_games_year'] = stats['last_year']\n",
        "            updated = True\n",
        "\n",
        "    # Update games_count if results show more\n",
        "    if stats['games_years'] > (row['games_count'] or 0):\n",
        "        all_athletes.at[i, 'games_count'] = stats['games_years']\n",
        "        updated = True\n",
        "\n",
        "    if updated:\n",
        "        backfilled += 1\n",
        "\n",
        "print(f'Athletes backfilled: {backfilled:,}')\n",
        "print(f'\\nUpdated medal totals:')\n",
        "for col in ['gold_count', 'silver_count', 'bronze_count', 'total_medals']:\n",
        "    print(f'  {col}: {all_athletes[col].sum():,.0f}')\n",
        "print(f'  Athletes with 1+ medal: {(all_athletes[\"total_medals\"] > 0).sum():,}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx-ZnKj56DIv",
        "outputId": "65a6a8bf-7a57-461a-9ee0-c6f38a73a031"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fresh stats computed for 11,085 athletes\n",
            "Athletes with 0 medals eligible for backfill: 5,915\n",
            "Athletes backfilled: 63\n",
            "\n",
            "Updated medal totals:\n",
            "  gold_count: 3,879\n",
            "  silver_count: 2,770\n",
            "  bronze_count: 2,449\n",
            "  total_medals: 9,098\n",
            "  Athletes with 1+ medal: 5,235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── PHASE 5 QC REPORT ────────────────────────────────────────────────\n",
        "\n",
        "print('=' * 60)\n",
        "print('PHASE 5 QC: RESULTS TABLE & CAREER STAT BACKFILL')\n",
        "print('=' * 60)\n",
        "\n",
        "print(f'\\n📊 RESULTS TABLE')\n",
        "print(f'  Total results:  {len(all_results):,}')\n",
        "print(f'  Olympic:        {(all_results[\"games_type\"]==\"Olympic\").sum():,}')\n",
        "print(f'  Paralympic:     {(all_results[\"games_type\"]==\"Paralympic\").sum():,}')\n",
        "print(f'  With medals:    {all_results[\"medal\"].notna().sum():,}')\n",
        "print(f'  Matched to ID:  {all_results[\"athlete_id\"].notna().sum():,} ({all_results[\"athlete_id\"].notna().mean()*100:.1f}%)')\n",
        "print(f'  Unmatched:      {all_results[\"athlete_id\"].isna().sum():,}')\n",
        "print(f'  Year range:     {all_results[\"games_year\"].min():.0f}–{all_results[\"games_year\"].max():.0f}')\n",
        "print(f'  Unique sports:  {all_results[\"sport\"].nunique()}')\n",
        "\n",
        "print(f'\\n📊 ATHLETES TABLE (post-backfill)')\n",
        "print(f'  Total athletes: {len(all_athletes):,}')\n",
        "print(f'  Olympic:        {(all_athletes[\"games_type\"]==\"Olympic\").sum():,}')\n",
        "print(f'  Paralympic:     {(all_athletes[\"games_type\"]==\"Paralympic\").sum():,}')\n",
        "\n",
        "print(f'\\n🏅 MEDAL TOTALS')\n",
        "for col in ['gold_count', 'silver_count', 'bronze_count', 'total_medals']:\n",
        "    print(f'  {col}: {all_athletes[col].sum():,.0f}')\n",
        "print(f'  Athletes with 1+ medal: {(all_athletes[\"total_medals\"]>0).sum():,}')\n",
        "\n",
        "# Cross-check: do athlete medal sums match results medal counts?\n",
        "results_medals = all_results[all_results['medal'].notna() & all_results['athlete_id'].notna()]\n",
        "results_gold = (results_medals['medal'] == 'Gold').sum()\n",
        "results_silver = (results_medals['medal'] == 'Silver').sum()\n",
        "results_bronze = (results_medals['medal'] == 'Bronze').sum()\n",
        "athlete_gold = all_athletes['gold_count'].sum()\n",
        "athlete_silver = all_athletes['silver_count'].sum()\n",
        "athlete_bronze = all_athletes['bronze_count'].sum()\n",
        "\n",
        "print(f'\\n🔄 CROSS-CHECK (results vs athletes table)')\n",
        "print(f'  Gold:   results={results_gold:,.0f}, athletes={athlete_gold:,.0f}, diff={athlete_gold-results_gold:+,.0f}')\n",
        "print(f'  Silver: results={results_silver:,.0f}, athletes={athlete_silver:,.0f}, diff={athlete_silver-results_silver:+,.0f}')\n",
        "print(f'  Bronze: results={results_bronze:,.0f}, athletes={athlete_bronze:,.0f}, diff={athlete_bronze-results_bronze:+,.0f}')\n",
        "\n",
        "print(f'\\n📋 RESULTS SAMPLE (5 random with medals):')\n",
        "medal_sample = all_results[all_results['medal'].notna()].sample(5, random_state=42)\n",
        "print(medal_sample[['athlete_name', 'games_year', 'games_type', 'sport',\n",
        "                     'event', 'medal']].to_string(index=False))\n",
        "\n",
        "print(f'\\n⚠️  KNOWN ISSUES')\n",
        "print(f'  Unmatched results: {all_results[\"athlete_id\"].isna().sum()} (minor name variations)')\n",
        "print(f'  No 2024 Olympic results (not in keithgalli)')\n",
        "print(f'  Paralympic results are medal-only (katiepress has no non-medal results)')\n",
        "\n",
        "print(f'\\n{\"=\" * 60}')\n",
        "print(f'Ready to proceed to Phase 6: Gemini Enrichment')\n",
        "print(f'{\"=\" * 60}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iVI4S5k6SD5",
        "outputId": "4e53e675-e447-4f54-d4cf-620b5039adc9"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 5 QC: RESULTS TABLE & CAREER STAT BACKFILL\n",
            "============================================================\n",
            "\n",
            "📊 RESULTS TABLE\n",
            "  Total results:  24,458\n",
            "  Olympic:        21,353\n",
            "  Paralympic:     3,105\n",
            "  With medals:    9,100\n",
            "  Matched to ID:  24,054 (98.3%)\n",
            "  Unmatched:      404\n",
            "  Year range:     1896–2022\n",
            "  Unique sports:  92\n",
            "\n",
            "📊 ATHLETES TABLE (post-backfill)\n",
            "  Total athletes: 12,207\n",
            "  Olympic:        10,685\n",
            "  Paralympic:     1,522\n",
            "\n",
            "🏅 MEDAL TOTALS\n",
            "  gold_count: 3,879\n",
            "  silver_count: 2,770\n",
            "  bronze_count: 2,449\n",
            "  total_medals: 9,098\n",
            "  Athletes with 1+ medal: 5,235\n",
            "\n",
            "🔄 CROSS-CHECK (results vs athletes table)\n",
            "  Gold:   results=3,834, athletes=3,879, diff=+45\n",
            "  Silver: results=2,730, athletes=2,770, diff=+40\n",
            "  Bronze: results=2,421, athletes=2,449, diff=+28\n",
            "\n",
            "📋 RESULTS SAMPLE (5 random with medals):\n",
            " athlete_name  games_year games_type                   sport                       event  medal\n",
            "Lee Stecklein      2022.0    Olympic Ice Hockey (Ice Hockey) Ice Hockey, Women (Olympic) Silver\n",
            "       Levy B      1996.0 Paralympic                Swimming   Women's 50 m Freestyle S8 Bronze\n",
            "     Casper K      1980.0 Paralympic               Athletics          Women's 4x60 m 2-5 Silver\n",
            " Willard Rice      1924.0    Olympic Ice Hockey (Ice Hockey)   Ice Hockey, Men (Olympic) Silver\n",
            "     Graham A      1980.0 Paralympic               Athletics             Men's 80 m CP D Bronze\n",
            "\n",
            "⚠️  KNOWN ISSUES\n",
            "  Unmatched results: 404 (minor name variations)\n",
            "  No 2024 Olympic results (not in keithgalli)\n",
            "  Paralympic results are medal-only (katiepress has no non-medal results)\n",
            "\n",
            "============================================================\n",
            "Ready to proceed to Phase 6: Gemini Enrichment\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Athlete count investigation ──────────────────────────────────────\n",
        "\n",
        "print('=== OLYMPIC BREAKDOWN ===')\n",
        "print(f'Total Olympic: {len(all_athletes[all_athletes[\"games_type\"]==\"Olympic\"]):,}')\n",
        "# How many came from each source in Phase 2?\n",
        "print(f'\\nKeithgalli bios (pre-Paris):  Check olympic_athletes before Paris concat')\n",
        "\n",
        "print('\\n=== PARALYMPIC BREAKDOWN ===')\n",
        "para = all_athletes[all_athletes['games_type'] == 'Paralympic']\n",
        "print(f'Total Paralympic: {len(para):,}')\n",
        "\n",
        "# The big question: did katiepress get properly filtered to USA?\n",
        "# Reload and check\n",
        "katie_check = pd.read_csv(f'{LOCAL_DIR}/paralympic-katiepress/medal_athlete.csv')\n",
        "katie_usa = katie_check[katie_check['npc'] == 'USA']\n",
        "katie_all_countries = katie_check['npc'].nunique()\n",
        "print(f'\\nKatiepress total rows: {len(katie_check):,}')\n",
        "print(f'Katiepress USA rows:   {len(katie_usa):,}')\n",
        "print(f'Katiepress countries:  {katie_all_countries}')\n",
        "print(f'Katiepress USA unique athletes: {katie_usa[\"athlete_name\"].nunique():,}')\n",
        "\n",
        "# What did we actually get in paralympic_athletes?\n",
        "print(f'\\nParalympic athletes with 0 medals: {(para[\"total_medals\"]==0).sum():,}')\n",
        "print(f'Paralympic athletes with 1+ medal: {(para[\"total_medals\"]>0).sum():,}')\n",
        "\n",
        "# Spot check: are there non-USA athletes in the mix?\n",
        "# Look for athletes with non-American names in katiepress-origin rows\n",
        "print(f'\\nParalympic athletes sample (low medal count):')\n",
        "print(para.nsmallest(10, 'total_medals')[['name', 'primary_sport', 'first_games_year',\n",
        "    'games_count', 'total_medals', 'classification_code']].to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_h26Fcre7W6v",
        "outputId": "75b424ee-9e50-4719-abfe-6440242c96ea"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== OLYMPIC BREAKDOWN ===\n",
            "Total Olympic: 10,685\n",
            "\n",
            "Keithgalli bios (pre-Paris):  Check olympic_athletes before Paris concat\n",
            "\n",
            "=== PARALYMPIC BREAKDOWN ===\n",
            "Total Paralympic: 1,522\n",
            "\n",
            "Katiepress total rows: 29,170\n",
            "Katiepress USA rows:   3,105\n",
            "Katiepress countries:  127\n",
            "Katiepress USA unique athletes: 1,169\n",
            "\n",
            "Paralympic athletes with 0 medals: 358\n",
            "Paralympic athletes with 1+ medal: 1,164\n",
            "\n",
            "Paralympic athletes sample (low medal count):\n",
            "                name         primary_sport  first_games_year  games_count  total_medals classification_code\n",
            "Abrahams David Henry              Swimming            2020.0          2.0           0.0       S13,SB13,SM13\n",
            "       Jazmin Almlie              Shooting            2020.0          2.0           0.0                 SH2\n",
            "        Charles Aoki      Wheelchair Rugby            2020.0          1.0           0.0                 3.0\n",
            "    Danielle Aravich             Athletics            2020.0          1.0           0.0                 T47\n",
            "      Ryohei Ariyasu                Rowing            2020.0          1.0           0.0              PR3-B2\n",
            "      Josie Aslakson Wheelchair Basketball            2020.0          2.0           0.0                 1.0\n",
            "       Hannah Aspden              Swimming            2020.0          2.0           0.0          S9,SB8,SM9\n",
            "         Evan Austin              Swimming            2020.0          2.0           0.0              S7,SM7\n",
            "     Femita Ayanbeku             Athletics            2020.0          2.0           0.0                 T64\n",
            "     Elizabeth Baker             Triathlon            2020.0          1.0           0.0               PTVI3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYWH9L6Dynee"
      },
      "source": [
        "---\n",
        "## Phase 6: Gemini Enrichment\n",
        "\n",
        "*Single Gemini pass per athlete: name verification + profile generation using Google Search grounding. Then embeddings in a second pass.*\n",
        "\n",
        "**Phase 6a: Profile Summaries + Name Verification**\n",
        "1. Setup & configuration\n",
        "2. Thread-local Gemini client\n",
        "3. Prompt builder + generation functions (structured JSON output)\n",
        "4. Test with sample athletes\n",
        "5. Parallel processing — full run (~12K athletes)\n",
        "6. Profile QC\n",
        "\n",
        "**Phase 6b: Vector Embeddings**\n",
        "7. Embedding functions\n",
        "8. Test single embedding\n",
        "9. Parallel processing — full run\n",
        "10. Merge enrichments into `all_athletes`\n",
        "11. Phase 6 QC + GCS checkpoint\n",
        "\n",
        "**Key design decisions:**\n",
        "- Context-first prompts: every known fact (sport, classification, Games years, events, medals) is included to maximize Google Search accuracy\n",
        "- Name verification: Gemini returns `verified_name` with confidence level; abbreviated names (katiepress) are expanded when confidently identified\n",
        "- Safety rails: last name must match, first initial must match, UNVERIFIED if uncertain\n",
        "- UNVERIFIED athletes get a data-only profile sentence built from table facts\n",
        "- Resume-safe: progress checkpointed to `/tmp/` CSV files; reruns only process failures"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 6, Step 1: Setup & Configuration ────────────────────────\n",
        "!pip install -q google-genai tqdm\n",
        "\n",
        "import json\n",
        "import time\n",
        "import csv\n",
        "import re\n",
        "import threading\n",
        "import hashlib\n",
        "from pathlib import Path\n",
        "from typing import Optional, Tuple, List\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from datetime import datetime\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "class ProfileConfig:\n",
        "    \"\"\"Configuration for profile summary + name verification\"\"\"\n",
        "    MODEL_NAME = 'gemini-2.5-flash'\n",
        "    TEMPERATURE = 1.2\n",
        "    MAX_OUTPUT_TOKENS = 1500  # Slightly more than v1 to accommodate JSON wrapper\n",
        "\n",
        "    BATCH_SIZE = 200\n",
        "    MAX_WORKERS = 50\n",
        "    SAVE_INTERVAL = 200\n",
        "    MAX_RETRIES = 3\n",
        "    RETRY_DELAY = 2\n",
        "\n",
        "    MIN_PROFILE_LENGTH = 80\n",
        "    MAX_PROFILE_LENGTH = 5000\n",
        "\n",
        "    PROGRESS_FILE = '/tmp/v2_athlete_profiles_progress.csv'\n",
        "    ERROR_LOG = '/tmp/v2_athlete_profiles_errors.csv'\n",
        "\n",
        "\n",
        "class EmbeddingConfig:\n",
        "    \"\"\"Configuration for embedding generation\"\"\"\n",
        "    MODEL_NAME = 'gemini-embedding-001'\n",
        "    OUTPUT_DIMENSION = 3072\n",
        "\n",
        "    BATCH_SIZE = 200\n",
        "    MAX_WORKERS = 75\n",
        "    SAVE_INTERVAL = 200\n",
        "    MAX_RETRIES = 3\n",
        "    RETRY_DELAY = 2\n",
        "\n",
        "    PROGRESS_FILE = '/tmp/v2_athlete_embeddings_progress.csv'\n",
        "    ERROR_LOG = '/tmp/v2_athlete_embeddings_errors.csv'\n",
        "\n",
        "\n",
        "# Build event lookup from results table: athlete_id → list of \"event (medal)\" strings\n",
        "# Build event lookup from results table: athlete_id → list of \"event (medal)\" strings\n",
        "event_lookup = {}\n",
        "for aid, group in all_results.groupby('athlete_id'):\n",
        "    events = []\n",
        "    for _, r in group.iterrows():\n",
        "        event_str = str(r.get('event', '')).strip()\n",
        "        year = r.get('games_year', '')\n",
        "        medal = r.get('medal', '')\n",
        "        if event_str and event_str != 'nan':\n",
        "            label = event_str\n",
        "            if pd.notna(year):\n",
        "                label += f\" ({int(year)})\"\n",
        "            if pd.notna(medal) and medal in ('Gold', 'Silver', 'Bronze'):\n",
        "                label += f\" — {medal}\"\n",
        "            events.append(label)\n",
        "    if events:\n",
        "        event_lookup[aid] = events\n",
        "\n",
        "print(f\"Profile config:   {ProfileConfig.MODEL_NAME}, {ProfileConfig.MAX_WORKERS} workers\")\n",
        "print(f\"Embedding config: {EmbeddingConfig.MODEL_NAME}, {EmbeddingConfig.OUTPUT_DIMENSION} dims, {EmbeddingConfig.MAX_WORKERS} workers\")\n",
        "print(f\"Athletes to process: {len(all_athletes):,}\")\n",
        "print(f\"Athletes with event detail: {len(event_lookup):,}\")\n",
        "print(f\"Athletes without event detail: {len(all_athletes) - len(event_lookup):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFl7Bv86Bnlu",
        "outputId": "8d4128a6-e984-43d3-bde1-5bbbeea045be"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Profile config:   gemini-2.5-flash, 50 workers\n",
            "Embedding config: gemini-embedding-001, 3072 dims, 75 workers\n",
            "Athletes to process: 12,207\n",
            "Athletes with event detail: 11,085\n",
            "Athletes without event detail: 1,122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 6, Step 2: Thread-local Gemini client ──────────────────\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "import google.auth\n",
        "\n",
        "_thread_local = threading.local()\n",
        "\n",
        "def get_client():\n",
        "    \"\"\"Get or create a thread-local Gemini client.\"\"\"\n",
        "    if getattr(_thread_local, \"client\", None) is None:\n",
        "        credentials, _ = google.auth.default()\n",
        "        _thread_local.client = genai.Client(\n",
        "            vertexai=True,\n",
        "            project=PROJECT_ID,\n",
        "            location=REGION,\n",
        "        )\n",
        "    return _thread_local.client\n",
        "\n",
        "# Test connection\n",
        "try:\n",
        "    test_response = get_client().models.generate_content(\n",
        "        model=ProfileConfig.MODEL_NAME,\n",
        "        contents='Say \"API connected\" and nothing else.',\n",
        "        config=types.GenerateContentConfig(max_output_tokens=20),\n",
        "    )\n",
        "    response_text = test_response.text if test_response.text else \"(empty response)\"\n",
        "    print(f\"✅ Gemini API connected\")\n",
        "    print(f\"   Project: {PROJECT_ID}\")\n",
        "    print(f\"   Region:  {REGION}\")\n",
        "    print(f\"   Model:   {ProfileConfig.MODEL_NAME}\")\n",
        "    print(f\"   Response: {response_text.strip()}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Connection failed: {e}\")\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59fBRmTZBqRU",
        "outputId": "d4b00fb5-1f29-42d5-e3b1-e2cf024f2a3d"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Gemini API connected\n",
            "   Project: qwiklabs-gcp-01-bafc8841fc77\n",
            "   Region:  us-central1\n",
            "   Model:   gemini-2.5-flash\n",
            "   Response: (empty response)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 6, Step 3: Prompt builder + generation functions ────────\n",
        "\n",
        "def is_abbreviated(name):\n",
        "    \"\"\"Check if name looks like katiepress abbreviated format: 'Last F' or 'Last Fi'\"\"\"\n",
        "    if pd.isna(name):\n",
        "        return False\n",
        "    parts = str(name).strip().split()\n",
        "    if len(parts) < 2:\n",
        "        return False\n",
        "    # Last token is 1-2 chars = likely initial/abbreviation\n",
        "    return len(parts[-1]) <= 2 or len(parts[0]) <= 2\n",
        "\n",
        "\n",
        "def build_data_only_profile(row):\n",
        "    \"\"\"Build a factual sentence from table data for UNVERIFIED athletes.\"\"\"\n",
        "    name = str(row.get('name', 'Unknown')).strip()\n",
        "    games_type = row.get('games_type', 'Olympic')\n",
        "    sport = row.get('primary_sport', '')\n",
        "    classification = row.get('classification_code', '')\n",
        "    first_yr = row.get('first_games_year', '')\n",
        "    last_yr = row.get('last_games_year', '')\n",
        "    games_count = row.get('games_count', '')\n",
        "    total_medals = row.get('total_medals', 0)\n",
        "\n",
        "    parts = [f\"{name} represented the United States as a {games_type} athlete\"]\n",
        "\n",
        "    if pd.notna(sport) and str(sport) != 'nan':\n",
        "        parts[0] += f\" in {sport}\"\n",
        "\n",
        "    if pd.notna(classification) and str(classification) not in ('nan', 'None', ''):\n",
        "        parts.append(f\"competing in classification {classification}\")\n",
        "\n",
        "    if pd.notna(first_yr) and pd.notna(last_yr):\n",
        "        fy, ly = int(first_yr), int(last_yr)\n",
        "        if fy == ly:\n",
        "            parts.append(f\"at the {fy} Games\")\n",
        "        else:\n",
        "            gc = f\" across {int(games_count)} Games\" if pd.notna(games_count) and int(games_count) > 1 else \"\"\n",
        "            parts.append(f\"from {fy} to {ly}{gc}\")\n",
        "\n",
        "    if pd.notna(total_medals) and int(total_medals) > 0:\n",
        "        gold = int(row.get('gold_count', 0)) if pd.notna(row.get('gold_count')) else 0\n",
        "        silver = int(row.get('silver_count', 0)) if pd.notna(row.get('silver_count')) else 0\n",
        "        bronze = int(row.get('bronze_count', 0)) if pd.notna(row.get('bronze_count')) else 0\n",
        "        medal_parts = []\n",
        "        if gold > 0: medal_parts.append(f\"{gold} gold\")\n",
        "        if silver > 0: medal_parts.append(f\"{silver} silver\")\n",
        "        if bronze > 0: medal_parts.append(f\"{bronze} bronze\")\n",
        "        parts.append(f\"earning {', '.join(medal_parts)}\")\n",
        "\n",
        "    return ', '.join(parts) + '.'\n",
        "\n",
        "\n",
        "def create_profile_prompt(row) -> str:\n",
        "    \"\"\"Build a context-rich prompt for name verification + profile generation.\"\"\"\n",
        "\n",
        "    name = str(row.get('name', 'Unknown')).strip()\n",
        "    games_type = row.get('games_type', 'Olympic')\n",
        "    athlete_id = row.get('athlete_id', '')\n",
        "    abbreviated = is_abbreviated(name)\n",
        "\n",
        "    # Header\n",
        "    lines = [\n",
        "        f\"You are researching Team USA {games_type} athletes.\",\n",
        "        f\"Given the following data, use Google Search to identify this athlete \"\n",
        "        f\"and write a profile.\",\n",
        "        \"\",\n",
        "        f\"=== ATHLETE DATA ===\",\n",
        "        f\"Name on file: {name}\" + (\" (likely abbreviated)\" if abbreviated else \"\"),\n",
        "    ]\n",
        "\n",
        "    # Structured facts\n",
        "    if pd.notna(row.get('primary_sport')) and str(row['primary_sport']) != 'nan':\n",
        "        lines.append(f\"Sport: {row['primary_sport']}\")\n",
        "    if pd.notna(row.get('classification_code')) and str(row['classification_code']) not in ('nan', 'None', ''):\n",
        "        lines.append(f\"Paralympic classification: {row['classification_code']}\")\n",
        "    if pd.notna(row.get('gender')) and str(row['gender']) not in ('nan', 'None'):\n",
        "        lines.append(f\"Gender: {row['gender']}\")\n",
        "    if pd.notna(row.get('birth_date')) and str(row['birth_date']) != 'nan':\n",
        "        lines.append(f\"Birth date: {row['birth_date']}\")\n",
        "\n",
        "    # Games info\n",
        "    if pd.notna(row.get('games_count')) and row['games_count'] > 0:\n",
        "        fy = int(row['first_games_year']) if pd.notna(row.get('first_games_year')) else '?'\n",
        "        ly = int(row['last_games_year']) if pd.notna(row.get('last_games_year')) else '?'\n",
        "        lines.append(f\"Games appearances: {int(row['games_count'])} ({fy}–{ly})\")\n",
        "\n",
        "    # Medals\n",
        "    medal_parts = []\n",
        "    for label, col in [('Gold', 'gold_count'), ('Silver', 'silver_count'), ('Bronze', 'bronze_count')]:\n",
        "        if pd.notna(row.get(col)) and row[col] > 0:\n",
        "            medal_parts.append(f\"{int(row[col])} {label}\")\n",
        "    if medal_parts:\n",
        "        lines.append(f\"Medals: {', '.join(medal_parts)}\")\n",
        "\n",
        "    # Event history from results table\n",
        "    events = event_lookup.get(athlete_id, [])\n",
        "    if events:\n",
        "        lines.append(f\"\\nEvent history:\")\n",
        "        for e in events[:20]:  # Cap at 20 to keep prompt manageable\n",
        "            lines.append(f\"  - {e}\")\n",
        "        if len(events) > 20:\n",
        "            lines.append(f\"  ... and {len(events) - 20} more events\")\n",
        "\n",
        "    # Bio fields (Paris 2024 Paralympic)\n",
        "    norm_key = norm_name(name)\n",
        "    bio = paris_para_bios.get(norm_key, {})\n",
        "    if bio:\n",
        "        lines.append(f\"\\nAdditional background:\")\n",
        "        for field, label in [('reason', 'Why they compete'), ('hero', 'Hero/inspiration'),\n",
        "                              ('philosophy', 'Philosophy'), ('other_sports', 'Other sports'),\n",
        "                              ('coach', 'Coach'), ('hobbies', 'Hobbies'),\n",
        "                              ('occupation', 'Occupation'), ('education', 'Education')]:\n",
        "            if field in bio:\n",
        "                lines.append(f\"  {label}: {bio[field]}\")\n",
        "\n",
        "    # Instructions\n",
        "    lines.append(f\"\\n=== INSTRUCTIONS ===\")\n",
        "    lines.append(\"Using Google Search and the data above, return ONLY valid JSON (no markdown, no backticks):\")\n",
        "    lines.append(\"\"\"\n",
        "{\n",
        "  \"verified_name\": \"Full Name\",\n",
        "  \"name_confidence\": \"high/medium/low\",\n",
        "  \"name_reasoning\": \"Brief explanation of how you identified this athlete\",\n",
        "  \"profile\": \"Two-paragraph profile, 150-250 words...\",\n",
        "  \"profile_confidence\": \"high/medium/low\"\n",
        "}\"\"\")\n",
        "\n",
        "    lines.append(f\"\\nName verification rules:\")\n",
        "    lines.append(f\"- The verified athlete MUST have represented the United States\")\n",
        "    lines.append(f\"- Sport and Games years must match the data on file\")\n",
        "    lines.append(f\"- The last name must match the name on file\")\n",
        "    if abbreviated:\n",
        "        first_token = name.split()[-1] if len(name.split()) >= 2 else ''\n",
        "        last_token = name.split()[0] if len(name.split()) >= 2 else ''\n",
        "        # katiepress format: \"LastName F\" — last token is the initial\n",
        "        if len(name.split()[-1]) <= 2:\n",
        "            lines.append(f\"- The first name must start with '{name.split()[-1]}'\")\n",
        "        elif len(name.split()[0]) <= 2:\n",
        "            lines.append(f\"- The first name must start with '{name.split()[0]}'\")\n",
        "    lines.append(f\"- If multiple athletes could match, set verified_name to \\\"UNVERIFIED\\\"\")\n",
        "    lines.append(f\"- If you cannot confidently identify the specific individual, set verified_name to \\\"UNVERIFIED\\\"\")\n",
        "    lines.append(f\"- A wrong name is WORSE than UNVERIFIED\")\n",
        "\n",
        "    lines.append(f\"\\nProfile guidelines:\")\n",
        "    lines.append(f\"- Paragraph 1: Athletic career — achievements, competition highlights, what makes them notable\")\n",
        "    lines.append(f\"- Paragraph 2: Personal background — how they entered their sport, training, what drives them\")\n",
        "    if pd.notna(row.get('classification_code')) and str(row['classification_code']) not in ('nan', 'None', ''):\n",
        "        lines.append(f\"- Briefly explain what classification {row['classification_code']} means in {row.get('primary_sport', 'their sport')}\")\n",
        "\n",
        "    return '\\n'.join(lines)\n",
        "\n",
        "\n",
        "def parse_gemini_response(response_text: str) -> dict:\n",
        "    \"\"\"Parse JSON from Gemini response, handling common formatting issues.\"\"\"\n",
        "    if not response_text:\n",
        "        return None\n",
        "\n",
        "    text = response_text.strip()\n",
        "\n",
        "    # Strip markdown code fences\n",
        "    if text.startswith('```'):\n",
        "        text = re.sub(r'^```(?:json)?\\s*', '', text)\n",
        "        text = re.sub(r'\\s*```$', '', text)\n",
        "\n",
        "    # Try direct parse\n",
        "    try:\n",
        "        return json.loads(text)\n",
        "    except json.JSONDecodeError:\n",
        "        pass\n",
        "\n",
        "    # Try to find JSON object in the response\n",
        "    match = re.search(r'\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}', text, re.DOTALL)\n",
        "    if match:\n",
        "        try:\n",
        "            return json.loads(match.group())\n",
        "        except json.JSONDecodeError:\n",
        "            pass\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def generate_profile(row, retries: int = ProfileConfig.MAX_RETRIES) -> dict:\n",
        "    \"\"\"Generate a profile + verified name with Google Search grounding. Returns dict.\"\"\"\n",
        "\n",
        "    prompt = create_profile_prompt(row)\n",
        "    name = str(row.get('name', 'Unknown')).strip()\n",
        "\n",
        "    config = types.GenerateContentConfig(\n",
        "        temperature=ProfileConfig.TEMPERATURE,\n",
        "        max_output_tokens=ProfileConfig.MAX_OUTPUT_TOKENS,\n",
        "        tools=[types.Tool(google_search=types.GoogleSearch())],\n",
        "        thinking_config=types.ThinkingConfig(thinking_budget=0),\n",
        "    )\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = get_client().models.generate_content(\n",
        "                model=ProfileConfig.MODEL_NAME,\n",
        "                contents=prompt,\n",
        "                config=config,\n",
        "            )\n",
        "\n",
        "            # Extract text from response\n",
        "            raw_text = None\n",
        "            if hasattr(response, 'text') and response.text:\n",
        "                raw_text = response.text\n",
        "            elif hasattr(response, 'candidates') and response.candidates:\n",
        "                candidate = response.candidates[0]\n",
        "                if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):\n",
        "                    parts = candidate.content.parts\n",
        "                    if parts and hasattr(parts[0], 'text'):\n",
        "                        raw_text = parts[0].text\n",
        "\n",
        "            if not raw_text:\n",
        "                if attempt < retries - 1:\n",
        "                    time.sleep(ProfileConfig.RETRY_DELAY)\n",
        "                    continue\n",
        "                return {\n",
        "                    'verified_name': name,\n",
        "                    'name_confidence': 'low',\n",
        "                    'name_reasoning': 'No API response',\n",
        "                    'profile': build_data_only_profile(row),\n",
        "                    'profile_confidence': 'data_only',\n",
        "                    'error': 'No text in API response'\n",
        "                }\n",
        "\n",
        "            # Parse JSON\n",
        "            parsed = parse_gemini_response(raw_text)\n",
        "\n",
        "            if parsed and 'profile' in parsed:\n",
        "                profile = str(parsed['profile']).strip()\n",
        "\n",
        "                # Validate profile length\n",
        "                if len(profile) < ProfileConfig.MIN_PROFILE_LENGTH:\n",
        "                    if attempt < retries - 1:\n",
        "                        time.sleep(ProfileConfig.RETRY_DELAY)\n",
        "                        continue\n",
        "\n",
        "                if len(profile) > ProfileConfig.MAX_PROFILE_LENGTH:\n",
        "                    profile = profile[:ProfileConfig.MAX_PROFILE_LENGTH] + \"...\"\n",
        "\n",
        "               # Clean whitespace\n",
        "                profile = re.sub(r'\\s+', ' ', profile).strip()\n",
        "                # Strip Gemini search citation artifacts like [1], [1, 2, 7], etc.\n",
        "                profile = re.sub(r'\\s*\\[[\\d,\\s]+\\]', '', profile)\n",
        "\n",
        "                # Detect refusal profiles and swap in data-only fallback\n",
        "                refusal_signals = ['could not be confidently', 'cannot be accurately',\n",
        "                                   'could not be identified', 'unable to verify',\n",
        "                                   'insufficient information', 'cannot be confirmed']\n",
        "                if any(signal in profile.lower() for signal in refusal_signals):\n",
        "                    profile = build_data_only_profile(row)\n",
        "                    return {\n",
        "                        'verified_name': name,  # Keep original\n",
        "                        'name_confidence': 'low',\n",
        "                        'name_reasoning': parsed.get('name_reasoning', 'Gemini returned refusal profile'),\n",
        "                        'profile': profile,\n",
        "                        'profile_confidence': 'data_only',\n",
        "                        'error': None\n",
        "                    }\n",
        "\n",
        "                verified = str(parsed.get('verified_name', name)).strip()\n",
        "                if verified.upper() == 'UNVERIFIED':\n",
        "                    verified = name  # Keep original\n",
        "\n",
        "                return {\n",
        "                    'verified_name': verified,\n",
        "                    'name_confidence': parsed.get('name_confidence', 'low'),\n",
        "                    'name_reasoning': str(parsed.get('name_reasoning', '')).strip(),\n",
        "                    'profile': profile,\n",
        "                    'profile_confidence': parsed.get('profile_confidence', 'low'),\n",
        "                    'error': None\n",
        "                }\n",
        "            else:\n",
        "                # Couldn't parse JSON — try using raw text as profile\n",
        "                if attempt < retries - 1:\n",
        "                    time.sleep(ProfileConfig.RETRY_DELAY)\n",
        "                    continue\n",
        "                return {\n",
        "                    'verified_name': name,\n",
        "                    'name_confidence': 'low',\n",
        "                    'name_reasoning': 'Could not parse JSON response',\n",
        "                    'profile': build_data_only_profile(row),\n",
        "                    'profile_confidence': 'data_only',\n",
        "                    'error': f'JSON parse failed. Raw: {raw_text[:200]}'\n",
        "                }\n",
        "\n",
        "        except Exception as e:\n",
        "            if attempt < retries - 1:\n",
        "                time.sleep(ProfileConfig.RETRY_DELAY * (attempt + 1))\n",
        "                continue\n",
        "            return {\n",
        "                'verified_name': name,\n",
        "                'name_confidence': 'low',\n",
        "                'name_reasoning': str(e),\n",
        "                'profile': build_data_only_profile(row),\n",
        "                'profile_confidence': 'data_only',\n",
        "                'error': f\"{type(e).__name__}: {str(e)}\"\n",
        "            }\n",
        "\n",
        "    return {\n",
        "        'verified_name': name,\n",
        "        'name_confidence': 'low',\n",
        "        'name_reasoning': 'Max retries exceeded',\n",
        "        'profile': build_data_only_profile(row),\n",
        "        'profile_confidence': 'data_only',\n",
        "        'error': 'Max retries exceeded'\n",
        "    }\n",
        "\n",
        "\n",
        "def log_error(athlete_id, name, error_msg, filename):\n",
        "    \"\"\"Log errors to CSV.\"\"\"\n",
        "    file_exists = Path(filename).exists()\n",
        "    with open(filename, 'a', newline='', encoding='utf-8') as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=['timestamp', 'athlete_id', 'name', 'error'])\n",
        "        if not file_exists:\n",
        "            writer.writeheader()\n",
        "        writer.writerow({\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'athlete_id': athlete_id,\n",
        "            'name': name,\n",
        "            'error': error_msg\n",
        "        })\n",
        "\n",
        "\n",
        "print(\"✅ Profile + name verification functions defined\")\n",
        "print(f\"   Abbreviated name example: {is_abbreviated('Smith J')} (Smith J)\")\n",
        "print(f\"   Full name example: {is_abbreviated('Jessica Smith')} (Jessica Smith)\")\n",
        "\n",
        "# Quick test of data-only fallback\n",
        "test_row = all_athletes.iloc[0]\n",
        "print(f\"\\n   Data-only fallback test:\")\n",
        "print(f\"   {build_data_only_profile(test_row)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYhqgp3tCOX5",
        "outputId": "1e2ebd49-a4c1-49b7-c6e0-9ecb6ff273cb"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Profile + name verification functions defined\n",
            "   Abbreviated name example: True (Smith J)\n",
            "   Full name example: False (Jessica Smith)\n",
            "\n",
            "   Data-only fallback test:\n",
            "   Khatuna Kvrivishvili-Lorig represented the United States as a Olympic athlete in Archery, from 2008 to 2012 across 2 Games.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 6, Step 4: Test with sample athletes ───────────────────\n",
        "\n",
        "test_cases = [\n",
        "    (\"Well-known Olympic\", all_athletes[\n",
        "        all_athletes['name'].str.contains('Simone', na=False) &\n",
        "        (all_athletes['games_type'] == 'Olympic')\n",
        "    ].head(1)),\n",
        "\n",
        "    (\"Abbreviated katiepress Paralympic\", all_athletes[\n",
        "        (all_athletes['games_type'] == 'Paralympic') &\n",
        "        (all_athletes['name'].apply(is_abbreviated)) &\n",
        "        (all_athletes['total_medals'] > 2)\n",
        "    ].sample(1, random_state=42)),\n",
        "\n",
        "    (\"Paris 2024 Paralympic (with bio)\", all_athletes[\n",
        "        (all_athletes['games_type'] == 'Paralympic') &\n",
        "        (all_athletes['name'].apply(\n",
        "            lambda n: norm_name(n) in paris_para_bios if pd.notna(n) else False\n",
        "        ))\n",
        "    ].sample(1, random_state=42)),\n",
        "]\n",
        "\n",
        "for label, test_df in test_cases:\n",
        "    if len(test_df) == 0:\n",
        "        print(f\"\\n⚠️  No test athlete found for: {label}\")\n",
        "        continue\n",
        "\n",
        "    row = test_df.iloc[0]\n",
        "    print(f\"\\n{'=' * 70}\")\n",
        "    print(f\"TEST: {label}\")\n",
        "    print(f\"  Name: {row['name']} | Sport: {row.get('primary_sport', 'N/A')}\")\n",
        "    print(f\"  Type: {row['games_type']} | Games: {row.get('games_count', '?')} ({row.get('first_games_year', '?')}–{row.get('last_games_year', '?')})\")\n",
        "    print(f\"  Medals: {row.get('total_medals', 0)} | Classification: {row.get('classification_code', 'N/A')}\")\n",
        "    print(f\"  Events in lookup: {len(event_lookup.get(row['athlete_id'], []))}\")\n",
        "    print(f\"  Abbreviated: {is_abbreviated(row['name'])}\")\n",
        "    print(f\"{'=' * 70}\")\n",
        "\n",
        "    # Show prompt preview\n",
        "    prompt = create_profile_prompt(row)\n",
        "    print(f\"\\nPrompt ({len(prompt)} chars, first 500):\")\n",
        "    print(prompt[:500])\n",
        "    print(\"...\\n\")\n",
        "\n",
        "    # Call Gemini\n",
        "    print(\"Calling Gemini + Google Search...\")\n",
        "    result = generate_profile(row)\n",
        "\n",
        "    print(f\"\\n  verified_name:    {result['verified_name']}\")\n",
        "    print(f\"  name_confidence:  {result['name_confidence']}\")\n",
        "    print(f\"  name_reasoning:   {result['name_reasoning'][:150]}\")\n",
        "    print(f\"  profile_confidence: {result['profile_confidence']}\")\n",
        "    print(f\"  error:            {result['error']}\")\n",
        "    print(f\"\\n  Profile ({len(result['profile'])} chars):\")\n",
        "    print(f\"  {result['profile'][:400]}\")\n",
        "    if len(result['profile']) > 400:\n",
        "        print(f\"  ...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGBLpSZ9C7Oq",
        "outputId": "7478df72-44eb-485f-9f5a-14337c14bc02"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TEST: Well-known Olympic\n",
            "  Name: Simone Schaller | Sport: Athletics\n",
            "  Type: Olympic | Games: 2.0 (1932.0–1936.0)\n",
            "  Medals: 0.0 | Classification: nan\n",
            "  Events in lookup: 2\n",
            "  Abbreviated: False\n",
            "======================================================================\n",
            "\n",
            "Prompt (1350 chars, first 500):\n",
            "You are researching Team USA Olympic athletes.\n",
            "Given the following data, use Google Search to identify this athlete and write a profile.\n",
            "\n",
            "=== ATHLETE DATA ===\n",
            "Name on file: Simone Schaller\n",
            "Sport: Athletics\n",
            "Gender: Female\n",
            "Birth date: 1912-08-22\n",
            "Games appearances: 2 (1932–1936)\n",
            "\n",
            "Event history:\n",
            "  - 80 metres Hurdles, Women (Olympic) (1932)\n",
            "  - 80 metres Hurdles, Women (Olympic) (1936)\n",
            "\n",
            "=== INSTRUCTIONS ===\n",
            "Using Google Search and the data above, return ONLY valid JSON (no markdown, no backticks):\n",
            "\n",
            "\n",
            "...\n",
            "\n",
            "Calling Gemini + Google Search...\n",
            "\n",
            "  verified_name:    Simone Schaller\n",
            "  name_confidence:  high\n",
            "  name_reasoning:   The athlete's full name, birth date, sport, gender, and Olympic appearances (years and events) all perfectly match the provided data. Multiple sources\n",
            "  profile_confidence: high\n",
            "  error:            None\n",
            "\n",
            "  Profile (1242 chars):\n",
            "  Simone Schaller, born August 22, 1912, was an American hurdler who represented the United States in two Olympic Games. She competed in the 80-meter hurdles in both the 1932 Los Angeles Olympics and the 1936 Berlin Olympics. In her home country games in 1932, Schaller finished a controversial fourth, reportedly tying a world record with teammate Babe Didrikson Zaharias in the preliminary heats. Fou\n",
            "  ...\n",
            "\n",
            "======================================================================\n",
            "TEST: Abbreviated katiepress Paralympic\n",
            "  Name: Strole M | Sport: Swimming\n",
            "  Type: Paralympic | Games: 1.0 (1976.0–1976.0)\n",
            "  Medals: 5.0 | Classification: None\n",
            "  Events in lookup: 5\n",
            "  Abbreviated: True\n",
            "======================================================================\n",
            "\n",
            "Prompt (1544 chars, first 500):\n",
            "You are researching Team USA Paralympic athletes.\n",
            "Given the following data, use Google Search to identify this athlete and write a profile.\n",
            "\n",
            "=== ATHLETE DATA ===\n",
            "Name on file: Strole M (likely abbreviated)\n",
            "Sport: Swimming\n",
            "Gender: Female\n",
            "Games appearances: 1 (1976–1976)\n",
            "Medals: 4 Silver, 1 Bronze\n",
            "\n",
            "Event history:\n",
            "  - Women's Shot Put 4 (1976) — Silver\n",
            "  - Women's Javelin 4 (1976) — Silver\n",
            "  - Women's 3x50 m Medley Relay 2-4 (1976) — Bronze\n",
            "  - Women's 50 m Freestyle 4 (1976) — Silver\n",
            "  - Women's 4\n",
            "...\n",
            "\n",
            "Calling Gemini + Google Search...\n",
            "\n",
            "  verified_name:    Mickey Strole\n",
            "  name_confidence:  high\n",
            "  name_reasoning:   The athlete data precisely matches 'Mickey Strole' who competed for the United States in the 1976 Paralympics, earning 4 silver and 1 bronze medal acr\n",
            "  profile_confidence: medium\n",
            "  error:            None\n",
            "\n",
            "  Profile (1174 chars):\n",
            "  Mickey Strole was a prominent American Paralympic athlete who made a significant impact at the 1976 Toronto Paralympic Games. Representing Team USA, Strole showcased remarkable versatility and skill, securing five medals in total. Her impressive performance included four silver medals: in the Women's Shot Put 4, Women's Javelin 4, Women's 50 m Freestyle 4, and the Women's 4x50 m Freestyle Relay 2-\n",
            "  ...\n",
            "\n",
            "======================================================================\n",
            "TEST: Paris 2024 Paralympic (with bio)\n",
            "  Name: Jarryd Wallace | Sport: Athletics\n",
            "  Type: Paralympic | Games: 2.0 (2020.0–2024.0)\n",
            "  Medals: 0.0 | Classification: T64\n",
            "  Events in lookup: 0\n",
            "  Abbreviated: False\n",
            "======================================================================\n",
            "\n",
            "Prompt (2194 chars, first 500):\n",
            "You are researching Team USA Paralympic athletes.\n",
            "Given the following data, use Google Search to identify this athlete and write a profile.\n",
            "\n",
            "=== ATHLETE DATA ===\n",
            "Name on file: Jarryd Wallace\n",
            "Sport: Athletics\n",
            "Paralympic classification: T64\n",
            "Gender: Male\n",
            "Birth date: 1990-05-15\n",
            "Games appearances: 2 (2020–2024)\n",
            "\n",
            "Additional background:\n",
            "  Why they compete: He was an 800m and 1600m high school athletics state champion and, after he acquired his impairment, he looked at the world record lists for Para at\n",
            "...\n",
            "\n",
            "Calling Gemini + Google Search...\n",
            "\n",
            "  verified_name:    Jarryd Wallace\n",
            "  name_confidence:  high\n",
            "  name_reasoning:   The search results consistently identify Jarryd Wallace as a Team USA Paralympic athlete in Athletics with a T64 classification. His birth date (May 1\n",
            "  profile_confidence: high\n",
            "  error:            None\n",
            "\n",
            "  Profile (1466 chars):\n",
            "  Jarryd Wallace is a highly accomplished Team USA Paralympic athlete in Athletics, competing in the T64 classification. He is a two-time Paralympic medalist, earning bronze in the 200m T64 at the 2020 Tokyo Games and a second bronze in the long jump T64 at the 2024 Paris Paralympic Games. Wallace has also achieved significant success at the World Championships, securing five medals, including three\n",
            "  ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 6, Step 5: Embedding functions + test ──────────────────\n",
        "\n",
        "def create_embedding_text(row, profile: str) -> str:\n",
        "    \"\"\"Create rich text for embedding from structured data + profile.\"\"\"\n",
        "\n",
        "    name = str(row.get('name', 'Unknown')).strip()\n",
        "    parts = [f\"Team USA {row.get('games_type', '')} athlete: {name}\"]\n",
        "\n",
        "    if pd.notna(row.get('primary_sport')) and str(row['primary_sport']) != 'nan':\n",
        "        parts.append(f\"Sport: {row['primary_sport']}\")\n",
        "    if pd.notna(row.get('classification_code')) and str(row['classification_code']) not in ('nan', 'None', ''):\n",
        "        parts.append(f\"Classification: {row['classification_code']}\")\n",
        "    if pd.notna(row.get('games_count')) and row['games_count'] > 0:\n",
        "        year_str = \"\"\n",
        "        if pd.notna(row.get('first_games_year')) and pd.notna(row.get('last_games_year')):\n",
        "            fy, ly = int(row['first_games_year']), int(row['last_games_year'])\n",
        "            year_str = f\" ({fy}–{ly})\"\n",
        "        medal_str = \"\"\n",
        "        if pd.notna(row.get('total_medals')) and row['total_medals'] > 0:\n",
        "            medal_str = f\", {int(row['total_medals'])} medals\"\n",
        "        parts.append(f\"Career: {int(row['games_count'])} Games{year_str}{medal_str}\")\n",
        "\n",
        "    # Add profile if it's a real Gemini-generated one (data-only fallbacks are redundant)\n",
        "    if profile and not profile.startswith('[Profile generation failed'):\n",
        "        parts.append(f\"Profile: {profile}\")\n",
        "\n",
        "    return \". \".join(parts)\n",
        "\n",
        "\n",
        "def generate_embedding(text: str, retries: int = EmbeddingConfig.MAX_RETRIES) -> Tuple[Optional[List[float]], Optional[str]]:\n",
        "    \"\"\"Generate embedding for text.\"\"\"\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = get_client().models.embed_content(\n",
        "                model=EmbeddingConfig.MODEL_NAME,\n",
        "                contents=text,\n",
        "                config=types.EmbedContentConfig(\n",
        "                    output_dimensionality=EmbeddingConfig.OUTPUT_DIMENSION\n",
        "                )\n",
        "            )\n",
        "\n",
        "            if hasattr(response, 'embeddings') and response.embeddings:\n",
        "                embedding = response.embeddings[0]\n",
        "                if hasattr(embedding, 'values') and embedding.values:\n",
        "                    return list(embedding.values), None\n",
        "\n",
        "            if attempt < retries - 1:\n",
        "                time.sleep(EmbeddingConfig.RETRY_DELAY)\n",
        "                continue\n",
        "            return None, \"No embedding values in response\"\n",
        "\n",
        "        except Exception as e:\n",
        "            if attempt < retries - 1:\n",
        "                time.sleep(EmbeddingConfig.RETRY_DELAY * (attempt + 1))\n",
        "                continue\n",
        "            return None, f\"{type(e).__name__}: {str(e)}\"\n",
        "\n",
        "    return None, \"Max retries exceeded\"\n",
        "\n",
        "\n",
        "# ── Quick test ───────────────────────────────────────────────────\n",
        "test_row = all_athletes.iloc[0]\n",
        "test_profile = \"A decorated Olympic archer who represented the United States across multiple Games.\"\n",
        "\n",
        "text = create_embedding_text(test_row, test_profile)\n",
        "print(f\"Embedding text ({len(text)} chars):\")\n",
        "print(f\"  {text[:300]}\")\n",
        "if len(text) > 300:\n",
        "    print(f\"  ...\")\n",
        "\n",
        "print(f\"\\nCalling embedding API ({EmbeddingConfig.OUTPUT_DIMENSION} dims)...\")\n",
        "embedding, error = generate_embedding(text)\n",
        "\n",
        "if embedding:\n",
        "    print(f\"✅ Success!\")\n",
        "    print(f\"   Dimensions: {len(embedding)}\")\n",
        "    print(f\"   Expected:   {EmbeddingConfig.OUTPUT_DIMENSION}\")\n",
        "    print(f\"   First 5:    {[f'{v:.6f}' for v in embedding[:5]]}\")\n",
        "    print(f\"   ✓ Dimension check: {'PASS' if len(embedding) == EmbeddingConfig.OUTPUT_DIMENSION else 'FAIL'}\")\n",
        "else:\n",
        "    print(f\"❌ Error: {error}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqE0jXzTFtqB",
        "outputId": "fad7f06b-6829-4462-8d89-ff863265aa6c"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding text (191 chars):\n",
            "  Team USA Olympic athlete: Khatuna Kvrivishvili-Lorig. Sport: Archery. Career: 2 Games (2008–2012). Profile: A decorated Olympic archer who represented the United States across multiple Games.\n",
            "\n",
            "Calling embedding API (3072 dims)...\n",
            "✅ Success!\n",
            "   Dimensions: 3072\n",
            "   Expected:   3072\n",
            "   First 5:    ['0.003113', '0.006287', '-0.007408', '-0.054036', '-0.000653']\n",
            "   ✓ Dimension check: PASS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 6, Step 6: Parallel profile generation — full run ──────\n",
        "\n",
        "def process_single_profile(idx_row) -> dict:\n",
        "    \"\"\"Process a single athlete for profile + name verification.\"\"\"\n",
        "    idx, row = idx_row\n",
        "    athlete_id = row['athlete_id']\n",
        "    name = str(row.get('name', 'Unknown')).strip()\n",
        "\n",
        "    result = generate_profile(row)\n",
        "    result['athlete_id'] = athlete_id\n",
        "    result['original_name'] = name\n",
        "\n",
        "    if result.get('error'):\n",
        "        log_error(athlete_id, name, result['error'], ProfileConfig.ERROR_LOG)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def save_profile_progress(results, filename):\n",
        "    \"\"\"Save profile progress to CSV.\"\"\"\n",
        "    df = pd.DataFrame(results)\n",
        "    cols = ['athlete_id', 'original_name', 'verified_name', 'name_confidence',\n",
        "            'name_reasoning', 'profile', 'profile_confidence', 'error']\n",
        "    cols = [c for c in cols if c in df.columns]\n",
        "    df[cols].to_csv(filename, index=False, encoding='utf-8', quoting=csv.QUOTE_ALL)\n",
        "    print(f\"  💾 Progress: {filename} ({len(df):,} profiles)\")\n",
        "\n",
        "\n",
        "def generate_all_profiles(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Generate profiles for all athletes with parallel processing + resume.\"\"\"\n",
        "\n",
        "    results = []\n",
        "    errors = []\n",
        "    processed_ids = set()\n",
        "\n",
        "    # Resume from progress — only count error-free entries as done\n",
        "    progress_path = Path(ProfileConfig.PROGRESS_FILE)\n",
        "    if progress_path.exists():\n",
        "        print(f\"\\n📂 Found progress file: {ProfileConfig.PROGRESS_FILE}\")\n",
        "        df_progress = pd.read_csv(ProfileConfig.PROGRESS_FILE)\n",
        "\n",
        "        # Successful = no error at all (including intentional data_only with no error)\n",
        "        successful = df_progress[df_progress['error'].isna() | (df_progress['error'] == '')]\n",
        "        failed = df_progress[df_progress['error'].notna() & (df_progress['error'] != '')]\n",
        "        processed_ids = set(successful['athlete_id'])\n",
        "\n",
        "        for _, row in successful.iterrows():\n",
        "            results.append({\n",
        "                'athlete_id': row['athlete_id'],\n",
        "                'original_name': row.get('original_name', ''),\n",
        "                'verified_name': row.get('verified_name', ''),\n",
        "                'name_confidence': row.get('name_confidence', ''),\n",
        "                'name_reasoning': row.get('name_reasoning', ''),\n",
        "                'profile': row.get('profile', ''),\n",
        "                'profile_confidence': row.get('profile_confidence', ''),\n",
        "                'error': None\n",
        "            })\n",
        "\n",
        "        print(f\"  ✅ Loaded {len(processed_ids):,} successful profiles\")\n",
        "        print(f\"  🔄 Will retry {len(failed):,} failed profiles (429s, timeouts, etc.)\")\n",
        "\n",
        "    # Filter to unprocessed + failed\n",
        "    df_todo = df[~df['athlete_id'].isin(processed_ids)].copy()\n",
        "\n",
        "    if len(df_todo) == 0:\n",
        "        print(f\"\\n✅ All profiles already generated!\")\n",
        "        return pd.DataFrame(results)\n",
        "\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"Starting PARALLEL profile generation\")\n",
        "    print(f\"  Total athletes:      {len(df):,}\")\n",
        "    print(f\"  Already processed:   {len(processed_ids):,}\")\n",
        "    print(f\"  To process:          {len(df_todo):,}\")\n",
        "    print(f\"  Workers:             {ProfileConfig.MAX_WORKERS}\")\n",
        "    print(f\"  Model:               {ProfileConfig.MODEL_NAME} + Google Search\")\n",
        "    print(f\"{'=' * 60}\\n\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    rows_to_process = list(df_todo.iterrows())\n",
        "    total_batches = (len(rows_to_process) + ProfileConfig.BATCH_SIZE - 1) // ProfileConfig.BATCH_SIZE\n",
        "\n",
        "    with tqdm(total=len(rows_to_process), desc=\"Generating profiles\") as pbar:\n",
        "        for batch_num in range(total_batches):\n",
        "            start_idx = batch_num * ProfileConfig.BATCH_SIZE\n",
        "            end_idx = min(start_idx + ProfileConfig.BATCH_SIZE, len(rows_to_process))\n",
        "            batch = rows_to_process[start_idx:end_idx]\n",
        "\n",
        "            with ThreadPoolExecutor(max_workers=ProfileConfig.MAX_WORKERS) as executor:\n",
        "                futures = {executor.submit(process_single_profile, item): item for item in batch}\n",
        "\n",
        "                for future in as_completed(futures):\n",
        "                    result = future.result()\n",
        "                    results.append(result)\n",
        "                    if result.get('error'):\n",
        "                        errors.append(result['athlete_id'])\n",
        "                    pbar.update(1)\n",
        "\n",
        "            # Checkpoint\n",
        "            if (batch_num + 1) % max(1, ProfileConfig.SAVE_INTERVAL // ProfileConfig.BATCH_SIZE) == 0 \\\n",
        "               or end_idx == len(rows_to_process):\n",
        "                save_profile_progress(results, ProfileConfig.PROGRESS_FILE)\n",
        "\n",
        "    # Final save\n",
        "    save_profile_progress(results, ProfileConfig.PROGRESS_FILE)\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"Profile Generation Complete!\")\n",
        "    print(f\"{'=' * 60}\")\n",
        "    print(f\"  Newly processed: {len(df_todo):,}\")\n",
        "    print(f\"  Total profiles:  {len(results):,}\")\n",
        "    print(f\"  Successful:      {len(results) - len(errors):,}\")\n",
        "    print(f\"  Errors:          {len(errors):,}\")\n",
        "    if len(df_todo) > 0:\n",
        "        print(f\"  Time:            {elapsed/60:.1f} minutes\")\n",
        "        print(f\"  Throughput:      {len(df_todo)/elapsed*60:.1f} athletes/minute\")\n",
        "    if errors:\n",
        "        print(f\"  Error rate:      {len(errors)/len(results)*100:.1f}%\")\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "\n",
        "# ── Run it ───────────────────────────────────────────────────────\n",
        "df_profiles = generate_all_profiles(all_athletes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517,
          "referenced_widgets": [
            "e4f1783329914747a1f1abc6e79a7336",
            "3e7b0e153c304dbd97481325b03b089f",
            "6382b2f7134d48a0b105a7c8a8b9fdd4",
            "c81bbcc101894c23958b313167a1f50d",
            "b40b362554704dc6b685224a616eb3e2",
            "8a2dce8d745b4c0ba77171dfc4fe0cf9",
            "4147caea37b34acc9fb0471a8946cc11",
            "747db6b4e2ab4d6b9cd990f66fa53b15",
            "3226e6a2c90d485d8feb4c444017d9be",
            "205ebf448084447e8de4fe70b56220b4",
            "51b9c3927b0446fc869ad5ccb83ab711"
          ]
        },
        "id": "zk8pGza4FxOS",
        "outputId": "daa72662-be5a-4afa-ffb4-45b0522d1e10"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📂 Found progress file: /tmp/v2_athlete_profiles_progress.csv\n",
            "  ✅ Loaded 12,206 successful profiles\n",
            "  🔄 Will retry 1 failed profiles (429s, timeouts, etc.)\n",
            "\n",
            "============================================================\n",
            "Starting PARALLEL profile generation\n",
            "  Total athletes:      12,207\n",
            "  Already processed:   12,206\n",
            "  To process:          1\n",
            "  Workers:             50\n",
            "  Model:               gemini-2.5-flash + Google Search\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating profiles:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4f1783329914747a1f1abc6e79a7336"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  💾 Progress: /tmp/v2_athlete_profiles_progress.csv (12,207 profiles)\n",
            "  💾 Progress: /tmp/v2_athlete_profiles_progress.csv (12,207 profiles)\n",
            "\n",
            "============================================================\n",
            "Profile Generation Complete!\n",
            "============================================================\n",
            "  Newly processed: 1\n",
            "  Total profiles:  12,207\n",
            "  Successful:      12,206\n",
            "  Errors:          1\n",
            "  Time:            0.2 minutes\n",
            "  Throughput:      6.2 athletes/minute\n",
            "  Error rate:      0.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Patch the 8 NaN profiles with data-only fallbacks\n",
        "patched = 0\n",
        "for idx, row in df_profiles.iterrows():\n",
        "    if not isinstance(row['profile'], str) or pd.isna(row['profile']):\n",
        "        aid = row['athlete_id']\n",
        "        ath_row = all_athletes[all_athletes['athlete_id'] == aid]\n",
        "        if len(ath_row) > 0:\n",
        "            df_profiles.at[idx, 'profile'] = build_data_only_profile(ath_row.iloc[0])\n",
        "            df_profiles.at[idx, 'profile_confidence'] = 'data_only'\n",
        "            patched += 1\n",
        "\n",
        "# Rebuild profile lookup\n",
        "profile_lookup = dict(zip(df_profiles['athlete_id'], df_profiles['profile']))\n",
        "\n",
        "# Verify\n",
        "still_bad = df_profiles[df_profiles['profile'].isna() | df_profiles['profile'].apply(lambda x: not isinstance(x, str))]\n",
        "print(f\"Patched: {patched}\")\n",
        "print(f\"Remaining non-string profiles: {len(still_bad)}\")\n",
        "\n",
        "# Save updated progress\n",
        "save_profile_progress(df_profiles.to_dict('records'), ProfileConfig.PROGRESS_FILE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcap2o51z1IY",
        "outputId": "fcf87c5e-0bfa-48f4-97ef-6e0d7100c0d8"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patched: 8\n",
            "Remaining non-string profiles: 0\n",
            "  💾 Progress: /tmp/v2_athlete_profiles_progress.csv (12,207 profiles)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for NaN profiles in df_profiles\n",
        "nan_profiles = df_profiles[df_profiles['profile'].isna() | (df_profiles['profile'].apply(lambda x: not isinstance(x, str)))]\n",
        "print(f\"Non-string profiles in df_profiles: {len(nan_profiles)}\")\n",
        "if len(nan_profiles) > 0:\n",
        "    print(nan_profiles[['original_name', 'verified_name', 'name_confidence', 'profile_confidence', 'error']].to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p0ehrTLzrvc",
        "outputId": "e90940ec-8512-4684-9c31-7ee3eb863a8f"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-string profiles in df_profiles: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 6, Step 7: Parallel embedding generation — full run ────\n",
        "\n",
        "# Build profile lookup from completed profiles\n",
        "profile_lookup = dict(zip(df_profiles['athlete_id'], df_profiles['profile']))\n",
        "\n",
        "\n",
        "def process_single_embedding(item) -> dict:\n",
        "    \"\"\"Process a single athlete for embedding.\"\"\"\n",
        "    athlete_id, row, profile = item\n",
        "\n",
        "    text = create_embedding_text(row, profile)\n",
        "    embedding, error = generate_embedding(text)\n",
        "\n",
        "    if embedding:\n",
        "        return {'athlete_id': athlete_id, 'embedding': embedding, 'error': None}\n",
        "    else:\n",
        "        name = str(row.get('name', 'Unknown')).strip()\n",
        "        log_error(athlete_id, name, error, EmbeddingConfig.ERROR_LOG)\n",
        "        return {'athlete_id': athlete_id, 'embedding': None, 'error': error}\n",
        "\n",
        "\n",
        "def save_embedding_progress(results, filename):\n",
        "    \"\"\"Save embedding progress to CSV.\"\"\"\n",
        "    df = pd.DataFrame([r for r in results if r['embedding'] is not None])\n",
        "    if len(df) > 0:\n",
        "        df['embedding'] = df['embedding'].apply(json.dumps)\n",
        "        df[['athlete_id', 'embedding']].to_csv(filename, index=False, encoding='utf-8')\n",
        "    print(f\"  💾 Progress: {filename} ({len(df):,} embeddings)\")\n",
        "\n",
        "\n",
        "def generate_all_embeddings(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Generate embeddings for all athletes with parallel processing + resume.\"\"\"\n",
        "\n",
        "    results = []\n",
        "    errors = []\n",
        "    processed_ids = set()\n",
        "\n",
        "    # Resume from progress\n",
        "    progress_path = Path(EmbeddingConfig.PROGRESS_FILE)\n",
        "    if progress_path.exists():\n",
        "        print(f\"\\n📂 Found progress file: {EmbeddingConfig.PROGRESS_FILE}\")\n",
        "        df_progress = pd.read_csv(EmbeddingConfig.PROGRESS_FILE)\n",
        "        df_progress['embedding'] = df_progress['embedding'].apply(\n",
        "            lambda x: json.loads(x) if isinstance(x, str) and x.startswith('[') else None)\n",
        "        successful = df_progress[df_progress['embedding'].notna()]\n",
        "        processed_ids = set(successful['athlete_id'])\n",
        "\n",
        "        for _, row in successful.iterrows():\n",
        "            results.append({\n",
        "                'athlete_id': row['athlete_id'],\n",
        "                'embedding': row['embedding'],\n",
        "                'error': None\n",
        "            })\n",
        "        print(f\"  ✅ Loaded {len(successful):,} embeddings\")\n",
        "\n",
        "    # Filter to unprocessed\n",
        "    df_todo = df[~df['athlete_id'].isin(processed_ids)].copy()\n",
        "\n",
        "    if len(df_todo) == 0:\n",
        "        print(f\"\\n✅ All embeddings already generated!\")\n",
        "        return pd.DataFrame(results)\n",
        "\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"Starting PARALLEL embedding generation\")\n",
        "    print(f\"  Total athletes:      {len(df):,}\")\n",
        "    print(f\"  Already processed:   {len(processed_ids):,}\")\n",
        "    print(f\"  To process:          {len(df_todo):,}\")\n",
        "    print(f\"  Workers:             {EmbeddingConfig.MAX_WORKERS}\")\n",
        "    print(f\"  Model:               {EmbeddingConfig.MODEL_NAME}\")\n",
        "    print(f\"  Dimensions:          {EmbeddingConfig.OUTPUT_DIMENSION}\")\n",
        "    print(f\"{'=' * 60}\\n\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Build items: (athlete_id, row, profile)\n",
        "    items = []\n",
        "    for idx, row in df_todo.iterrows():\n",
        "        profile = profile_lookup.get(row['athlete_id'], '')\n",
        "        items.append((row['athlete_id'], row, profile))\n",
        "\n",
        "    total_batches = (len(items) + EmbeddingConfig.BATCH_SIZE - 1) // EmbeddingConfig.BATCH_SIZE\n",
        "\n",
        "    with tqdm(total=len(items), desc=\"Generating embeddings\") as pbar:\n",
        "        for batch_num in range(total_batches):\n",
        "            start_idx = batch_num * EmbeddingConfig.BATCH_SIZE\n",
        "            end_idx = min(start_idx + EmbeddingConfig.BATCH_SIZE, len(items))\n",
        "            batch = items[start_idx:end_idx]\n",
        "\n",
        "            with ThreadPoolExecutor(max_workers=EmbeddingConfig.MAX_WORKERS) as executor:\n",
        "                futures = {executor.submit(process_single_embedding, item): item for item in batch}\n",
        "\n",
        "                for future in as_completed(futures):\n",
        "                    result = future.result()\n",
        "                    results.append(result)\n",
        "                    if result['error']:\n",
        "                        errors.append(result['athlete_id'])\n",
        "                    pbar.update(1)\n",
        "\n",
        "            if (batch_num + 1) % max(1, EmbeddingConfig.SAVE_INTERVAL // EmbeddingConfig.BATCH_SIZE) == 0 \\\n",
        "               or end_idx == len(items):\n",
        "                save_embedding_progress(results, EmbeddingConfig.PROGRESS_FILE)\n",
        "\n",
        "    # Final save\n",
        "    save_embedding_progress(results, EmbeddingConfig.PROGRESS_FILE)\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"Embedding Generation Complete!\")\n",
        "    print(f\"{'=' * 60}\")\n",
        "    print(f\"  Newly processed: {len(df_todo):,}\")\n",
        "    print(f\"  Total embeddings: {len([r for r in results if r['embedding']]):,}\")\n",
        "    print(f\"  Errors:           {len(errors):,}\")\n",
        "    if len(df_todo) > 0:\n",
        "        print(f\"  Time:             {elapsed/60:.1f} minutes\")\n",
        "        print(f\"  Throughput:       {len(df_todo)/elapsed*60:.1f} athletes/minute\")\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "\n",
        "# ── Run it ───────────────────────────────────────────────────────\n",
        "df_embeddings = generate_all_embeddings(all_athletes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fe3a10b144ef476e99e4750080e85623",
            "13b3ef126f34442184eec574caf14e43",
            "f95dbcc08f574df2972f089bfb4a2dd6",
            "2ef8e9b9ab6945918597fc794083a75c",
            "a5b37ffb23c745beab9da8f3ab4cde17",
            "6d9cb69ad6f24c48b112c3865f74f91c",
            "bccc58f467074529b22a5bda0a4a7f0a",
            "7e2e6309f0b74307962c2d3a72e2a91e",
            "2964373babba4034a151b8d3a8a0247e",
            "2b1608ba455e4796b4f17e1ea2528654",
            "f4806c6a8d064ebb9c999097522c0d89"
          ]
        },
        "id": "SllhXggLGGf1",
        "outputId": "eea9c695-09f9-403d-99d2-93939a5ba7ef"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📂 Found progress file: /tmp/v2_athlete_embeddings_progress.csv\n",
            "  ✅ Loaded 1,200 embeddings\n",
            "\n",
            "============================================================\n",
            "Starting PARALLEL embedding generation\n",
            "  Total athletes:      12,207\n",
            "  Already processed:   1,200\n",
            "  To process:          11,007\n",
            "  Workers:             75\n",
            "  Model:               gemini-embedding-001\n",
            "  Dimensions:          3072\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/11007 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe3a10b144ef476e99e4750080e85623"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (1,400 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (1,600 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (1,800 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (2,000 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (2,200 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (2,400 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (2,600 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (2,800 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (3,000 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (3,200 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (3,400 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (3,600 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (3,800 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (4,000 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (4,200 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (4,400 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (4,600 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (4,800 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (5,000 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (5,200 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (5,400 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (5,600 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (5,800 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (6,000 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (6,200 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (6,400 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (6,600 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (6,800 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (7,000 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (7,200 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (7,400 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (7,600 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (7,800 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (8,000 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (8,200 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (8,400 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (8,600 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (8,800 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (9,000 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (9,200 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (9,400 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (9,600 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (9,800 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (10,000 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (10,200 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (10,400 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (10,600 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (10,800 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (11,000 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (11,200 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (11,400 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (11,600 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (11,800 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (12,000 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (12,200 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (12,207 embeddings)\n",
            "  💾 Progress: /tmp/v2_athlete_embeddings_progress.csv (12,207 embeddings)\n",
            "\n",
            "============================================================\n",
            "Embedding Generation Complete!\n",
            "============================================================\n",
            "  Newly processed: 11,007\n",
            "  Total embeddings: 12,207\n",
            "  Errors:           0\n",
            "  Time:             41.7 minutes\n",
            "  Throughput:       264.1 athletes/minute\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 6, Step 8: Profile + Embedding QC ─────────────────────\n",
        "\n",
        "print('=' * 70)\n",
        "print('PHASE 6 QC: GEMINI ENRICHMENT')\n",
        "print('=' * 70)\n",
        "\n",
        "# ── PROFILE SUMMARIES ────────────────────────────────────────────\n",
        "print(f'\\n{\"─\" * 70}')\n",
        "print('PROFILE SUMMARIES')\n",
        "print(f'{\"─\" * 70}')\n",
        "\n",
        "total = len(df_profiles)\n",
        "has_error = df_profiles['error'].notna() & (df_profiles['error'] != '')\n",
        "data_only = df_profiles['profile_confidence'] == 'data_only'\n",
        "gemini_profiles = ~has_error & ~data_only\n",
        "\n",
        "print(f'\\n📊 COUNTS')\n",
        "print(f'  Total:              {total:,}')\n",
        "print(f'  Gemini-generated:   {gemini_profiles.sum():,} ({gemini_profiles.sum()/total*100:.1f}%)')\n",
        "print(f'  Data-only fallback: {data_only.sum():,} ({data_only.sum()/total*100:.1f}%)')\n",
        "print(f'  Errors:             {has_error.sum():,} ({has_error.sum()/total*100:.1f}%)')\n",
        "\n",
        "if gemini_profiles.sum() > 0:\n",
        "    lengths = df_profiles.loc[gemini_profiles, 'profile'].str.len()\n",
        "    print(f'\\n📏 PROFILE LENGTH (Gemini-generated)')\n",
        "    print(f'  Min:    {lengths.min():,} chars')\n",
        "    print(f'  Max:    {lengths.max():,} chars')\n",
        "    print(f'  Mean:   {lengths.mean():,.0f} chars')\n",
        "    print(f'  Median: {lengths.median():,.0f} chars')\n",
        "\n",
        "# ── NAME VERIFICATION ────────────────────────────────────────────\n",
        "print(f'\\n{\"─\" * 70}')\n",
        "print('NAME VERIFICATION')\n",
        "print(f'{\"─\" * 70}')\n",
        "\n",
        "print(f'\\n🏷️ NAME CONFIDENCE')\n",
        "print(df_profiles['name_confidence'].value_counts().to_string())\n",
        "\n",
        "name_changed = df_profiles['verified_name'] != df_profiles['original_name']\n",
        "print(f'\\n🔄 NAME CHANGES')\n",
        "print(f'  Names updated:    {name_changed.sum():,}')\n",
        "print(f'  Names unchanged:  {(~name_changed).sum():,}')\n",
        "\n",
        "# Show name changes by confidence\n",
        "if name_changed.sum() > 0:\n",
        "    changed = df_profiles[name_changed]\n",
        "    print(f'\\n  By confidence:')\n",
        "    print(f'    High:   {(changed[\"name_confidence\"] == \"high\").sum():,}')\n",
        "    print(f'    Medium: {(changed[\"name_confidence\"] == \"medium\").sum():,}')\n",
        "    print(f'    Low:    {(changed[\"name_confidence\"] == \"low\").sum():,}')\n",
        "\n",
        "    print(f'\\n  Sample name changes (high confidence, first 10):')\n",
        "    high_changes = changed[changed['name_confidence'] == 'high'].head(10)\n",
        "    for _, r in high_changes.iterrows():\n",
        "        print(f'    {r[\"original_name\"]:25s} → {r[\"verified_name\"]}')\n",
        "\n",
        "# ── PROFILE CONFIDENCE ───────────────────────────────────────────\n",
        "print(f'\\n{\"─\" * 70}')\n",
        "print('PROFILE CONFIDENCE')\n",
        "print(f'{\"─\" * 70}')\n",
        "print(df_profiles['profile_confidence'].value_counts().to_string())\n",
        "\n",
        "# ── BY GAMES TYPE ────────────────────────────────────────────────\n",
        "print(f'\\n{\"─\" * 70}')\n",
        "print('BREAKDOWN BY GAMES TYPE')\n",
        "print(f'{\"─\" * 70}')\n",
        "\n",
        "merged = df_profiles.merge(\n",
        "    all_athletes[['athlete_id', 'games_type', 'name']].rename(columns={'name': 'ath_name'}),\n",
        "    on='athlete_id', how='left'\n",
        ")\n",
        "\n",
        "for gt in ['Olympic', 'Paralympic']:\n",
        "    sub = merged[merged['games_type'] == gt]\n",
        "    gem = (sub['profile_confidence'] != 'data_only') & (sub['error'].isna() | (sub['error'] == ''))\n",
        "    do = sub['profile_confidence'] == 'data_only'\n",
        "    err = sub['error'].notna() & (sub['error'] != '')\n",
        "    nc = sub['verified_name'] != sub['original_name']\n",
        "    print(f'\\n  {gt}:')\n",
        "    print(f'    Total:            {len(sub):,}')\n",
        "    print(f'    Gemini profiles:  {gem.sum():,}')\n",
        "    print(f'    Data-only:        {do.sum():,}')\n",
        "    print(f'    Errors:           {err.sum():,}')\n",
        "    print(f'    Names updated:    {nc.sum():,}')\n",
        "\n",
        "# ── EMBEDDINGS ───────────────────────────────────────────────────\n",
        "print(f'\\n{\"─\" * 70}')\n",
        "print('EMBEDDINGS')\n",
        "print(f'{\"─\" * 70}')\n",
        "\n",
        "has_emb = df_embeddings['embedding'].apply(lambda x: x is not None and isinstance(x, list))\n",
        "emb_errors = df_embeddings['error'].notna()\n",
        "\n",
        "print(f'\\n📊 COUNTS')\n",
        "print(f'  Total:       {len(df_embeddings):,}')\n",
        "print(f'  Successful:  {has_emb.sum():,} ({has_emb.sum()/len(df_embeddings)*100:.1f}%)')\n",
        "print(f'  Failed:      {emb_errors.sum():,}')\n",
        "\n",
        "if has_emb.sum() > 0:\n",
        "    sample_emb = df_embeddings.loc[has_emb, 'embedding'].iloc[0]\n",
        "    print(f'  Dimensions:  {len(sample_emb)}')\n",
        "    print(f'  Expected:    {EmbeddingConfig.OUTPUT_DIMENSION}')\n",
        "\n",
        "# ── SAMPLE ERRORS ────────────────────────────────────────────────\n",
        "if has_error.sum() > 0:\n",
        "    print(f'\\n{\"─\" * 70}')\n",
        "    print('SAMPLE ERRORS (first 10)')\n",
        "    print(f'{\"─\" * 70}')\n",
        "    err_sample = df_profiles[has_error][['original_name', 'error']].head(10)\n",
        "    for _, r in err_sample.iterrows():\n",
        "        print(f'  {r[\"original_name\"]:25s} | {str(r[\"error\"])[:80]}')\n",
        "\n",
        "# ── SAMPLE PROFILES ──────────────────────────────────────────────\n",
        "print(f'\\n{\"─\" * 70}')\n",
        "print('SAMPLE PROFILES')\n",
        "print(f'{\"─\" * 70}')\n",
        "\n",
        "for label, mask in [('Gemini high-confidence', gemini_profiles & (df_profiles['profile_confidence'] == 'high')),\n",
        "                     ('Data-only fallback', data_only)]:\n",
        "    sub = df_profiles[mask]\n",
        "    if len(sub) > 0:\n",
        "        s = sub.sample(1, random_state=42).iloc[0]\n",
        "        print(f'\\n  --- {label}: {s[\"verified_name\"]} ---')\n",
        "        print(f'  Confidence: name={s[\"name_confidence\"]}, profile={s[\"profile_confidence\"]}')\n",
        "        print(f'  {s[\"profile\"][:300]}')\n",
        "        if len(s['profile']) > 300:\n",
        "            print(f'  ...')\n",
        "\n",
        "print(f'\\n{\"=\" * 70}')\n",
        "print('Ready to proceed to Step 9: Merge enrichments into all_athletes')\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq3wrcJ4uTgI",
        "outputId": "9e1707fc-1a64-4251-87a5-88c9aac791b1"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "PHASE 6 QC: GEMINI ENRICHMENT\n",
            "======================================================================\n",
            "\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "PROFILE SUMMARIES\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "\n",
            "📊 COUNTS\n",
            "  Total:              12,207\n",
            "  Gemini-generated:   12,147 (99.5%)\n",
            "  Data-only fallback: 60 (0.5%)\n",
            "  Errors:             1 (0.0%)\n",
            "\n",
            "📏 PROFILE LENGTH (Gemini-generated)\n",
            "  Min:    10 chars\n",
            "  Max:    2,238 chars\n",
            "  Mean:   1,275 chars\n",
            "  Median: 1,285 chars\n",
            "\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "NAME VERIFICATION\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "\n",
            "🏷️ NAME CONFIDENCE\n",
            "name_confidence\n",
            "high      11824\n",
            "low         373\n",
            "medium       10\n",
            "\n",
            "🔄 NAME CHANGES\n",
            "  Names updated:    5,738\n",
            "  Names unchanged:  6,469\n",
            "\n",
            "  By confidence:\n",
            "    High:   5,729\n",
            "    Medium: 7\n",
            "    Low:    2\n",
            "\n",
            "  Sample name changes (high confidence, first 10):\n",
            "    Amos Casselman            → Amos Burr Casselman\n",
            "    Samuel Duvall             → Samuel Harding Duvall\n",
            "    Charles Hubbard           → Charles Randolph Hubbard\n",
            "    Linda Myers               → Linda Ann Myers\n",
            "    Debra Ochs                → Deborah Lynn Ochs\n",
            "    Emma Cooke                → Emma C. Cooke\n",
            "    Ed Eliason                → Edwin Murry Eliason\n",
            "    Ruth Rowe                 → Ruth E. Rowe\n",
            "    William Clark             → William Allen Clark\n",
            "    Cyrus Dallin              → Cyrus Edwin Dallin\n",
            "\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "PROFILE CONFIDENCE\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "profile_confidence\n",
            "high         11521\n",
            "medium         429\n",
            "low            197\n",
            "data_only       60\n",
            "\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "BREAKDOWN BY GAMES TYPE\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "\n",
            "  Olympic:\n",
            "    Total:            10,685\n",
            "    Gemini profiles:  10,651\n",
            "    Data-only:        34\n",
            "    Errors:           1\n",
            "    Names updated:    4,668\n",
            "\n",
            "  Paralympic:\n",
            "    Total:            1,522\n",
            "    Gemini profiles:  1,496\n",
            "    Data-only:        26\n",
            "    Errors:           0\n",
            "    Names updated:    1,070\n",
            "\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "EMBEDDINGS\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "\n",
            "📊 COUNTS\n",
            "  Total:       12,207\n",
            "  Successful:  12,207 (100.0%)\n",
            "  Failed:      0\n",
            "  Dimensions:  3072\n",
            "  Expected:    3072\n",
            "\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "SAMPLE ERRORS (first 10)\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "  Otto Boehmke              | No text in API response\n",
            "\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "SAMPLE PROFILES\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "\n",
            "  --- Gemini high-confidence: Diane Madl ---\n",
            "  Confidence: name=high, profile=high\n",
            "  Diane Madl is a distinguished figure in American field hockey, known for her impactful playing career and extensive coaching contributions. She represented the United States as a member of the U.S. National Team, culminating in her participation in the 1996 Summer Olympics in Atlanta. During her col\n",
            "  ...\n",
            "\n",
            "  --- Data-only fallback: Gilberto Brown ---\n",
            "  Confidence: name=low, profile=data_only\n",
            "  Gilberto Brown represented the United States as a Olympic athlete.\n",
            "\n",
            "======================================================================\n",
            "Ready to proceed to Step 9: Merge enrichments into all_athletes\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 6, Step 9: Merge enrichments into all_athletes ─────────\n",
        "\n",
        "# 1. Apply verified names\n",
        "name_map = {}\n",
        "for _, row in df_profiles.iterrows():\n",
        "    if row['name_confidence'] in ('high', 'medium') and \\\n",
        "       pd.notna(row.get('verified_name')) and \\\n",
        "       row['verified_name'] != row.get('original_name', ''):\n",
        "        name_map[row['athlete_id']] = row['verified_name']\n",
        "\n",
        "print(f\"Applying {len(name_map):,} verified name updates...\")\n",
        "all_athletes['name'] = all_athletes.apply(\n",
        "    lambda r: name_map.get(r['athlete_id'], r['name']), axis=1\n",
        ")\n",
        "\n",
        "# 2. Add profile summaries\n",
        "profile_map = dict(zip(df_profiles['athlete_id'], df_profiles['profile']))\n",
        "all_athletes['profile_summary'] = all_athletes['athlete_id'].map(profile_map)\n",
        "\n",
        "# 3. Add embeddings\n",
        "embedding_map = dict(zip(\n",
        "    df_embeddings[df_embeddings['embedding'].apply(\n",
        "        lambda x: x is not None and isinstance(x, list))]['athlete_id'],\n",
        "    df_embeddings[df_embeddings['embedding'].apply(\n",
        "        lambda x: x is not None and isinstance(x, list))]['embedding']\n",
        "))\n",
        "all_athletes['embedding'] = all_athletes['athlete_id'].map(embedding_map)\n",
        "\n",
        "# 4. Sync updated names to results table\n",
        "print(\"Syncing names to results table...\")\n",
        "results_name_map = dict(zip(all_athletes['athlete_id'], all_athletes['name']))\n",
        "all_results['athlete_name'] = all_results.apply(\n",
        "    lambda r: results_name_map.get(r['athlete_id'], r['athlete_name']), axis=1\n",
        ")\n",
        "\n",
        "# 5. Save enriched checkpoints\n",
        "enriched = all_athletes.copy()\n",
        "enriched['embedding'] = enriched['embedding'].apply(\n",
        "    lambda x: json.dumps(x) if isinstance(x, list) else None)\n",
        "\n",
        "ath_path = '/tmp/team_usa_athletes_enriched.csv'\n",
        "enriched.to_csv(ath_path, index=False, encoding='utf-8', quoting=csv.QUOTE_ALL)\n",
        "\n",
        "res_path = '/tmp/team_usa_results.csv'\n",
        "all_results.to_csv(res_path, index=False)\n",
        "\n",
        "# Upload both files\n",
        "ath_dest = f'{BUCKET}/enriched/team_usa_athletes_enriched.csv'\n",
        "res_dest = f'{BUCKET}/enriched/team_usa_results.csv'\n",
        "\n",
        "!gcloud storage cp {ath_path} {ath_dest}\n",
        "!gcloud storage cp {res_path} {res_dest}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNB1uhYn-Hq7",
        "outputId": "9c6d6d1a-c0d2-478f-8d4c-55f5dd25a04c"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying 5,736 verified name updates...\n",
            "Syncing names to results table...\n",
            "\u001b[1;31mERROR:\u001b[0m Cannot check if the destination bucket is compatible for running parallel composite uploads as the user does not permission to perform GET operation on the bucket. The operation will be performed without parallel composite upload feature and hence might perform relatively slower.\n",
            "Copying file:///tmp/team_usa_athletes_enriched.csv to gs://class-demo/team-usa/enriched/team_usa_athletes_enriched.csv\n",
            "\n",
            "Average throughput: 81.9MiB/s\n",
            "Copying file:///tmp/team_usa_results.csv to gs://class-demo/team-usa/enriched/team_usa_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsZUb4Qaynee"
      },
      "source": [
        "---\n",
        "## Phase 7: Validation & Export\n",
        "\n",
        "*Final QC, vector similarity smoke test, schema freeze, and export to GCS.*\n",
        "\n",
        "**Steps:**\n",
        "1. Dataset overview — temporal coverage, gender, sport diversity, medal leaders\n",
        "2. Paralympic classification analysis\n",
        "3. Vector similarity smoke test\n",
        "4. Schema freeze + final export to `gs://class-demo/team-usa/final/`\n",
        "5. Data card"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 7, Step 1: Dataset overview ────────────────────────────\n",
        "import numpy as np\n",
        "\n",
        "print('=' * 70)\n",
        "print('DATASET OVERVIEW')\n",
        "print('=' * 70)\n",
        "\n",
        "# Temporal span\n",
        "print('\\n📅 TEMPORAL COVERAGE')\n",
        "for gt in ['Olympic', 'Paralympic']:\n",
        "    sub = all_athletes[all_athletes['games_type'] == gt]\n",
        "    first = sub['first_games_year'].dropna()\n",
        "    last = sub['last_games_year'].dropna()\n",
        "    if len(first) > 0:\n",
        "        print(f'  {gt:15s} {int(first.min())}–{int(last.max())}')\n",
        "\n",
        "# Gender breakdown\n",
        "print('\\n👥 GENDER DISTRIBUTION')\n",
        "gender_by_type = all_athletes.groupby(['games_type', 'gender']).size().unstack(fill_value=0)\n",
        "print(gender_by_type.to_string())\n",
        "\n",
        "# Sport diversity\n",
        "print('\\n🏅 SPORT DIVERSITY')\n",
        "for gt in ['Olympic', 'Paralympic']:\n",
        "    sub = all_athletes[all_athletes['games_type'] == gt]\n",
        "    n_sports = sub['primary_sport'].nunique()\n",
        "    top_3 = sub['primary_sport'].value_counts().head(3)\n",
        "    print(f'  {gt}: {n_sports} sports — top 3: {\", \".join(f\"{s} ({c})\" for s, c in top_3.items())}')\n",
        "\n",
        "# Medal leaders\n",
        "print('\\n🥇 TOP 10 MEDALISTS (ALL-TIME)')\n",
        "top = all_athletes.nlargest(10, 'total_medals')[\n",
        "    ['name', 'games_type', 'primary_sport', 'gold_count', 'total_medals', 'games_count']\n",
        "].reset_index(drop=True)\n",
        "top.index = top.index + 1\n",
        "print(top.to_string())\n",
        "\n",
        "# Multi-Games athletes\n",
        "print('\\n🔁 MULTI-GAMES ATHLETES')\n",
        "for gt in ['Olympic', 'Paralympic']:\n",
        "    sub = all_athletes[(all_athletes['games_type'] == gt) & (all_athletes['games_count'] >= 2)]\n",
        "    multi4 = (all_athletes['games_type'] == gt) & (all_athletes['games_count'] >= 4)\n",
        "    print(f'  {gt:15s} 2+ Games: {len(sub):,}   4+ Games: {multi4.sum():,}')\n",
        "\n",
        "# Enrichment coverage\n",
        "print('\\n📝 ENRICHMENT COVERAGE')\n",
        "has_profile = all_athletes['profile_summary'].notna()\n",
        "has_embedding = all_athletes['embedding'].notna()\n",
        "print(f'  Profiles:    {has_profile.sum():,} / {len(all_athletes):,} ({has_profile.sum()/len(all_athletes)*100:.1f}%)')\n",
        "print(f'  Embeddings:  {has_embedding.sum():,} / {len(all_athletes):,} ({has_embedding.sum()/len(all_athletes)*100:.1f}%)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcrQdczXA3ig",
        "outputId": "caf47a3f-784f-4080-e31a-7b381e61a106"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "DATASET OVERVIEW\n",
            "======================================================================\n",
            "\n",
            "📅 TEMPORAL COVERAGE\n",
            "  Olympic         1896–2024\n",
            "  Paralympic      1960–2024\n",
            "\n",
            "👥 GENDER DISTRIBUTION\n",
            "gender      Female  Male\n",
            "games_type              \n",
            "Olympic       3151  7534\n",
            "Paralympic     626   764\n",
            "\n",
            "🏅 SPORT DIVERSITY\n",
            "  Olympic: 78 sports — top 3: Athletics (2070), Swimming (758), Rowing (713)\n",
            "  Paralympic: 34 sports — top 3: Athletics (466), Swimming (228), Wheelchair Basketball (132)\n",
            "\n",
            "🥇 TOP 10 MEDALISTS (ALL-TIME)\n",
            "                name  games_type  primary_sport  gold_count  total_medals  games_count\n",
            "1       Trischa Zorn  Paralympic       Swimming        32.0          46.0          7.0\n",
            "2     Michael Phelps     Olympic       Swimming        23.0          28.0          5.0\n",
            "3       Jessica Long  Paralympic       Swimming        13.0          23.0          4.0\n",
            "4        Bart Dodson  Paralympic      Athletics        13.0          20.0          5.0\n",
            "5      Erin Popovich  Paralympic       Swimming        14.0          19.0          3.0\n",
            "6     Rosalie Hixson  Paralympic      Athletics         8.0          18.0          4.0\n",
            "7       Daniel Kelly  Paralympic       Swimming         5.0          17.0          3.0\n",
            "8   Tatyana McFadden  Paralympic      Athletics         7.0          17.0          5.0\n",
            "9    Elizabeth Scott  Paralympic       Swimming        10.0          17.0          3.0\n",
            "10     Chris Waddell  Paralympic  Alpine Skiing         6.0          16.0          6.0\n",
            "\n",
            "🔁 MULTI-GAMES ATHLETES\n",
            "  Olympic         2+ Games: 2,680   4+ Games: 217\n",
            "  Paralympic      2+ Games: 462   4+ Games: 38\n",
            "\n",
            "📝 ENRICHMENT COVERAGE\n",
            "  Profiles:    12,207 / 12,207 (100.0%)\n",
            "  Embeddings:  12,207 / 12,207 (100.0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 7, Step 2: Classification analysis + similarity test ───\n",
        "from numpy.linalg import norm\n",
        "\n",
        "print('=' * 70)\n",
        "print('PARALYMPIC CLASSIFICATION ANALYSIS')\n",
        "print('=' * 70)\n",
        "\n",
        "para = all_athletes[all_athletes['games_type'] == 'Paralympic']\n",
        "has_class = para['classification_code'].notna() & (~para['classification_code'].isin(['None', 'nan', '']))\n",
        "print(f'\\n  Total Paralympic athletes: {len(para):,}')\n",
        "print(f'  With classification:      {has_class.sum():,} ({has_class.sum()/len(para)*100:.1f}%)')\n",
        "print(f'  Unique codes:             {para.loc[has_class, \"classification_code\"].nunique()}')\n",
        "print(f'\\n  Top 15 classifications:')\n",
        "print(para.loc[has_class, 'classification_code'].value_counts().head(15).to_string())\n",
        "\n",
        "# ── Vector similarity smoke test ─────────────────────────────────\n",
        "print(f'\\n{\"=\" * 70}')\n",
        "print('VECTOR SIMILARITY SMOKE TEST')\n",
        "print('=' * 70)\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    a, b = np.array(a), np.array(b)\n",
        "    return np.dot(a, b) / (norm(a) * norm(b))\n",
        "\n",
        "# Pick a well-known swimmer and find nearest neighbors\n",
        "athletes_with_emb = all_athletes[all_athletes['embedding'].notna()].copy()\n",
        "\n",
        "# Find a swimmer with an embedding\n",
        "swimmer = athletes_with_emb[\n",
        "    (athletes_with_emb['primary_sport'].str.contains('Swim', na=False)) &\n",
        "    (athletes_with_emb['total_medals'] > 3)\n",
        "].head(1)\n",
        "\n",
        "if len(swimmer) > 0:\n",
        "    query = swimmer.iloc[0]\n",
        "    query_emb = query['embedding']\n",
        "    print(f'\\nQuery athlete: {query[\"name\"]} ({query[\"games_type\"]}, {query[\"primary_sport\"]})')\n",
        "    print(f'  Medals: {int(query[\"total_medals\"]) if pd.notna(query[\"total_medals\"]) else 0}, Games: {int(query[\"games_count\"]) if pd.notna(query[\"games_count\"]) else 0}')\n",
        "\n",
        "    # Compute similarities\n",
        "    sims = []\n",
        "    for _, row in athletes_with_emb.iterrows():\n",
        "        if row['athlete_id'] != query['athlete_id']:\n",
        "            sim = cosine_similarity(query_emb, row['embedding'])\n",
        "            sims.append((row['name'], row['games_type'], row['primary_sport'],\n",
        "                         int(row['total_medals']) if pd.notna(row.get('total_medals')) else 0, sim))\n",
        "\n",
        "    sims.sort(key=lambda x: x[4], reverse=True)\n",
        "\n",
        "    print(f'\\n  Top 10 most similar athletes:')\n",
        "    print(f'  {\"Name\":35s} {\"Type\":12s} {\"Sport\":25s} {\"Medals\":>7s} {\"Similarity\":>10s}')\n",
        "    print(f'  {\"-\"*35} {\"-\"*12} {\"-\"*25} {\"-\"*7} {\"-\"*10}')\n",
        "    for name, gt, sport, medals, sim in sims[:10]:\n",
        "        print(f'  {name:35s} {gt:12s} {str(sport):25s} {medals:>7d} {sim:>10.4f}')\n",
        "\n",
        "    # Cross-type check: find most similar Paralympic athlete to our Olympic swimmer\n",
        "    para_sims = [s for s in sims if s[1] == 'Paralympic']\n",
        "    if para_sims:\n",
        "        print(f'\\n  Most similar Paralympic athlete:')\n",
        "        ps = para_sims[0]\n",
        "        print(f'  {ps[0]} ({ps[2]}, {ps[3]} medals) — similarity: {ps[4]:.4f}')\n",
        "else:\n",
        "    print('\\n  ⚠️ No swimmer with embedding found for similarity test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ncMtYjFA7iw",
        "outputId": "c773fa6c-4383-4c92-a384-49288897a7cf"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "PARALYMPIC CLASSIFICATION ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "  Total Paralympic athletes: 1,522\n",
            "  With classification:      691 (45.4%)\n",
            "  Unique codes:             154\n",
            "\n",
            "  Top 15 classifications:\n",
            "classification_code\n",
            "B3     41\n",
            "B1     31\n",
            "B2     28\n",
            "C3     19\n",
            "C1     17\n",
            "S7     16\n",
            "C5     16\n",
            "C4     16\n",
            "LW2    15\n",
            "T54    14\n",
            "T52    13\n",
            "S9     12\n",
            "T10    12\n",
            "T42    12\n",
            "T53    12\n",
            "\n",
            "======================================================================\n",
            "VECTOR SIMILARITY SMOKE TEST\n",
            "======================================================================\n",
            "\n",
            "Query athlete: Shirley Babashoff (Olympic, Swimming)\n",
            "  Medals: 8, Games: 2\n",
            "\n",
            "  Top 10 most similar athletes:\n",
            "  Name                                Type         Sport                      Medals Similarity\n",
            "  ----------------------------------- ------------ ------------------------- ------- ----------\n",
            "  Jack Babashoff                      Olympic      Swimming                        1     0.8441\n",
            "  Wendy Weinberg                      Olympic      Swimming                        1     0.7895\n",
            "  Wendy Boglioli                      Olympic      Swimming                        2     0.7738\n",
            "  Jill Sterkel                        Olympic      Swimming                        4     0.7644\n",
            "  Karen Moe-Thornton                  Olympic      Swimming                        1     0.7624\n",
            "  Sandra Lynn Neilson                 Olympic      Swimming                        3     0.7591\n",
            "  Melissa Belote                      Olympic      Swimming                        3     0.7536\n",
            "  Laura Gail Siering                  Olympic      Swimming                        1     0.7527\n",
            "  Deena Diane Deardurff               Olympic      Swimming                        1     0.7523\n",
            "  Sharon Stouder                      Olympic      Swimming                        4     0.7489\n",
            "\n",
            "  Most similar Paralympic athlete:\n",
            "  Nancy Clarke (Swimming, 4 medals) — similarity: 0.6831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Phase 7, Step 3: Schema freeze + final export ────────────────\n",
        "\n",
        "ATHLETE_COLUMNS = [\n",
        "    'athlete_id', 'name', 'gender', 'birth_date',\n",
        "    'height_cm', 'weight_kg',\n",
        "    'games_type', 'games_season', 'primary_sport', 'classification_code',\n",
        "    'first_games_year', 'last_games_year', 'games_count',\n",
        "    'gold_count', 'silver_count', 'bronze_count', 'total_medals',\n",
        "    'profile_summary', 'embedding',\n",
        "]\n",
        "\n",
        "RESULT_COLUMNS = [\n",
        "    'athlete_id', 'athlete_name', 'games_year', 'games_season',\n",
        "    'games_type', 'sport', 'discipline', 'event', 'medal',\n",
        "    'classification_code',\n",
        "]\n",
        "\n",
        "# Apply column order\n",
        "athletes_final = all_athletes[[c for c in ATHLETE_COLUMNS if c in all_athletes.columns]].copy()\n",
        "results_final = all_results[[c for c in RESULT_COLUMNS if c in all_results.columns]].copy()\n",
        "\n",
        "# Check for missing columns\n",
        "missing_ath = [c for c in ATHLETE_COLUMNS if c not in all_athletes.columns]\n",
        "missing_res = [c for c in RESULT_COLUMNS if c not in all_results.columns]\n",
        "if missing_ath:\n",
        "    print(f'⚠️ Athletes missing columns: {missing_ath}')\n",
        "if missing_res:\n",
        "    print(f'⚠️ Results missing columns: {missing_res}')\n",
        "\n",
        "# Serialize embeddings for CSV export\n",
        "athletes_final['embedding'] = athletes_final['embedding'].apply(\n",
        "    lambda x: json.dumps(x) if isinstance(x, list) else None)\n",
        "\n",
        "# Save locally\n",
        "ath_final_path = '/tmp/team_usa_athletes_final.csv'\n",
        "res_final_path = '/tmp/team_usa_results_final.csv'\n",
        "\n",
        "athletes_final.to_csv(ath_final_path, index=False, encoding='utf-8', quoting=csv.QUOTE_ALL)\n",
        "results_final.to_csv(res_final_path, index=False, encoding='utf-8')\n",
        "\n",
        "# Upload to GCS\n",
        "ath_dest = f'{BUCKET}/final/team_usa_athletes.csv'\n",
        "res_dest = f'{BUCKET}/final/team_usa_results.csv'\n",
        "\n",
        "!gcloud storage cp {ath_final_path} {ath_dest}\n",
        "!gcloud storage cp {res_final_path} {res_dest}\n",
        "\n",
        "print(f'\\n{\"=\" * 60}')\n",
        "print(f'FINAL EXPORT')\n",
        "print(f'{\"=\" * 60}')\n",
        "print(f'  Athletes: {len(athletes_final):,} rows × {len(athletes_final.columns)} columns')\n",
        "print(f'  Results:  {len(results_final):,} rows × {len(results_final.columns)} columns')\n",
        "print(f'\\n  Athletes schema: {list(athletes_final.columns)}')\n",
        "print(f'  Results schema:  {list(results_final.columns)}')\n",
        "print(f'\\n  ✅ {ath_dest}')\n",
        "print(f'  ✅ {res_dest}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hc2rE0ENBaP5",
        "outputId": "21232061-34fc-4bab-e821-da391447a4a8"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;31mERROR:\u001b[0m Cannot check if the destination bucket is compatible for running parallel composite uploads as the user does not permission to perform GET operation on the bucket. The operation will be performed without parallel composite upload feature and hence might perform relatively slower.\n",
            "Copying file:///tmp/team_usa_athletes_final.csv to gs://class-demo/team-usa/final/team_usa_athletes.csv\n",
            "\n",
            "Average throughput: 144.0MiB/s\n",
            "Copying file:///tmp/team_usa_results_final.csv to gs://class-demo/team-usa/final/team_usa_results.csv\n",
            "\n",
            "============================================================\n",
            "FINAL EXPORT\n",
            "============================================================\n",
            "  Athletes: 12,207 rows × 19 columns\n",
            "  Results:  24,458 rows × 10 columns\n",
            "\n",
            "  Athletes schema: ['athlete_id', 'name', 'gender', 'birth_date', 'height_cm', 'weight_kg', 'games_type', 'games_season', 'primary_sport', 'classification_code', 'first_games_year', 'last_games_year', 'games_count', 'gold_count', 'silver_count', 'bronze_count', 'total_medals', 'profile_summary', 'embedding']\n",
            "  Results schema:  ['athlete_id', 'athlete_name', 'games_year', 'games_season', 'games_type', 'sport', 'discipline', 'event', 'medal', 'classification_code']\n",
            "\n",
            "  ✅ gs://class-demo/team-usa/final/team_usa_athletes.csv\n",
            "  ✅ gs://class-demo/team-usa/final/team_usa_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hMw74kGXCEWQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}